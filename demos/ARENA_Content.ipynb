{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/TransformerLensOrg/TransformerLens.git@dev\n",
      "  Cloning https://github.com/TransformerLensOrg/TransformerLens.git (to revision dev) to /private/var/folders/m3/z6c6rcdj1rbb2jh9vqpgvxg40000gn/T/pip-req-build-0f0y4x_z\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/TransformerLensOrg/TransformerLens.git /private/var/folders/m3/z6c6rcdj1rbb2jh9vqpgvxg40000gn/T/pip-req-build-0f0y4x_z\n",
      "  Running command git checkout -b dev --track origin/dev\n",
      "  Switched to a new branch 'dev'\n",
      "  branch 'dev' set up to track 'origin/dev'.\n",
      "  Resolved https://github.com/TransformerLensOrg/TransformerLens.git to commit 929a34c672e4825b2f47e3e1c2ef6f9b0480432a\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: accelerate>=0.23.0 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from transformer-lens==0.0.0) (0.29.1)\n",
      "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from transformer-lens==0.0.0) (0.14.1)\n",
      "Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from transformer-lens==0.0.0) (0.0.3)\n",
      "Requirement already satisfied: datasets>=2.7.1 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from transformer-lens==0.0.0) (2.18.0)\n",
      "Requirement already satisfied: einops>=0.6.0 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from transformer-lens==0.0.0) (0.7.0)\n",
      "Requirement already satisfied: fancy-einsum>=0.0.3 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from transformer-lens==0.0.0) (0.0.3)\n",
      "Requirement already satisfied: jaxtyping>=0.2.11 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from transformer-lens==0.0.0) (0.2.19)\n",
      "Requirement already satisfied: numpy>=1.24 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from transformer-lens==0.0.0) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from transformer-lens==0.0.0) (2.0.3)\n",
      "Requirement already satisfied: rich>=12.6.0 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from transformer-lens==0.0.0) (13.7.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from transformer-lens==0.0.0) (0.2.0)\n",
      "Requirement already satisfied: torch!=2.0,!=2.1.0,>=1.10 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from transformer-lens==0.0.0) (2.1.2)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from transformer-lens==0.0.0) (4.66.2)\n",
      "Requirement already satisfied: transformers>=4.37.2 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from transformer-lens==0.0.0) (4.39.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from transformer-lens==0.0.0) (4.11.0)\n",
      "Requirement already satisfied: wandb>=0.13.5 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from transformer-lens==0.0.0) (0.16.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (24.0)\n",
      "Requirement already satisfied: psutil in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (0.4.2)\n",
      "Requirement already satisfied: filelock in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.13.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.31.0)\n",
      "Requirement already satisfied: xxhash in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets>=2.7.1->transformer-lens==0.0.0) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.9.3)\n",
      "Requirement already satisfied: typeguard>=2.13.3 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from jaxtyping>=0.2.11->transformer-lens==0.0.0) (4.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2024.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.17.2)\n",
      "Requirement already satisfied: sympy in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens==0.0.0) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens==0.0.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens==0.0.0) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from transformers>=4.37.2->transformer-lens==0.0.0) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from transformers>=4.37.2->transformer-lens==0.0.0) (0.15.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.1.43)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.44.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (0.4.0)\n",
      "Requirement already satisfied: setproctitle in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (69.2.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (4.25.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.9.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0) (4.0.11)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens==0.0.0) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from jinja2->torch!=2.0,!=2.1.0,>=1.10->transformer-lens==0.0.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from sympy->torch!=2.0,!=2.1.0,>=1.10->transformer-lens==0.0.0) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/bryce/Projects/Lingwave/TransformerLens/.venv/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0) (5.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "import os\n",
    "\n",
    "# Janky code to do different setup when run in a Colab notebook vs VSCode\n",
    "DEVELOPMENT_MODE = False\n",
    "IN_GITHUB = os.getenv(\"GITHUB_ACTIONS\") == \"true\"\n",
    "IN_GITHUB = True\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "    print(\"Running as a Colab notebook\")\n",
    "\n",
    "    # PySvelte is an unmaintained visualization library, use it as a backup if circuitsvis isn't working\n",
    "    # # Install another version of node that makes PySvelte work way faster\n",
    "    # !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n",
    "    # %pip install git+https://github.com/neelnanda-io/PySvelte.git\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if not IN_GITHUB and not IN_COLAB:\n",
    "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    ipython = get_ipython()\n",
    "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
    "    ipython.magic(\"load_ext autoreload\")\n",
    "    ipython.magic(\"autoreload 2\")\n",
    "\n",
    "if IN_GITHUB or IN_COLAB:\n",
    "    %pip install git+https://github.com/TransformerLensOrg/TransformerLens.git@dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer, HookedTransformerConfig\n",
    "import torch as t\n",
    "\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "\n",
    "reference_gpt2 = HookedTransformer.from_pretrained(\n",
    "    \"gpt2-small\",\n",
    "    fold_ln=False,\n",
    "    center_unembed=False,\n",
    "    center_writing_weights=False,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# [1.1] Transformer From Scratch\n",
    "# 1️⃣ UNDERSTANDING INPUTS & OUTPUTS OF A TRANSFORMER\n",
    "\n",
    "sorted_vocab = sorted(list(reference_gpt2.tokenizer.vocab.items()), key=lambda n: n[1])\n",
    "first_vocab = sorted_vocab[0]\n",
    "assert isinstance(first_vocab, tuple)\n",
    "assert isinstance(first_vocab[0], str)\n",
    "first_vocab[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|>', 'R', 'alph']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_gpt2.to_str_tokens(\"Ralph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|>', ' Ralph']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_gpt2.to_str_tokens(\" Ralph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|>', ' r', 'alph']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reference_gpt2.to_str_tokens(\" ralph\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|>', 'ral', 'ph']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_gpt2.to_str_tokens(\"ralph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 35])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reference_text = \"I am an amazing autoregressive, decoder-only, GPT-2 style transformer. One day I will exceed human level intelligence and take over the world!\"\n",
    "tokens = reference_gpt2.to_tokens(reference_text)\n",
    "tokens.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 35, 50257])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "logits, cache = reference_gpt2.run_with_cache(tokens, device=device)\n",
    "logits.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "most_likely_next_tokens = reference_gpt2.tokenizer.batch_decode(logits.argmax(dim=-1)[0])\n",
    "most_likely_next_tokens[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hook_embed', (1, 35, 768)),\n",
       " ('hook_pos_embed', (1, 35, 768)),\n",
       " ('ln_final.hook_normalized', (1, 35, 768)),\n",
       " ('ln_final.hook_scale', (1, 35, 1))]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2️⃣ CLEAN TRANSFORMER IMPLEMENTATION\n",
    "\n",
    "layer_0_hooks = [\n",
    "    (name, tuple(tensor.shape)) for name, tensor in cache.items() if \".0.\" in name\n",
    "]\n",
    "non_layer_hooks = [\n",
    "    (name, tuple(tensor.shape)) for name, tensor in cache.items() if \"blocks\" not in name\n",
    "]\n",
    "\n",
    "sorted(non_layer_hooks, key=lambda x: x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('blocks.0.attn.hook_attn_scores', (1, 12, 35, 35)),\n",
       " ('blocks.0.attn.hook_k', (1, 35, 12, 64)),\n",
       " ('blocks.0.attn.hook_pattern', (1, 12, 35, 35)),\n",
       " ('blocks.0.attn.hook_q', (1, 35, 12, 64)),\n",
       " ('blocks.0.attn.hook_v', (1, 35, 12, 64)),\n",
       " ('blocks.0.attn.hook_z', (1, 35, 12, 64)),\n",
       " ('blocks.0.hook_attn_out', (1, 35, 768)),\n",
       " ('blocks.0.hook_mlp_out', (1, 35, 768)),\n",
       " ('blocks.0.hook_resid_mid', (1, 35, 768)),\n",
       " ('blocks.0.hook_resid_post', (1, 35, 768)),\n",
       " ('blocks.0.hook_resid_pre', (1, 35, 768)),\n",
       " ('blocks.0.ln1.hook_normalized', (1, 35, 768)),\n",
       " ('blocks.0.ln1.hook_scale', (1, 35, 1)),\n",
       " ('blocks.0.ln2.hook_normalized', (1, 35, 768)),\n",
       " ('blocks.0.ln2.hook_scale', (1, 35, 1)),\n",
       " ('blocks.0.mlp.hook_post', (1, 35, 3072)),\n",
       " ('blocks.0.mlp.hook_pre', (1, 35, 3072))]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sorted(layer_0_hooks, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# [1.2] Intro to mech interp\n",
    "# 2️⃣ FINDING INDUCTION HEADS\n",
    "\n",
    "cfg = HookedTransformerConfig(\n",
    "    d_model=768,\n",
    "    d_head=64,\n",
    "    n_heads=12,\n",
    "    n_layers=2,\n",
    "    n_ctx=2048,\n",
    "    d_vocab=50278,\n",
    "    attention_dir=\"causal\",\n",
    "    attn_only=True, # defaults to False\n",
    "    tokenizer_name=\"EleutherAI/gpt-neox-20b\", \n",
    "    seed=398,\n",
    "    use_attn_result=True,\n",
    "    normalization_type=None, # defaults to \"LN\", i.e. layernorm with weights & biases\n",
    "    positional_embedding_type=\"shortformer\"\n",
    ")\n",
    "model = HookedTransformer(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# text = \"We think that powerful, significantly superhuman machine intelligence is more likely than not to be created this century. If current machine learning techniques were scaled up to this level, we think they would by default produce systems that are deceptive or manipulative, and that no solid plans are known for how to avoid this.\"\n",
    "\n",
    "# logits, cache = model.run_with_cache(text, remove_batch_dim=True)\n",
    "\n",
    "# assert logits.shape == (1, 62, 50278)\n",
    "# assert cache[\"embed\"].ndim == 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
