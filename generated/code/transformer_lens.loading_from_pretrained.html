<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />
<link rel="index" title="Index" href="../../genindex.html" /><link rel="search" title="Search" href="../../search.html" /><link rel="next" title="transformer_lens.past_key_value_caching" href="transformer_lens.past_key_value_caching.html" /><link rel="prev" title="transformer_lens.hook_points" href="transformer_lens.hook_points.html" />

    <link rel="shortcut icon" href="../../_static/favicon.ico"/><!-- Generated with Sphinx 5.2.3 and Furo 2023.03.27 -->
        <title>transformer_lens.loading_from_pretrained - TransformerLens Documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?digest=fad236701ea90a88636c2a8c73b44ae642ed2a53" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../index.html"><div class="brand">TransformerLens Documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand centered" href="../../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../../_static/transformer_lens_logo.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">TransformerLens Documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../content/getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../content/getting_started_mech_interp.html">Getting Started in Mechanistic Interpretability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../content/gallery.html">Gallery</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Documentation</span></p>
<ul class="current">
<li class="toctree-l1 current has-children"><a class="reference internal" href="modules.html">Transformer Lens API</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 current has-children"><a class="reference internal" href="transformer_lens.html">transformer_lens</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="transformer_lens.ActivationCache.html">transformer_lens.ActivationCache</a></li>
<li class="toctree-l3"><a class="reference internal" href="transformer_lens.FactoredMatrix.html">transformer_lens.FactoredMatrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="transformer_lens.HookedEncoder.html">transformer_lens.HookedEncoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="transformer_lens.HookedTransformer.html">transformer_lens.HookedTransformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="transformer_lens.HookedTransformerConfig.html">transformer_lens.HookedTransformerConfig</a></li>
<li class="toctree-l3"><a class="reference internal" href="transformer_lens.SVDInterpreter.html">transformer_lens.SVDInterpreter</a></li>
<li class="toctree-l3"><a class="reference internal" href="transformer_lens.components.html">transformer_lens.components</a></li>
<li class="toctree-l3"><a class="reference internal" href="transformer_lens.evals.html">transformer_lens.evals</a></li>
<li class="toctree-l3"><a class="reference internal" href="transformer_lens.head_detector.html">transformer_lens.head_detector</a></li>
<li class="toctree-l3"><a class="reference internal" href="transformer_lens.hook_points.html">transformer_lens.hook_points</a></li>
<li class="toctree-l3 current current-page"><a class="current reference internal" href="#">transformer_lens.loading_from_pretrained</a></li>
<li class="toctree-l3"><a class="reference internal" href="transformer_lens.past_key_value_caching.html">transformer_lens.past_key_value_caching</a></li>
<li class="toctree-l3"><a class="reference internal" href="transformer_lens.patching.html">transformer_lens.patching</a></li>
<li class="toctree-l3"><a class="reference internal" href="transformer_lens.train.html">transformer_lens.train</a></li>
<li class="toctree-l3"><a class="reference internal" href="transformer_lens.utils.html">transformer_lens.utils</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="transformer_lens.utilities.html">transformer_lens.utilities</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="transformer_lens.utilities.devices.html">transformer_lens.utilities.devices</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../model_properties_table.html">Model Properties Table</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../content/tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../content/citation.html">Citation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../content/contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../demos/Main_Demo.html">Transformer Lens Main Demo Notebook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../demos/Main_Demo.html#Setup">Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../demos/Main_Demo.html#Introduction">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../demos/Main_Demo.html#Features">Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../demos/Exploratory_Analysis_Demo.html">Exploratory Analysis Demo</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Development</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../content/contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/neelnanda-io/TransformerLens">Github</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="module-transformer_lens.loading_from_pretrained">
<span id="transformer-lens-loading-from-pretrained"></span><h1>transformer_lens.loading_from_pretrained<a class="headerlink" href="#module-transformer_lens.loading_from_pretrained" title="Permalink to this heading">#</a></h1>
<p>Loading Pretrained Models Utilities.</p>
<p>This module contains functions for loading pretrained models from the Hugging Face Hub.</p>
<dl class="py class">
<dt class="sig sig-object py" id="transformer_lens.loading_from_pretrained.Config">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">transformer_lens.loading_from_pretrained.</span></span><span class="sig-name descname"><span class="pre">Config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">768</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_norm_eps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_vocab</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50257</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_range</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.02</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_ctx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1024</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_head</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d_mlp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3072</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_heads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">12</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">12</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#transformer_lens.loading_from_pretrained.Config" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="transformer_lens.loading_from_pretrained.Config.d_head">
<span class="sig-name descname"><span class="pre">d_head</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">64</span></em><a class="headerlink" href="#transformer_lens.loading_from_pretrained.Config.d_head" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformer_lens.loading_from_pretrained.Config.d_mlp">
<span class="sig-name descname"><span class="pre">d_mlp</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">3072</span></em><a class="headerlink" href="#transformer_lens.loading_from_pretrained.Config.d_mlp" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformer_lens.loading_from_pretrained.Config.d_model">
<span class="sig-name descname"><span class="pre">d_model</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">768</span></em><a class="headerlink" href="#transformer_lens.loading_from_pretrained.Config.d_model" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformer_lens.loading_from_pretrained.Config.d_vocab">
<span class="sig-name descname"><span class="pre">d_vocab</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">50257</span></em><a class="headerlink" href="#transformer_lens.loading_from_pretrained.Config.d_vocab" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformer_lens.loading_from_pretrained.Config.debug">
<span class="sig-name descname"><span class="pre">debug</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#transformer_lens.loading_from_pretrained.Config.debug" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformer_lens.loading_from_pretrained.Config.init_range">
<span class="sig-name descname"><span class="pre">init_range</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0.02</span></em><a class="headerlink" href="#transformer_lens.loading_from_pretrained.Config.init_range" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformer_lens.loading_from_pretrained.Config.layer_norm_eps">
<span class="sig-name descname"><span class="pre">layer_norm_eps</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1e-05</span></em><a class="headerlink" href="#transformer_lens.loading_from_pretrained.Config.layer_norm_eps" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformer_lens.loading_from_pretrained.Config.n_ctx">
<span class="sig-name descname"><span class="pre">n_ctx</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1024</span></em><a class="headerlink" href="#transformer_lens.loading_from_pretrained.Config.n_ctx" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformer_lens.loading_from_pretrained.Config.n_heads">
<span class="sig-name descname"><span class="pre">n_heads</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">12</span></em><a class="headerlink" href="#transformer_lens.loading_from_pretrained.Config.n_heads" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="transformer_lens.loading_from_pretrained.Config.n_layers">
<span class="sig-name descname"><span class="pre">n_layers</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">12</span></em><a class="headerlink" href="#transformer_lens.loading_from_pretrained.Config.n_layers" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py data">
<dt class="sig sig-object py" id="transformer_lens.loading_from_pretrained.MODEL_ALIASES">
<span class="sig-prename descclassname"><span class="pre">transformer_lens.loading_from_pretrained.</span></span><span class="sig-name descname"><span class="pre">MODEL_ALIASES</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{'ArthurConmy/redwood_attn_2l':</span> <span class="pre">['redwood_attn_2l'],</span> <span class="pre">'Baidicoot/Othello-GPT-Transformer-Lens':</span> <span class="pre">['othello-gpt'],</span> <span class="pre">'EleutherAI/gpt-j-6B':</span> <span class="pre">['gpt-j-6B',</span> <span class="pre">'gpt-j',</span> <span class="pre">'gptj'],</span> <span class="pre">'EleutherAI/gpt-neo-1.3B':</span> <span class="pre">['gpt-neo-1.3B',</span> <span class="pre">'gpt-neo-medium',</span> <span class="pre">'neo-medium'],</span> <span class="pre">'EleutherAI/gpt-neo-125M':</span> <span class="pre">['gpt-neo-125M',</span> <span class="pre">'gpt-neo-small',</span> <span class="pre">'neo-small',</span> <span class="pre">'neo'],</span> <span class="pre">'EleutherAI/gpt-neo-2.7B':</span> <span class="pre">['gpt-neo-2.7B',</span> <span class="pre">'gpt-neo-large',</span> <span class="pre">'neo-large'],</span> <span class="pre">'EleutherAI/gpt-neox-20b':</span> <span class="pre">['gpt-neox-20b',</span> <span class="pre">'gpt-neox',</span> <span class="pre">'neox'],</span> <span class="pre">'EleutherAI/pythia-1.4b':</span> <span class="pre">['pythia-1.4b',</span> <span class="pre">'EleutherAI/pythia-1.3b',</span> <span class="pre">'pythia-1.3b'],</span> <span class="pre">'EleutherAI/pythia-1.4b-deduped':</span> <span class="pre">['pythia-1.4b-deduped',</span> <span class="pre">'EleutherAI/pythia-1.3b-deduped',</span> <span class="pre">'pythia-1.3b-deduped'],</span> <span class="pre">'EleutherAI/pythia-1.4b-deduped-v0':</span> <span class="pre">['pythia-1.4b-deduped-v0',</span> <span class="pre">'EleutherAI/pythia-1.3b-deduped-v0',</span> <span class="pre">'pythia-1.3b-deduped-v0'],</span> <span class="pre">'EleutherAI/pythia-1.4b-v0':</span> <span class="pre">['pythia-1.4b-v0',</span> <span class="pre">'EleutherAI/pythia-1.3b-v0',</span> <span class="pre">'pythia-1.3b-v0'],</span> <span class="pre">'EleutherAI/pythia-12b':</span> <span class="pre">['pythia-12b',</span> <span class="pre">'EleutherAI/pythia-13b',</span> <span class="pre">'pythia-13b'],</span> <span class="pre">'EleutherAI/pythia-12b-deduped':</span> <span class="pre">['pythia-12b-deduped',</span> <span class="pre">'EleutherAI/pythia-13b-deduped',</span> <span class="pre">'pythia-13b-deduped'],</span> <span class="pre">'EleutherAI/pythia-12b-deduped-v0':</span> <span class="pre">['pythia-12b-deduped-v0',</span> <span class="pre">'EleutherAI/pythia-13b-deduped-v0',</span> <span class="pre">'pythia-13b-deduped-v0'],</span> <span class="pre">'EleutherAI/pythia-12b-v0':</span> <span class="pre">['pythia-12b-v0',</span> <span class="pre">'EleutherAI/pythia-13b-v0',</span> <span class="pre">'pythia-13b-v0'],</span> <span class="pre">'EleutherAI/pythia-14m':</span> <span class="pre">['pythia-14m'],</span> <span class="pre">'EleutherAI/pythia-160m':</span> <span class="pre">['pythia-160m',</span> <span class="pre">'EleutherAI/pythia-125m',</span> <span class="pre">'pythia-125m'],</span> <span class="pre">'EleutherAI/pythia-160m-deduped':</span> <span class="pre">['pythia-160m-deduped',</span> <span class="pre">'EleutherAI/pythia-125m-deduped',</span> <span class="pre">'pythia-125m-deduped'],</span> <span class="pre">'EleutherAI/pythia-160m-deduped-v0':</span> <span class="pre">['pythia-160m-deduped-v0',</span> <span class="pre">'EleutherAI/pythia-125m-deduped-v0',</span> <span class="pre">'pythia-125m-deduped-v0'],</span> <span class="pre">'EleutherAI/pythia-160m-seed1':</span> <span class="pre">['pythia-160m-seed1',</span> <span class="pre">'EleutherAI/pythia-125m-seed1',</span> <span class="pre">'pythia-125m-seed1'],</span> <span class="pre">'EleutherAI/pythia-160m-seed2':</span> <span class="pre">['pythia-160m-seed2',</span> <span class="pre">'EleutherAI/pythia-125m-seed2',</span> <span class="pre">'pythia-125m-seed2'],</span> <span class="pre">'EleutherAI/pythia-160m-seed3':</span> <span class="pre">['pythia-160m-seed3',</span> <span class="pre">'EleutherAI/pythia-125m-seed3',</span> <span class="pre">'pythia-125m-seed3'],</span> <span class="pre">'EleutherAI/pythia-160m-v0':</span> <span class="pre">['pythia-160m-v0',</span> <span class="pre">'EleutherAI/pythia-125m-v0',</span> <span class="pre">'pythia-125m-v0'],</span> <span class="pre">'EleutherAI/pythia-1b':</span> <span class="pre">['pythia-1b',</span> <span class="pre">'EleutherAI/pythia-800m',</span> <span class="pre">'pythia-800m'],</span> <span class="pre">'EleutherAI/pythia-1b-deduped':</span> <span class="pre">['pythia-1b-deduped',</span> <span class="pre">'EleutherAI/pythia-800m-deduped',</span> <span class="pre">'pythia-800m-deduped'],</span> <span class="pre">'EleutherAI/pythia-1b-deduped-v0':</span> <span class="pre">['pythia-1b-deduped-v0',</span> <span class="pre">'EleutherAI/pythia-800m-deduped-v0',</span> <span class="pre">'pythia-800m-deduped-v0'],</span> <span class="pre">'EleutherAI/pythia-1b-v0':</span> <span class="pre">['pythia-1b-v0',</span> <span class="pre">'EleutherAI/pythia-800m-v0',</span> <span class="pre">'pythia-800m-v0'],</span> <span class="pre">'EleutherAI/pythia-2.8b':</span> <span class="pre">['pythia-2.8b',</span> <span class="pre">'EleutherAI/pythia-2.7b',</span> <span class="pre">'pythia-2.7b'],</span> <span class="pre">'EleutherAI/pythia-2.8b-deduped':</span> <span class="pre">['pythia-2.8b-deduped',</span> <span class="pre">'EleutherAI/pythia-2.7b-deduped',</span> <span class="pre">'pythia-2.7b-deduped'],</span> <span class="pre">'EleutherAI/pythia-2.8b-deduped-v0':</span> <span class="pre">['pythia-2.8b-deduped-v0',</span> <span class="pre">'EleutherAI/pythia-2.7b-deduped-v0',</span> <span class="pre">'pythia-2.7b-deduped-v0'],</span> <span class="pre">'EleutherAI/pythia-2.8b-v0':</span> <span class="pre">['pythia-2.8b-v0',</span> <span class="pre">'EleutherAI/pythia-2.7b-v0',</span> <span class="pre">'pythia-2.7b-v0'],</span> <span class="pre">'EleutherAI/pythia-31m':</span> <span class="pre">['pythia-31m'],</span> <span class="pre">'EleutherAI/pythia-410m':</span> <span class="pre">['pythia-410m',</span> <span class="pre">'EleutherAI/pythia-350m',</span> <span class="pre">'pythia-350m'],</span> <span class="pre">'EleutherAI/pythia-410m-deduped':</span> <span class="pre">['pythia-410m-deduped',</span> <span class="pre">'EleutherAI/pythia-350m-deduped',</span> <span class="pre">'pythia-350m-deduped'],</span> <span class="pre">'EleutherAI/pythia-410m-deduped-v0':</span> <span class="pre">['pythia-410m-deduped-v0',</span> <span class="pre">'EleutherAI/pythia-350m-deduped-v0',</span> <span class="pre">'pythia-350m-deduped-v0'],</span> <span class="pre">'EleutherAI/pythia-410m-v0':</span> <span class="pre">['pythia-410m-v0',</span> <span class="pre">'EleutherAI/pythia-350m-v0',</span> <span class="pre">'pythia-350m-v0'],</span> <span class="pre">'EleutherAI/pythia-6.9b':</span> <span class="pre">['pythia-6.9b',</span> <span class="pre">'EleutherAI/pythia-6.7b',</span> <span class="pre">'pythia-6.7b'],</span> <span class="pre">'EleutherAI/pythia-6.9b-deduped':</span> <span class="pre">['pythia-6.9b-deduped',</span> <span class="pre">'EleutherAI/pythia-6.7b-deduped',</span> <span class="pre">'pythia-6.7b-deduped'],</span> <span class="pre">'EleutherAI/pythia-6.9b-deduped-v0':</span> <span class="pre">['pythia-6.9b-deduped-v0',</span> <span class="pre">'EleutherAI/pythia-6.7b-deduped-v0',</span> <span class="pre">'pythia-6.7b-deduped-v0'],</span> <span class="pre">'EleutherAI/pythia-6.9b-v0':</span> <span class="pre">['pythia-6.9b-v0',</span> <span class="pre">'EleutherAI/pythia-6.7b-v0',</span> <span class="pre">'pythia-6.7b-v0'],</span> <span class="pre">'EleutherAI/pythia-70m':</span> <span class="pre">['pythia-70m',</span> <span class="pre">'pythia',</span> <span class="pre">'EleutherAI/pythia-19m',</span> <span class="pre">'pythia-19m'],</span> <span class="pre">'EleutherAI/pythia-70m-deduped':</span> <span class="pre">['pythia-70m-deduped',</span> <span class="pre">'EleutherAI/pythia-19m-deduped',</span> <span class="pre">'pythia-19m-deduped'],</span> <span class="pre">'EleutherAI/pythia-70m-deduped-v0':</span> <span class="pre">['pythia-70m-deduped-v0',</span> <span class="pre">'EleutherAI/pythia-19m-deduped-v0',</span> <span class="pre">'pythia-19m-deduped-v0'],</span> <span class="pre">'EleutherAI/pythia-70m-v0':</span> <span class="pre">['pythia-70m-v0',</span> <span class="pre">'pythia-v0',</span> <span class="pre">'EleutherAI/pythia-19m-v0',</span> <span class="pre">'pythia-19m-v0'],</span> <span class="pre">'Llama-2-13b-chat-hf':</span> <span class="pre">['Llama-2-13b-chat',</span> <span class="pre">'meta-llama/Llama-2-13b-chat-hf'],</span> <span class="pre">'Llama-2-13b-hf':</span> <span class="pre">['Llama-2-13b',</span> <span class="pre">'meta-llama/Llama-2-13b-hf'],</span> <span class="pre">'Llama-2-7b-chat-hf':</span> <span class="pre">['Llama-2-7b-chat',</span> <span class="pre">'meta-llama/Llama-2-7b-chat-hf'],</span> <span class="pre">'Llama-2-7b-hf':</span> <span class="pre">['Llama-2-7b',</span> <span class="pre">'meta-llama/Llama-2-7b-hf'],</span> <span class="pre">'NeelNanda/Attn-Only-2L512W-Shortformer-6B-big-lr':</span> <span class="pre">['attn-only-2l-demo',</span> <span class="pre">'attn-only-2l-shortformer-6b-big-lr',</span> <span class="pre">'attn-only-2l-induction-demo',</span> <span class="pre">'attn-only-demo'],</span> <span class="pre">'NeelNanda/Attn_Only_1L512W_C4_Code':</span> <span class="pre">['attn-only-1l',</span> <span class="pre">'attn-only-1l-new',</span> <span class="pre">'attn-only-1l-c4-code'],</span> <span class="pre">'NeelNanda/Attn_Only_2L512W_C4_Code':</span> <span class="pre">['attn-only-2l',</span> <span class="pre">'attn-only-2l-new',</span> <span class="pre">'attn-only-2l-c4-code'],</span> <span class="pre">'NeelNanda/Attn_Only_3L512W_C4_Code':</span> <span class="pre">['attn-only-3l',</span> <span class="pre">'attn-only-3l-new',</span> <span class="pre">'attn-only-3l-c4-code'],</span> <span class="pre">'NeelNanda/Attn_Only_4L512W_C4_Code':</span> <span class="pre">['attn-only-4l',</span> <span class="pre">'attn-only-4l-new',</span> <span class="pre">'attn-only-4l-c4-code'],</span> <span class="pre">'NeelNanda/GELU_1L512W_C4_Code':</span> <span class="pre">['gelu-1l',</span> <span class="pre">'gelu-1l-new',</span> <span class="pre">'gelu-1l-c4-code'],</span> <span class="pre">'NeelNanda/GELU_2L512W_C4_Code':</span> <span class="pre">['gelu-2l',</span> <span class="pre">'gelu-2l-new',</span> <span class="pre">'gelu-2l-c4-code'],</span> <span class="pre">'NeelNanda/GELU_3L512W_C4_Code':</span> <span class="pre">['gelu-3l',</span> <span class="pre">'gelu-3l-new',</span> <span class="pre">'gelu-3l-c4-code'],</span> <span class="pre">'NeelNanda/GELU_4L512W_C4_Code':</span> <span class="pre">['gelu-4l',</span> <span class="pre">'gelu-4l-new',</span> <span class="pre">'gelu-4l-c4-code'],</span> <span class="pre">'NeelNanda/SoLU_10L1280W_C4_Code':</span> <span class="pre">['solu-10l',</span> <span class="pre">'solu-10l-new',</span> <span class="pre">'solu-10l-c4-code'],</span> <span class="pre">'NeelNanda/SoLU_10L_v22_old':</span> <span class="pre">['solu-10l-pile',</span> <span class="pre">'solu-10l-old'],</span> <span class="pre">'NeelNanda/SoLU_12L1536W_C4_Code':</span> <span class="pre">['solu-12l',</span> <span class="pre">'solu-12l-new',</span> <span class="pre">'solu-12l-c4-code'],</span> <span class="pre">'NeelNanda/SoLU_12L_v23_old':</span> <span class="pre">['solu-12l-pile',</span> <span class="pre">'solu-12l-old'],</span> <span class="pre">'NeelNanda/SoLU_1L512W_C4_Code':</span> <span class="pre">['solu-1l',</span> <span class="pre">'solu-1l-new',</span> <span class="pre">'solu-1l-c4-code'],</span> <span class="pre">'NeelNanda/SoLU_1L512W_Wiki_Finetune':</span> <span class="pre">['solu-1l-wiki',</span> <span class="pre">'solu-1l-wiki-finetune',</span> <span class="pre">'solu-1l-finetune'],</span> <span class="pre">'NeelNanda/SoLU_1L_v9_old':</span> <span class="pre">['solu-1l-pile',</span> <span class="pre">'solu-1l-old'],</span> <span class="pre">'NeelNanda/SoLU_2L512W_C4_Code':</span> <span class="pre">['solu-2l',</span> <span class="pre">'solu-2l-new',</span> <span class="pre">'solu-2l-c4-code'],</span> <span class="pre">'NeelNanda/SoLU_2L_v10_old':</span> <span class="pre">['solu-2l-pile',</span> <span class="pre">'solu-2l-old'],</span> <span class="pre">'NeelNanda/SoLU_3L512W_C4_Code':</span> <span class="pre">['solu-3l',</span> <span class="pre">'solu-3l-new',</span> <span class="pre">'solu-3l-c4-code'],</span> <span class="pre">'NeelNanda/SoLU_4L512W_C4_Code':</span> <span class="pre">['solu-4l',</span> <span class="pre">'solu-4l-new',</span> <span class="pre">'solu-4l-c4-code'],</span> <span class="pre">'NeelNanda/SoLU_4L512W_Wiki_Finetune':</span> <span class="pre">['solu-4l-wiki',</span> <span class="pre">'solu-4l-wiki-finetune',</span> <span class="pre">'solu-4l-finetune'],</span> <span class="pre">'NeelNanda/SoLU_4L_v11_old':</span> <span class="pre">['solu-4l-pile',</span> <span class="pre">'solu-4l-old'],</span> <span class="pre">'NeelNanda/SoLU_6L768W_C4_Code':</span> <span class="pre">['solu-6l',</span> <span class="pre">'solu-6l-new',</span> <span class="pre">'solu-6l-c4-code'],</span> <span class="pre">'NeelNanda/SoLU_6L_v13_old':</span> <span class="pre">['solu-6l-pile',</span> <span class="pre">'solu-6l-old'],</span> <span class="pre">'NeelNanda/SoLU_8L1024W_C4_Code':</span> <span class="pre">['solu-8l',</span> <span class="pre">'solu-8l-new',</span> <span class="pre">'solu-8l-c4-code'],</span> <span class="pre">'NeelNanda/SoLU_8L_v21_old':</span> <span class="pre">['solu-8l-pile',</span> <span class="pre">'solu-8l-old'],</span> <span class="pre">'bigcode/santacoder':</span> <span class="pre">['santacoder'],</span> <span class="pre">'distilgpt2':</span> <span class="pre">['distillgpt2',</span> <span class="pre">'distill-gpt2',</span> <span class="pre">'distil-gpt2',</span> <span class="pre">'gpt2-xs'],</span> <span class="pre">'facebook/opt-1.3b':</span> <span class="pre">['opt-1.3b',</span> <span class="pre">'opt-medium'],</span> <span class="pre">'facebook/opt-125m':</span> <span class="pre">['opt-125m',</span> <span class="pre">'opt-small',</span> <span class="pre">'opt'],</span> <span class="pre">'facebook/opt-13b':</span> <span class="pre">['opt-13b',</span> <span class="pre">'opt-xxl'],</span> <span class="pre">'facebook/opt-2.7b':</span> <span class="pre">['opt-2.7b',</span> <span class="pre">'opt-large'],</span> <span class="pre">'facebook/opt-30b':</span> <span class="pre">['opt-30b',</span> <span class="pre">'opt-xxxl'],</span> <span class="pre">'facebook/opt-6.7b':</span> <span class="pre">['opt-6.7b',</span> <span class="pre">'opt-xl'],</span> <span class="pre">'facebook/opt-66b':</span> <span class="pre">['opt-66b',</span> <span class="pre">'opt-xxxxl'],</span> <span class="pre">'gpt2':</span> <span class="pre">['gpt2-small'],</span> <span class="pre">'llama-13b-hf':</span> <span class="pre">['llama-13b'],</span> <span class="pre">'llama-30b-hf':</span> <span class="pre">['llama-30b'],</span> <span class="pre">'llama-65b-hf':</span> <span class="pre">['llama-65b'],</span> <span class="pre">'llama-7b-hf':</span> <span class="pre">['llama-7b'],</span> <span class="pre">'roneneldan/TinyStories-1Layer-21M':</span> <span class="pre">['tiny-stories-1L-21M'],</span> <span class="pre">'roneneldan/TinyStories-1M':</span> <span class="pre">['tiny-stories-1M'],</span> <span class="pre">'roneneldan/TinyStories-28M':</span> <span class="pre">['tiny-stories-28M'],</span> <span class="pre">'roneneldan/TinyStories-2Layers-33M':</span> <span class="pre">['tiny-stories-2L-33M'],</span> <span class="pre">'roneneldan/TinyStories-33M':</span> <span class="pre">['tiny-stories-33M'],</span> <span class="pre">'roneneldan/TinyStories-3M':</span> <span class="pre">['tiny-stories-3M'],</span> <span class="pre">'roneneldan/TinyStories-8M':</span> <span class="pre">['tiny-stories-8M'],</span> <span class="pre">'roneneldan/TinyStories-Instruct-1M':</span> <span class="pre">['tiny-stories-instruct-1M'],</span> <span class="pre">'roneneldan/TinyStories-Instruct-28M':</span> <span class="pre">['tiny-stories-instruct-28M'],</span> <span class="pre">'roneneldan/TinyStories-Instruct-2Layers-33M':</span> <span class="pre">['tiny-stories-instruct-2L-33M'],</span> <span class="pre">'roneneldan/TinyStories-Instruct-33M':</span> <span class="pre">['tiny-stories-instruct-33M'],</span> <span class="pre">'roneneldan/TinyStories-Instruct-3M':</span> <span class="pre">['tiny-stories-instruct-3M'],</span> <span class="pre">'roneneldan/TinyStories-Instruct-8M':</span> <span class="pre">['tiny-stories-instruct-8M'],</span> <span class="pre">'roneneldan/TinyStories-Instuct-1Layer-21M':</span> <span class="pre">['tiny-stories-instruct-1L-21M'],</span> <span class="pre">'stabilityai/stablelm-base-alpha-3b':</span> <span class="pre">['stablelm-base-alpha-3b',</span> <span class="pre">'stablelm-base-3b'],</span> <span class="pre">'stabilityai/stablelm-base-alpha-7b':</span> <span class="pre">['stablelm-base-alpha-7b',</span> <span class="pre">'stablelm-base-7b'],</span> <span class="pre">'stabilityai/stablelm-tuned-alpha-3b':</span> <span class="pre">['stablelm-tuned-alpha-3b',</span> <span class="pre">'stablelm-tuned-3b'],</span> <span class="pre">'stabilityai/stablelm-tuned-alpha-7b':</span> <span class="pre">['stablelm-tuned-alpha-7b',</span> <span class="pre">'stablelm-tuned-7b'],</span> <span class="pre">'stanford-crfm/alias-gpt2-small-x21':</span> <span class="pre">['stanford-gpt2-small-a',</span> <span class="pre">'alias-gpt2-small-x21',</span> <span class="pre">'gpt2-mistral-small-a',</span> <span class="pre">'gpt2-stanford-small-a'],</span> <span class="pre">'stanford-crfm/arwen-gpt2-medium-x21':</span> <span class="pre">['stanford-gpt2-medium-a',</span> <span class="pre">'arwen-gpt2-medium-x21',</span> <span class="pre">'gpt2-medium-small-a',</span> <span class="pre">'gpt2-stanford-medium-a'],</span> <span class="pre">'stanford-crfm/battlestar-gpt2-small-x49':</span> <span class="pre">['stanford-gpt2-small-b',</span> <span class="pre">'battlestar-gpt2-small-x49',</span> <span class="pre">'gpt2-mistral-small-b',</span> <span class="pre">'gpt2-mistral-small-b'],</span> <span class="pre">'stanford-crfm/beren-gpt2-medium-x49':</span> <span class="pre">['stanford-gpt2-medium-b',</span> <span class="pre">'beren-gpt2-medium-x49',</span> <span class="pre">'gpt2-medium-small-b',</span> <span class="pre">'gpt2-stanford-medium-b'],</span> <span class="pre">'stanford-crfm/caprica-gpt2-small-x81':</span> <span class="pre">['stanford-gpt2-small-c',</span> <span class="pre">'caprica-gpt2-small-x81',</span> <span class="pre">'gpt2-mistral-small-c',</span> <span class="pre">'gpt2-stanford-small-c'],</span> <span class="pre">'stanford-crfm/celebrimbor-gpt2-medium-x81':</span> <span class="pre">['stanford-gpt2-medium-c',</span> <span class="pre">'celebrimbor-gpt2-medium-x81',</span> <span class="pre">'gpt2-medium-small-c',</span> <span class="pre">'gpt2-medium-small-c'],</span> <span class="pre">'stanford-crfm/darkmatter-gpt2-small-x343':</span> <span class="pre">['stanford-gpt2-small-d',</span> <span class="pre">'darkmatter-gpt2-small-x343',</span> <span class="pre">'gpt2-mistral-small-d',</span> <span class="pre">'gpt2-mistral-small-d'],</span> <span class="pre">'stanford-crfm/durin-gpt2-medium-x343':</span> <span class="pre">['stanford-gpt2-medium-d',</span> <span class="pre">'durin-gpt2-medium-x343',</span> <span class="pre">'gpt2-medium-small-d',</span> <span class="pre">'gpt2-stanford-medium-d'],</span> <span class="pre">'stanford-crfm/eowyn-gpt2-medium-x777':</span> <span class="pre">['stanford-gpt2-medium-e',</span> <span class="pre">'eowyn-gpt2-medium-x777',</span> <span class="pre">'gpt2-medium-small-e',</span> <span class="pre">'gpt2-stanford-medium-e'],</span> <span class="pre">'stanford-crfm/expanse-gpt2-small-x777':</span> <span class="pre">['stanford-gpt2-small-e',</span> <span class="pre">'expanse-gpt2-small-x777',</span> <span class="pre">'gpt2-mistral-small-e',</span> <span class="pre">'gpt2-mistral-small-e']}</span></em><a class="headerlink" href="#transformer_lens.loading_from_pretrained.MODEL_ALIASES" title="Permalink to this definition">#</a></dt>
<dd><p>Model aliases for models on HuggingFace.</p>
</dd></dl>

<dl class="py data">
<dt class="sig sig-object py" id="transformer_lens.loading_from_pretrained.OFFICIAL_MODEL_NAMES">
<span class="sig-prename descclassname"><span class="pre">transformer_lens.loading_from_pretrained.</span></span><span class="sig-name descname"><span class="pre">OFFICIAL_MODEL_NAMES</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">['gpt2',</span> <span class="pre">'gpt2-medium',</span> <span class="pre">'gpt2-large',</span> <span class="pre">'gpt2-xl',</span> <span class="pre">'distilgpt2',</span> <span class="pre">'facebook/opt-125m',</span> <span class="pre">'facebook/opt-1.3b',</span> <span class="pre">'facebook/opt-2.7b',</span> <span class="pre">'facebook/opt-6.7b',</span> <span class="pre">'facebook/opt-13b',</span> <span class="pre">'facebook/opt-30b',</span> <span class="pre">'facebook/opt-66b',</span> <span class="pre">'EleutherAI/gpt-neo-125M',</span> <span class="pre">'EleutherAI/gpt-neo-1.3B',</span> <span class="pre">'EleutherAI/gpt-neo-2.7B',</span> <span class="pre">'EleutherAI/gpt-j-6B',</span> <span class="pre">'EleutherAI/gpt-neox-20b',</span> <span class="pre">'stanford-crfm/alias-gpt2-small-x21',</span> <span class="pre">'stanford-crfm/battlestar-gpt2-small-x49',</span> <span class="pre">'stanford-crfm/caprica-gpt2-small-x81',</span> <span class="pre">'stanford-crfm/darkmatter-gpt2-small-x343',</span> <span class="pre">'stanford-crfm/expanse-gpt2-small-x777',</span> <span class="pre">'stanford-crfm/arwen-gpt2-medium-x21',</span> <span class="pre">'stanford-crfm/beren-gpt2-medium-x49',</span> <span class="pre">'stanford-crfm/celebrimbor-gpt2-medium-x81',</span> <span class="pre">'stanford-crfm/durin-gpt2-medium-x343',</span> <span class="pre">'stanford-crfm/eowyn-gpt2-medium-x777',</span> <span class="pre">'EleutherAI/pythia-14m',</span> <span class="pre">'EleutherAI/pythia-31m',</span> <span class="pre">'EleutherAI/pythia-70m',</span> <span class="pre">'EleutherAI/pythia-160m',</span> <span class="pre">'EleutherAI/pythia-410m',</span> <span class="pre">'EleutherAI/pythia-1b',</span> <span class="pre">'EleutherAI/pythia-1.4b',</span> <span class="pre">'EleutherAI/pythia-2.8b',</span> <span class="pre">'EleutherAI/pythia-6.9b',</span> <span class="pre">'EleutherAI/pythia-12b',</span> <span class="pre">'EleutherAI/pythia-70m-deduped',</span> <span class="pre">'EleutherAI/pythia-160m-deduped',</span> <span class="pre">'EleutherAI/pythia-410m-deduped',</span> <span class="pre">'EleutherAI/pythia-1b-deduped',</span> <span class="pre">'EleutherAI/pythia-1.4b-deduped',</span> <span class="pre">'EleutherAI/pythia-2.8b-deduped',</span> <span class="pre">'EleutherAI/pythia-6.9b-deduped',</span> <span class="pre">'EleutherAI/pythia-12b-deduped',</span> <span class="pre">'EleutherAI/pythia-70m-v0',</span> <span class="pre">'EleutherAI/pythia-160m-v0',</span> <span class="pre">'EleutherAI/pythia-410m-v0',</span> <span class="pre">'EleutherAI/pythia-1b-v0',</span> <span class="pre">'EleutherAI/pythia-1.4b-v0',</span> <span class="pre">'EleutherAI/pythia-2.8b-v0',</span> <span class="pre">'EleutherAI/pythia-6.9b-v0',</span> <span class="pre">'EleutherAI/pythia-12b-v0',</span> <span class="pre">'EleutherAI/pythia-70m-deduped-v0',</span> <span class="pre">'EleutherAI/pythia-160m-deduped-v0',</span> <span class="pre">'EleutherAI/pythia-410m-deduped-v0',</span> <span class="pre">'EleutherAI/pythia-1b-deduped-v0',</span> <span class="pre">'EleutherAI/pythia-1.4b-deduped-v0',</span> <span class="pre">'EleutherAI/pythia-2.8b-deduped-v0',</span> <span class="pre">'EleutherAI/pythia-6.9b-deduped-v0',</span> <span class="pre">'EleutherAI/pythia-12b-deduped-v0',</span> <span class="pre">'EleutherAI/pythia-160m-seed1',</span> <span class="pre">'EleutherAI/pythia-160m-seed2',</span> <span class="pre">'EleutherAI/pythia-160m-seed3',</span> <span class="pre">'NeelNanda/SoLU_1L_v9_old',</span> <span class="pre">'NeelNanda/SoLU_2L_v10_old',</span> <span class="pre">'NeelNanda/SoLU_4L_v11_old',</span> <span class="pre">'NeelNanda/SoLU_6L_v13_old',</span> <span class="pre">'NeelNanda/SoLU_8L_v21_old',</span> <span class="pre">'NeelNanda/SoLU_10L_v22_old',</span> <span class="pre">'NeelNanda/SoLU_12L_v23_old',</span> <span class="pre">'NeelNanda/SoLU_1L512W_C4_Code',</span> <span class="pre">'NeelNanda/SoLU_2L512W_C4_Code',</span> <span class="pre">'NeelNanda/SoLU_3L512W_C4_Code',</span> <span class="pre">'NeelNanda/SoLU_4L512W_C4_Code',</span> <span class="pre">'NeelNanda/SoLU_6L768W_C4_Code',</span> <span class="pre">'NeelNanda/SoLU_8L1024W_C4_Code',</span> <span class="pre">'NeelNanda/SoLU_10L1280W_C4_Code',</span> <span class="pre">'NeelNanda/SoLU_12L1536W_C4_Code',</span> <span class="pre">'NeelNanda/GELU_1L512W_C4_Code',</span> <span class="pre">'NeelNanda/GELU_2L512W_C4_Code',</span> <span class="pre">'NeelNanda/GELU_3L512W_C4_Code',</span> <span class="pre">'NeelNanda/GELU_4L512W_C4_Code',</span> <span class="pre">'NeelNanda/Attn_Only_1L512W_C4_Code',</span> <span class="pre">'NeelNanda/Attn_Only_2L512W_C4_Code',</span> <span class="pre">'NeelNanda/Attn_Only_3L512W_C4_Code',</span> <span class="pre">'NeelNanda/Attn_Only_4L512W_C4_Code',</span> <span class="pre">'NeelNanda/Attn-Only-2L512W-Shortformer-6B-big-lr',</span> <span class="pre">'NeelNanda/SoLU_1L512W_Wiki_Finetune',</span> <span class="pre">'NeelNanda/SoLU_4L512W_Wiki_Finetune',</span> <span class="pre">'ArthurConmy/redwood_attn_2l',</span> <span class="pre">'llama-7b-hf',</span> <span class="pre">'llama-13b-hf',</span> <span class="pre">'llama-30b-hf',</span> <span class="pre">'llama-65b-hf',</span> <span class="pre">'Llama-2-7b-hf',</span> <span class="pre">'Llama-2-7b-chat-hf',</span> <span class="pre">'Llama-2-13b-hf',</span> <span class="pre">'Llama-2-13b-chat-hf',</span> <span class="pre">'Baidicoot/Othello-GPT-Transformer-Lens',</span> <span class="pre">'bert-base-cased',</span> <span class="pre">'roneneldan/TinyStories-1M',</span> <span class="pre">'roneneldan/TinyStories-3M',</span> <span class="pre">'roneneldan/TinyStories-8M',</span> <span class="pre">'roneneldan/TinyStories-28M',</span> <span class="pre">'roneneldan/TinyStories-33M',</span> <span class="pre">'roneneldan/TinyStories-Instruct-1M',</span> <span class="pre">'roneneldan/TinyStories-Instruct-3M',</span> <span class="pre">'roneneldan/TinyStories-Instruct-8M',</span> <span class="pre">'roneneldan/TinyStories-Instruct-28M',</span> <span class="pre">'roneneldan/TinyStories-Instruct-33M',</span> <span class="pre">'roneneldan/TinyStories-1Layer-21M',</span> <span class="pre">'roneneldan/TinyStories-2Layers-33M',</span> <span class="pre">'roneneldan/TinyStories-Instuct-1Layer-21M',</span> <span class="pre">'roneneldan/TinyStories-Instruct-2Layers-33M',</span> <span class="pre">'stabilityai/stablelm-base-alpha-3b',</span> <span class="pre">'stabilityai/stablelm-base-alpha-7b',</span> <span class="pre">'stabilityai/stablelm-tuned-alpha-3b',</span> <span class="pre">'stabilityai/stablelm-tuned-alpha-7b',</span> <span class="pre">'bigcode/santacoder']</span></em><a class="headerlink" href="#transformer_lens.loading_from_pretrained.OFFICIAL_MODEL_NAMES" title="Permalink to this definition">#</a></dt>
<dd><p>Official model names for models on HuggingFace.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformer_lens.loading_from_pretrained.convert_coder_weights">
<span class="sig-prename descclassname"><span class="pre">transformer_lens.loading_from_pretrained.</span></span><span class="sig-name descname"><span class="pre">convert_coder_weights</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="transformer_lens.HookedTransformerConfig.html#transformer_lens.HookedTransformerConfig.HookedTransformerConfig" title="transformer_lens.HookedTransformerConfig.HookedTransformerConfig"><span class="pre">HookedTransformerConfig</span></a></span></em><span class="sig-paren">)</span><a class="headerlink" href="#transformer_lens.loading_from_pretrained.convert_coder_weights" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformer_lens.loading_from_pretrained.get_checkpoint_labels">
<span class="sig-prename descclassname"><span class="pre">transformer_lens.loading_from_pretrained.</span></span><span class="sig-name descname"><span class="pre">get_checkpoint_labels</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#transformer_lens.loading_from_pretrained.get_checkpoint_labels" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the checkpoint labels for a given model, and the label_type
(step or token). Raises an error for models that are not checkpointed.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformer_lens.loading_from_pretrained.get_num_params_of_pretrained">
<span class="sig-prename descclassname"><span class="pre">transformer_lens.loading_from_pretrained.</span></span><span class="sig-name descname"><span class="pre">get_num_params_of_pretrained</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#transformer_lens.loading_from_pretrained.get_num_params_of_pretrained" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the number of parameters of a pretrained model, used to filter to only run code for sufficiently small models.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="transformer_lens.loading_from_pretrained.get_pretrained_model_config">
<span class="sig-prename descclassname"><span class="pre">transformer_lens.loading_from_pretrained.</span></span><span class="sig-name descname"><span class="pre">get_pretrained_model_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">checkpoint_index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">checkpoint_value</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fold_ln</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_devices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_prepend_bos</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dtype</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">torch.float32</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#transformer_lens.loading_from_pretrained.get_pretrained_model_config" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the pretrained model config as an HookedTransformerConfig object.</p>
<p>There are two types of pretrained models: HuggingFace models (where
AutoModel and AutoConfig work), and models trained by me (NeelNanda) which
arent as integrated with HuggingFace infrastructure.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_name</strong>  The name of the model. This can be either the official
HuggingFace model name, or the name of a model trained by me
(NeelNanda).</p></li>
<li><p><strong>checkpoint_index</strong> (<em>int</em><em>, </em><em>optional</em>)  If loading from a
checkpoint, the index of the checkpoint to load. Defaults to None.</p></li>
<li><p><strong>checkpoint_value</strong> (<em>int</em><em>, </em><em>optional</em>)  If loading from a checkpoint, the</p></li>
<li><p><strong>of</strong> (<em>value</em>)  the checkpoint to load, ie the step or token number (each model has
checkpoints labelled with exactly one of these). Defaults to None.</p></li>
<li><p><strong>fold_ln</strong> (<em>bool</em><em>, </em><em>optional</em>)  Whether to fold the layer norm into the
subsequent linear layers (see HookedTransformer.fold_layer_norm for
details). Defaults to False.</p></li>
<li><p><strong>device</strong> (<em>str</em><em>, </em><em>optional</em>)  The device to load the model onto. By
default will load to CUDA if available, else CPU.</p></li>
<li><p><strong>n_devices</strong> (<em>int</em><em>, </em><em>optional</em>)  The number of devices to split the model across. Defaults to 1.</p></li>
<li><p><strong>default_prepend_bos</strong> (<em>bool</em><em>, </em><em>optional</em>)  Default behavior of whether to prepend the BOS token when the
methods of HookedTransformer process input text to tokenize (only when input is a string).
Defaults to True - even for models not explicitly trained with this, heads often use the
first position as a resting position and accordingly lose information from the first token,
so this empirically seems to give better results. To change the default behavior to False, pass in
default_prepend_bos=False. Note that you can also locally override the default behavior by passing
in prepend_bos=True/False when you call a method that processes the input string.</p></li>
<li><p><strong>dtype</strong> (<em>torch.dtype</em><em>, </em><em>optional</em>)  The dtype to load the TransformerLens model in.</p></li>
<li><p><strong>kwargs</strong>  Other optional arguments passed to HuggingFaces from_pretrained.
Also given to other HuggingFace functions when compatible.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="transformer_lens.past_key_value_caching.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">transformer_lens.past_key_value_caching</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="transformer_lens.hook_points.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">transformer_lens.hook_points</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023, Neel Nanda
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">transformer_lens.loading_from_pretrained</a><ul>
<li><a class="reference internal" href="#transformer_lens.loading_from_pretrained.Config"><code class="docutils literal notranslate"><span class="pre">Config</span></code></a><ul>
<li><a class="reference internal" href="#transformer_lens.loading_from_pretrained.Config.d_head"><code class="docutils literal notranslate"><span class="pre">Config.d_head</span></code></a></li>
<li><a class="reference internal" href="#transformer_lens.loading_from_pretrained.Config.d_mlp"><code class="docutils literal notranslate"><span class="pre">Config.d_mlp</span></code></a></li>
<li><a class="reference internal" href="#transformer_lens.loading_from_pretrained.Config.d_model"><code class="docutils literal notranslate"><span class="pre">Config.d_model</span></code></a></li>
<li><a class="reference internal" href="#transformer_lens.loading_from_pretrained.Config.d_vocab"><code class="docutils literal notranslate"><span class="pre">Config.d_vocab</span></code></a></li>
<li><a class="reference internal" href="#transformer_lens.loading_from_pretrained.Config.debug"><code class="docutils literal notranslate"><span class="pre">Config.debug</span></code></a></li>
<li><a class="reference internal" href="#transformer_lens.loading_from_pretrained.Config.init_range"><code class="docutils literal notranslate"><span class="pre">Config.init_range</span></code></a></li>
<li><a class="reference internal" href="#transformer_lens.loading_from_pretrained.Config.layer_norm_eps"><code class="docutils literal notranslate"><span class="pre">Config.layer_norm_eps</span></code></a></li>
<li><a class="reference internal" href="#transformer_lens.loading_from_pretrained.Config.n_ctx"><code class="docutils literal notranslate"><span class="pre">Config.n_ctx</span></code></a></li>
<li><a class="reference internal" href="#transformer_lens.loading_from_pretrained.Config.n_heads"><code class="docutils literal notranslate"><span class="pre">Config.n_heads</span></code></a></li>
<li><a class="reference internal" href="#transformer_lens.loading_from_pretrained.Config.n_layers"><code class="docutils literal notranslate"><span class="pre">Config.n_layers</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#transformer_lens.loading_from_pretrained.MODEL_ALIASES"><code class="docutils literal notranslate"><span class="pre">MODEL_ALIASES</span></code></a></li>
<li><a class="reference internal" href="#transformer_lens.loading_from_pretrained.OFFICIAL_MODEL_NAMES"><code class="docutils literal notranslate"><span class="pre">OFFICIAL_MODEL_NAMES</span></code></a></li>
<li><a class="reference internal" href="#transformer_lens.loading_from_pretrained.convert_coder_weights"><code class="docutils literal notranslate"><span class="pre">convert_coder_weights()</span></code></a></li>
<li><a class="reference internal" href="#transformer_lens.loading_from_pretrained.get_checkpoint_labels"><code class="docutils literal notranslate"><span class="pre">get_checkpoint_labels()</span></code></a></li>
<li><a class="reference internal" href="#transformer_lens.loading_from_pretrained.get_num_params_of_pretrained"><code class="docutils literal notranslate"><span class="pre">get_num_params_of_pretrained()</span></code></a></li>
<li><a class="reference internal" href="#transformer_lens.loading_from_pretrained.get_pretrained_model_config"><code class="docutils literal notranslate"><span class="pre">get_pretrained_model_config()</span></code></a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/scripts/furo.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    </body>
</html>