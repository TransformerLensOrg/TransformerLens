{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Lexoscope\n",
    "\n",
    "There's a surprisingly rich ecosystem of easy ways to create interactive graphics, especially for ML systems. If you're trying to do mechanistic interpretability, the ability to do web dev and to both visualize data and interact with it seems high value! \n",
    "\n",
    "This is a demo of how you can combine EasyTransformer and [Gradio](https://gradio.app/) to create an interactive Lexoscope - a visualization of a neuron's activations on text that will dynamically update as you edit the text. I don't particularly claim that this code is any *good*, but the goal is to illustrate what quickly hacking together a custom visualisation (while knowing fuck all about web dev, like me) can look like! (And as such, I try to explain the basic web dev concepts I use)\n",
    "\n",
    "Note that you'll need to run the code yourself to get the interactive interface, so the cell at the bottom will be blank at first!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running as a Jupyter notebook - intended for development only!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "  print(\"Running as a Colab notebook\")\n",
    "\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "  print(\"Running as a Jupyter notebook - intended for development only!\")\n",
    "  from IPython import get_ipython\n",
    "  ipython = get_ipython()\n",
    "  # Code to automatically update the EasyTransformer code as its edited without restarting the kernel\n",
    "  ipython.magic(\"load_ext autoreload\")\n",
    "  ipython.magic(\"autoreload 2\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if IN_COLAB:\n",
    "    os.system('pip install git+https://github.com/neelnanda-io/Easy-Transformer.git')\n",
    "    os.system('pip install gradio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from easy_transformer import EasyTransformer\n",
    "from easy_transformer.utils import to_numpy\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Model Activations\n",
    "\n",
    "We first write some code using EasyTransformer's cache to extract the neuron activations on a given layer and neuron, for a given text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-small\"\n",
    "model = EasyTransformer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neuron_acts(text, layer, neuron_index):\n",
    "    # Hacky way to get out state from a single hook - we have a single element list and edit that list within the hook.\n",
    "    cache = {}\n",
    "    def caching_hook(act, hook):\n",
    "        cache[\"activation\"] = act[0, :, neuron_index]\n",
    "    model.run_with_hooks(text, fwd_hooks=[(f\"blocks.{layer}.mlp.hook_post\", caching_hook)])\n",
    "    return to_numpy(cache[\"activation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run this function and verify that it gives vaguely sensible outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', 'hello', ' world']\n",
      "[-0.16982502  0.01151305 -0.05436837]\n"
     ]
    }
   ],
   "source": [
    "default_layer = 4\n",
    "default_neuron_index = 12\n",
    "default_text = \"hello world\"\n",
    "print(model.to_str_tokens(default_text))\n",
    "print(get_neuron_acts(default_text, default_layer, default_neuron_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Model Activations\n",
    "\n",
    "We now write some code to visualize the neuron activations on some text - we're going to hack something together which just does some string processing to make an HTML string, with each token element colored according to the intensity neuron activation. We normalize the neuron activations so they all lie in [0, 1]. You can do much better, but this is a useful proof of concept of what \"just hack stuff together\" can look like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displayed HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style> \n",
       "    span.token {\n",
       "        border: 1px solid rgb(123, 123, 123)\n",
       "        } \n",
       "    </style><h4>Layer: <b>4</b>. Neuron Index: <b>12</b></h4><h4>Max Range: <b>10.0000</b>. Min Range: <b>-0.1698</b></h4><h4>Custom Range Set. Max Act: <b>0.0743</b>. Min Act: <b>-0.1698</b></h4><span class='token' style='background-color:rgb(240, 240.0, 240.0)' ><|endoftext|></span><span class='token' style='background-color:rgb(240, 234.14020192623138, 234.14020192623138)' >Hello</span><span class='token' style='background-color:rgb(240, 238.05408704280853, 238.05408704280853)' >,</span><span class='token' style='background-color:rgb(240, 238.6111822128296, 238.6111822128296)' > my</span><span class='token' style='background-color:rgb(240, 238.2863974571228, 238.2863974571228)' > name</span><span class='token' style='background-color:rgb(240, 236.18733036518097, 236.18733036518097)' > is</span><span class='token' style='background-color:rgb(240, 239.91767477989197, 239.91767477989197)' > not</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML String:\n",
      "<style> \n",
      "    span.token {\n",
      "        border: 1px solid rgb(123, 123, 123)\n",
      "        } \n",
      "    </style><h4>Layer: <b>4</b>. Neuron Index: <b>12</b></h4><h4>Max Range: <b>10.0000</b>. Min Range: <b>-0.1698</b></h4><h4>Custom Range Set. Max Act: <b>0.0743</b>. Min Act: <b>-0.1698</b></h4><span class='token' style='background-color:rgb(240, 240.0, 240.0)' ><|endoftext|></span><span class='token' style='background-color:rgb(240, 234.14020192623138, 234.14020192623138)' >Hello</span><span class='token' style='background-color:rgb(240, 238.05408704280853, 238.05408704280853)' >,</span><span class='token' style='background-color:rgb(240, 238.6111822128296, 238.6111822128296)' > my</span><span class='token' style='background-color:rgb(240, 238.2863974571228, 238.2863974571228)' > name</span><span class='token' style='background-color:rgb(240, 236.18733036518097, 236.18733036518097)' > is</span><span class='token' style='background-color:rgb(240, 239.91767477989197, 239.91767477989197)' > not</span>\n"
     ]
    }
   ],
   "source": [
    "# This is some CSS (tells us what style )to give each token a thin gray border, to make it easy to see token separation\n",
    "style_string = \"\"\"<style> \n",
    "    span.token {\n",
    "        border: 1px solid rgb(123, 123, 123)\n",
    "        } \n",
    "    </style>\"\"\"\n",
    "\n",
    "def calculate_color(val, max_val, min_val):\n",
    "    # Hacky code that takes in a value val in range [min_val, max_val], normalizes it to [0, 1] and returns a color which interpolates between slightly off-white and red (0 = white, 1 = red)\n",
    "    # We return a string of the form \"rgb(240, 240, 240)\" which is a color CSS knows \n",
    "    normalized_val = (val - min_val)/max_val\n",
    "    return f\"rgb(240, {240*(1-normalized_val)}, {240*(1-normalized_val)})\"\n",
    "\n",
    "def shitty_neuron_vis(text, layer, neuron_index, max_val=None, min_val=None):\n",
    "    \"\"\" \n",
    "    text: The text to visualize\n",
    "    layer: The layer index\n",
    "    neuron_index: The neuron index\n",
    "    max_val: The top end of our activation range, defaults to the maximum activation\n",
    "    min_val: The top end of our activation range, defaults to the minimum activation\n",
    "\n",
    "    Returns a string of HTML that displays the text with each token colored according to its activation\n",
    "\n",
    "    Note: It's useful to be able to input a fixed max_val and min_val, because otherwise the colors will change as you edit the text, which is annoying.\n",
    "    \"\"\"\n",
    "    if layer is None:\n",
    "        return \"Please select a Layer\"\n",
    "    if neuron_index is None:\n",
    "        return \"Please select a Neuron\"\n",
    "    acts = get_neuron_acts(text, layer, neuron_index)\n",
    "    act_max = acts.max()\n",
    "    act_min = acts.min()\n",
    "    # Defaults to the max and min of the activations\n",
    "    if max_val is None:\n",
    "        max_val = act_max\n",
    "    if min_val is None:\n",
    "        min_val = act_min\n",
    "    # We want to make a list of HTML strings to concatenate into our final HTML string\n",
    "    # We first add the style to make each token element have a nice border\n",
    "    htmls = [style_string]\n",
    "    # We then add some text to tell us what layer and neuron we're looking at - we're just dealing with strings and can use f-strings as normal\n",
    "    # h4 means \"small heading\"\n",
    "    htmls.append(f\"<h4>Layer: <b>{layer}</b>. Neuron Index: <b>{neuron_index}</b></h4>\")\n",
    "    # We then add a line telling us the limits of our range\n",
    "    htmls.append(f\"<h4>Max Range: <b>{max_val:.4f}</b>. Min Range: <b>{min_val:.4f}</b></h4>\")\n",
    "    # If we added a custom range, print a line telling us the range of our activations too.\n",
    "    if act_max!=max_val or act_min!=min_val:\n",
    "        htmls.append(f\"<h4>Custom Range Set. Max Act: <b>{act_max:.4f}</b>. Min Act: <b>{act_min:.4f}</b></h4>\")\n",
    "    # Convert the text to a list of tokens\n",
    "    str_tokens = model.to_str_tokens(text)\n",
    "    for tok, act in zip(str_tokens, acts):\n",
    "        # A span is an HTML element that lets us style a part of a string (and remains on the same line by default)\n",
    "        # We set the background color of the span to be the color we calculated from the activation\n",
    "        # We set the contents of the span to be the token\n",
    "        htmls.append(f\"<span class='token' style='background-color:{calculate_color(act, max_val, min_val)}' >{tok}</span>\")\n",
    "    \n",
    "    return \"\".join(htmls)\n",
    "\n",
    "# The function outputs a string of HTML\n",
    "demo_html_string = shitty_neuron_vis(\"Hello, my name is not\", default_layer, default_neuron_index, 10.)\n",
    "\n",
    "# IPython lets us display HTML\n",
    "print(\"Displayed HTML\")\n",
    "display(HTML(demo_html_string))\n",
    "\n",
    "# We can also print the string directly\n",
    "print(\"HTML String:\")\n",
    "print(demo_html_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Interactive UI\n",
    "\n",
    "We now put all these together to create an interactive visualization in Gradio! \n",
    "\n",
    "The internal format is that there's a bunch of elements - Textboxes, Numbers, etc which the user can interact with and which return strings and numbers. And we can also define output elements that just display things - in this case, one which takes in an arbitrary HTML string. We call `input.change(update_function, inputs, output)` - this says \"if that input element changes, run the update function on the value of each of the elements in `inputs` and set the value of `output` to the output of the function\". As a bonus, this gives us live interactivity!\n",
    "\n",
    "This is also more complex than a typical Gradio intro example - I wanted to use custom HTML to display the nice colours, which made things much messier! Normally you could just make `out` into another Textbox and pass it a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `with gr.Blocks() as demo:` syntax just creates a variable called demo containing all these components\n",
    "with gr.Blocks() as demo:\n",
    "    gr.HTML(value=f\"Hacky Interactive Lexoscope for {model_name}\")\n",
    "    # The input elements\n",
    "    text = gr.Textbox(label=\"Text\", value=\"Hello World\")\n",
    "    # Precision=0 makes it an int, otherwise it's a float\n",
    "    # Value sets the initial default value\n",
    "    layer = gr.Number(label=\"Layer\", value=default_layer, precision=0)\n",
    "    neuron_index = gr.Number(label=\"Neuron Index\", value=default_neuron_index, precision=0)\n",
    "    # If empty, these two map to None\n",
    "    max_val = gr.Number(label=\"Max Value\", value=1.0)\n",
    "    min_val = gr.Number(label=\"Min Value\", value=0.0)\n",
    "    inputs = [text, layer, neuron_index, max_val, min_val]\n",
    "\n",
    "    # The output element\n",
    "    out = gr.HTML(label=\"Neuron Acts\", value=\"Start typing text!\")\n",
    "    for inp in inputs:\n",
    "        inp.change(shitty_neuron_vis, inputs, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now launch our demo element, and we're done! The setting share=True even gives you a public link to the demo (though it just redirects to the backend run by this notebook, and will go away once you turn the notebook off!) Sharing makes it much slower, and can be turned off if you aren't in a colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7880\n",
      "Running on public URL: https://25354.gradio.app\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting, check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://25354.gradio.app\" width=\"900\" height=\"1000\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x7fbfa47bff50>,\n",
       " 'http://127.0.0.1:7880/',\n",
       " 'https://25354.gradio.app')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo.launch(share=True, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you set share=True, you even get a link you can share with people! (Though it's much slower to load and that just redirects them to something hosted in your colab, so it'll go away when you turn the colab off!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rerunning server... use `close()` to stop if you need to change `launch()` parameters.\n",
      "----\n",
      "Running on local URL:  http://127.0.0.1:7880\n",
      "Running on public URL: https://25354.gradio.app\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting, check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://25354.gradio.app\" width=\"900\" height=\"1000\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x7fbfa47bff50>,\n",
       " 'http://127.0.0.1:7880/',\n",
       " 'https://25354.gradio.app')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo.launch(share=True, height=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
