Search.setIndex({"docnames": ["content/citation", "content/contributing", "content/gallery", "content/getting_started", "content/getting_started_mech_interp", "content/tutorials", "generated/code/modules", "generated/code/transformer_lens", "generated/code/transformer_lens.ActivationCache", "generated/code/transformer_lens.FactoredMatrix", "generated/code/transformer_lens.HookedEncoder", "generated/code/transformer_lens.HookedTransformer", "generated/code/transformer_lens.HookedTransformerConfig", "generated/code/transformer_lens.SVDInterpreter", "generated/code/transformer_lens.components", "generated/code/transformer_lens.evals", "generated/code/transformer_lens.head_detector", "generated/code/transformer_lens.hook_points", "generated/code/transformer_lens.loading_from_pretrained", "generated/code/transformer_lens.past_key_value_caching", "generated/code/transformer_lens.patching", "generated/code/transformer_lens.train", "generated/code/transformer_lens.utilities", "generated/code/transformer_lens.utilities.devices", "generated/code/transformer_lens.utils", "generated/demos/Exploratory_Analysis_Demo", "generated/demos/Main_Demo", "generated/model_properties_table", "index"], "filenames": ["content/citation.md", "content/contributing.md", "content/gallery.md", "content/getting_started.md", "content/getting_started_mech_interp.md", "content/tutorials.md", "generated/code/modules.rst", "generated/code/transformer_lens.rst", "generated/code/transformer_lens.ActivationCache.rst", "generated/code/transformer_lens.FactoredMatrix.rst", "generated/code/transformer_lens.HookedEncoder.rst", "generated/code/transformer_lens.HookedTransformer.rst", "generated/code/transformer_lens.HookedTransformerConfig.rst", "generated/code/transformer_lens.SVDInterpreter.rst", "generated/code/transformer_lens.components.rst", "generated/code/transformer_lens.evals.rst", "generated/code/transformer_lens.head_detector.rst", "generated/code/transformer_lens.hook_points.rst", "generated/code/transformer_lens.loading_from_pretrained.rst", "generated/code/transformer_lens.past_key_value_caching.rst", "generated/code/transformer_lens.patching.rst", "generated/code/transformer_lens.train.rst", "generated/code/transformer_lens.utilities.rst", "generated/code/transformer_lens.utilities.devices.rst", "generated/code/transformer_lens.utils.rst", "generated/demos/Exploratory_Analysis_Demo.ipynb", "generated/demos/Main_Demo.ipynb", "generated/model_properties_table.md", "index.md"], "titles": ["Citation", "Contributing", "Gallery", "Getting Started", "Getting Started in Mechanistic Interpretability", "Tutorials", "Transformer Lens API", "transformer_lens", "transformer_lens.ActivationCache", "transformer_lens.FactoredMatrix", "transformer_lens.HookedEncoder", "transformer_lens.HookedTransformer", "transformer_lens.HookedTransformerConfig", "transformer_lens.SVDInterpreter", "transformer_lens.components", "transformer_lens.evals", "transformer_lens.head_detector", "transformer_lens.hook_points", "transformer_lens.loading_from_pretrained", "transformer_lens.past_key_value_caching", "transformer_lens.patching", "transformer_lens.train", "transformer_lens.utilities", "transformer_lens.utilities.devices", "transformer_lens.utils", "Exploratory Analysis Demo", "Transformer Lens Main Demo Notebook", "Model Properties Table", "TransformerLens"], "terms": {"pleas": [0, 1, 3, 4, 26], "cite": 0, "thi": [0, 1, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 28], "librari": [0, 2, 3, 4, 5, 8, 15, 24, 25], "misc": 0, "nanda2022transformerlen": 0, "titl": [0, 1, 25, 26], "transformerlen": [0, 2, 3, 4, 5, 8, 11, 14, 18, 24, 25, 26], "author": [0, 25], "neel": [0, 2, 4, 5, 11, 13, 26], "nanda": [0, 2, 4, 11, 26], "joseph": 0, "bloom": [0, 14, 18, 27], "year": 0, "2022": [0, 24], "howpublish": 0, "url": 0, "http": [0, 1, 3, 5, 8, 11, 12, 14, 15, 16, 20, 24, 25, 26], "github": [0, 1, 3, 5, 11], "com": [0, 3, 5, 8, 11, 25, 26], "neelnanda": [0, 3, 5, 11, 18], "io": [0, 3, 5, 15, 16, 25, 26], "For": [1, 8, 10, 11, 14, 16, 24, 25], "one": [1, 3, 4, 8, 10, 11, 12, 14, 16, 17, 18, 19, 20, 24, 25, 26, 28], "click": [1, 26], "your": [1, 5, 11, 12, 16, 17, 25, 26], "develop": [1, 5, 25, 26], "environ": 1, "project": [1, 5, 8, 21, 25], "includ": [1, 4, 5, 8, 10, 11, 12, 15, 16, 17, 25], "It": [1, 3, 5, 8, 10, 11, 12, 14, 15, 17, 20, 24, 25, 26, 28], "can": [1, 2, 3, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 24, 25, 26, 28], "us": [1, 2, 3, 5, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28], "local": [1, 11, 12, 14, 18, 24, 26], "v": [1, 8, 11, 12, 20, 25, 26], "code": [1, 4, 8, 11, 12, 14, 15, 16, 17, 18, 24, 25, 26], "codespac": 1, "poetri": 1, "packag": 1, "manag": [1, 8, 11, 17, 24], "instal": [1, 25, 26], "follow": [1, 8, 11, 24, 26, 28], "also": [1, 5, 8, 10, 11, 12, 13, 16, 17, 18, 23, 24, 25, 26], "virtual": 1, "config": [1, 11, 12, 14, 18, 20, 21], "virtualenv": 1, "true": [1, 8, 10, 11, 12, 15, 16, 17, 18, 20, 23, 24, 25, 26], "dev": 1, "doc": [1, 6, 8, 11, 26], "jupyt": 1, "If": [1, 3, 6, 8, 10, 11, 12, 14, 16, 17, 18, 20, 23, 24, 25, 26], "ad": [1, 5, 11, 12, 14, 17, 25, 26], "featur": [1, 3, 5, 10, 13, 20, 24, 25, 28], "add": [1, 11, 12, 14, 17, 19, 24, 25, 26, 28], "unit": 1, "you": [1, 3, 4, 5, 8, 10, 11, 12, 13, 15, 16, 17, 18, 24, 25, 26, 28], "need": [1, 3, 8, 11, 12, 14, 17, 24, 25, 26, 28], "model": [1, 2, 3, 5, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 23, 24, 25], "ones": [1, 10, 11, 16, 25], "ar": [1, 3, 4, 5, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 24, 26, 28], "cach": [1, 8, 11, 12, 14, 16, 17, 19, 20, 24, 25, 28], "action": [1, 2, 25], "so": [1, 5, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 24, 25, 26], "quickli": [1, 5], "cd": [1, 25, 26], "These": [1, 25, 26], "gpt2": [1, 11, 12, 13, 14, 15, 18, 25, 26, 27], "attn": [1, 8, 10, 11, 12, 14, 18, 20, 24, 25, 26, 27], "onli": [1, 2, 8, 9, 10, 11, 12, 14, 16, 17, 18, 24, 25, 26, 27], "1l": [1, 18, 25, 26, 27], "2l": [1, 11, 18, 26, 27], "3l": [1, 18, 26, 27], "4l": [1, 18, 26, 27], "tini": [1, 8, 11, 18, 24, 25, 26, 27], "stori": [1, 8, 11, 18, 20, 24, 25, 27], "1m": [1, 8, 11, 18, 24, 27], "note": [1, 3, 8, 9, 10, 11, 12, 14, 15, 17, 18, 24, 25, 26], "i": [1, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 28], "quit": 1, "slow": [1, 26], "we": [1, 2, 6, 8, 11, 12, 16, 19, 20, 24, 25, 26, 28], "have": [1, 3, 8, 10, 11, 14, 16, 20, 24, 25, 26, 28], "cpu": [1, 8, 10, 11, 12, 14, 18, 25, 26], "smaller": [1, 26], "like": [1, 3, 4, 5, 10, 11, 14, 15, 16, 20, 24, 25, 26, 28], "prefer": 1, "possibl": [1, 10, 11, 16, 20, 24, 25, 26, 28], "via": [1, 2, 4, 10, 11, 20, 25], "make": [1, 5, 9, 10, 11, 16, 17, 25, 26, 28], "accept": [1, 10, 11, 17, 25], "pycln": 1, "isort": 1, "black": [1, 26], "pull": 1, "request": 1, "check": [1, 3, 5, 11, 13, 14, 15, 16, 17, 24, 25, 26], "all": [1, 4, 8, 10, 11, 14, 15, 16, 17, 20, 24, 25], "file": [1, 24], "sure": [1, 11, 24, 25, 26], "thorough": 1, "ani": [1, 8, 10, 11, 12, 14, 17, 24, 25, 26, 28], "should": [1, 5, 8, 10, 11, 14, 16, 17, 21, 24, 25, 26], "do": [1, 3, 4, 5, 8, 10, 11, 14, 15, 17, 20, 24, 25, 26, 28], "directli": [1, 10, 12, 24, 25, 26], "automat": [1, 5, 11, 12, 24, 25, 26], "gener": [1, 5, 11, 14, 15, 19, 20, 24, 25], "api": [1, 17, 25], "when": [1, 3, 5, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 24, 25, 26], "merg": [1, 11], "main": [1, 3, 5, 8, 17, 25], "thei": [1, 4, 11, 12, 14, 15, 20, 24, 25, 26, 28], "pytest": 1, "doctest": 1, "want": [1, 5, 8, 11, 13, 15, 16, 17, 19, 24, 25, 26], "view": [1, 2], "chang": [1, 2, 3, 11, 12, 17, 18, 20, 24, 25, 26], "hot": [1, 25, 26], "reload": [1, 25, 26], "give": [1, 8, 11, 12, 15, 18, 20, 24, 25, 26], "real": [1, 5, 24, 25, 26, 28], "time": [1, 5, 6, 8, 11, 16, 17, 24, 25, 26], "edit": [1, 5, 11, 20, 25, 26, 28], "googl": [1, 5, 25, 26], "python": [1, 2, 12, 15, 18, 24, 26, 27], "write": [1, 2, 3, 11, 24, 25, 26, 28], "some": [1, 3, 8, 11, 13, 14, 15, 17, 20, 24, 25], "from": [1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 20, 24, 25, 26, 28], "restructuredtext": 1, "rest": [1, 8, 11, 12, 15, 18, 24, 26], "In": [1, 2, 8, 10, 11, 14, 15, 17, 25, 26], "case": [1, 2, 8, 11, 12, 15, 16, 17, 18, 20, 24, 25, 27], "A": [1, 2, 4, 8, 9, 10, 11, 14, 15, 17, 19, 20, 24, 25, 26], "descript": 1, "what": [1, 3, 5, 8, 11, 16, 20, 26, 28], "doe": [1, 8, 10, 11, 12, 16, 17, 20, 24, 25, 26], "much": [1, 8, 11, 15, 16, 20, 24, 25, 26], "detail": [1, 8, 11, 12, 14, 18, 20, 24, 25, 26], "necessari": [1, 26], "fulli": [1, 20, 25], "understand": [1, 8, 11, 16, 26], "warn": [1, 8, 11, 16, 17, 24], "user": [1, 2, 12, 24, 26], "e": [1, 8, 10, 11, 14, 16, 17, 18, 24, 25, 26, 27], "g": [1, 8, 10, 11, 14, 16, 17, 24, 26], "common": [1, 5, 8, 11, 24, 25, 26], "pitfal": 1, "exampl": [1, 2, 8, 10, 11, 13, 14, 15, 17, 24, 25], "here": [1, 2, 11, 12, 14, 15, 16, 24, 25, 26], "print": [1, 8, 15, 21, 24, 25, 26], "1": [1, 4, 8, 10, 11, 12, 14, 16, 17, 18, 19, 24, 25, 26, 27], "2": [1, 3, 4, 8, 10, 11, 12, 14, 15, 16, 18, 24, 25, 26, 27, 28], "3": [1, 8, 9, 10, 11, 14, 15, 20, 24, 25, 26, 27, 28], "arg": [1, 17], "param_without_type_signatur": 1, "each": [1, 8, 9, 11, 12, 14, 16, 17, 18, 19, 20, 24, 25, 26], "indent": 1, "onc": [1, 11, 24, 25, 26], "more": [1, 5, 8, 9, 11, 12, 14, 16, 20, 24, 25, 26, 28], "param_2": 1, "anoth": [1, 25, 26], "paramet": [1, 5, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 23, 24, 25], "return": [1, 8, 9, 10, 11, 14, 15, 16, 17, 18, 20, 21, 23, 24, 25, 26], "without": [1, 8, 11, 14, 24, 25, 26], "type": [1, 5, 8, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 23, 24, 25, 26], "signatur": [1, 10, 11, 26], "rais": [1, 11, 16, 18, 24, 26], "inform": [1, 11, 12, 14, 17, 18, 25, 26], "about": [1, 5, 8, 11, 15, 17, 20, 24, 25, 26, 28], "error": [1, 8, 11, 16, 18, 26], "mai": [1, 8, 10, 11, 12, 24, 25, 26], "part": [1, 8, 11, 14, 20, 25, 26, 28], "codebas": [1, 26], "cross": [1, 8, 11, 24, 25, 26], "referenc": 1, "omit": [1, 16, 26], "full": [1, 4, 8, 10, 11, 12, 14, 24, 26], "path": [1, 4, 24], "same": [1, 3, 8, 9, 11, 14, 16, 17, 19, 20, 24, 25, 26], "mod": 1, "transformer_len": [1, 3, 6, 25, 26], "modul": [1, 6, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 24, 26], "const": 1, "loading_from_pretrain": [1, 6, 7, 11, 26], "official_model_nam": [1, 11, 18], "hookedtransform": [1, 3, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 18, 20, 21, 23, 24, 25, 26], "meth": [1, 8], "from_pretrain": [1, 3, 8, 10, 11, 13, 15, 18, 24, 25, 26], "attr": 1, "cfg": [1, 10, 11, 13, 14, 15, 18, 19, 23, 24, 25, 26], "latex": 1, "re": [1, 3, 4, 5, 8, 11, 12, 16, 25, 26], "place": [1, 5, 10, 11, 24, 25, 26], "string": [1, 10, 11, 12, 15, 16, 17, 18, 24, 25, 26], "backward": [1, 17, 25, 26], "slash": 1, "must": [1, 8, 10, 11, 12, 14, 16, 17, 24, 25, 26], "repeat": [1, 11, 15, 19, 24, 25, 26], "inlin": 1, "displai": [1, 25, 26], "mode": [1, 8, 11, 12, 14, 24, 25, 26], "b": [1, 9, 10, 11, 14, 15, 18, 20, 24, 26, 27], "2ab": 1, "nowrap": 1, "begin": [1, 3, 11, 15, 16, 24, 25, 26], "eqnarrai": 1, "y": [1, 8, 11, 16, 25, 26], "ax": [1, 11, 20, 26], "bx": 1, "c": [1, 18, 24, 26, 27], "f": [1, 25, 26], "x": [1, 8, 11, 14, 16, 17, 18, 24, 25, 26], "2xy": 1, "end": [1, 5, 11, 17, 20, 24, 25, 26], "ital": 1, "text": [1, 5, 8, 11, 12, 14, 15, 17, 18, 19, 24, 25], "bold": 1, "list": [1, 3, 4, 8, 10, 11, 12, 15, 16, 17, 19, 20, 24, 25, 26], "item": [1, 8, 24, 25, 26], "number": [1, 8, 11, 12, 13, 14, 15, 18, 20, 21, 23, 24, 25, 26], "quot": 1, "level": [1, 17, 25, 26, 28], "extern": [1, 25], "link": [1, 11, 15], "domain": 1, "invalid": 1, "research": [2, 3, 4, 5, 25, 26, 28], "done": [2, 4, 8, 11, 12, 14, 17, 25, 26], "involv": [2, 25, 26], "progress": [2, 11, 26], "measur": [2, 15, 16, 20, 24, 25], "grokk": [2, 5], "mechanist": [2, 3, 5, 20, 25, 26], "interpret": [2, 3, 5, 8, 11, 13, 16, 20, 24, 25], "iclr": 2, "spotlight": 2, "2023": 2, "lawrenc": 2, "chan": 2, "tom": [2, 25], "lieberum": 2, "jess": 2, "smith": 2, "jacob": 2, "steinhardt": 2, "find": [2, 5, 8, 9, 11, 20, 25, 26], "neuron": [2, 5, 8, 11, 25, 26], "haystack": 2, "studi": [2, 4, 20, 25, 26], "spars": 2, "probe": 2, "gurne": 2, "matthew": 2, "pauli": 2, "katherin": 2, "harvei": 2, "dmitrii": 2, "troitskii": 2, "dimitri": 2, "bertsima": 2, "toward": [2, 14, 20, 25], "autom": 2, "circuit": [2, 10, 11, 14, 15, 16, 20, 24, 25, 26], "discoveri": 2, "arthur": [2, 26], "conmi": [2, 26], "augustin": 2, "n": [2, 14, 21, 24, 25, 26], "mavor": 2, "parker": 2, "aengu": 2, "lynch": 2, "stefan": 2, "heimersheim": 2, "adri\u00e0": 2, "garriga": 2, "alonso": 2, "actual": [2, 11, 16, 17, 26], "othello": [2, 5, 18, 27], "gpt": [2, 3, 4, 5, 8, 10, 11, 12, 14, 15, 18, 24, 25, 26, 27, 28], "ha": [2, 3, 4, 8, 9, 10, 11, 14, 15, 18, 19, 20, 24, 25, 26], "linear": [2, 5, 10, 11, 14, 18, 25, 26], "emerg": [2, 5], "world": [2, 5, 26, 28], "represent": [2, 5], "docstr": 2, "4": [2, 12, 14, 15, 24, 25, 26, 27], "layer": [2, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 23, 24, 26], "attent": [2, 5, 8, 11, 12, 14, 16, 20, 24, 26], "transform": [2, 3, 4, 5, 8, 10, 11, 12, 14, 18, 19, 20, 24, 25], "jett": 2, "janiak": 2, "toi": [2, 11], "univers": 2, "icml": 2, "bilal": 2, "chughtai": 2, "n2g": 2, "scalabl": 2, "approach": [2, 8, 25, 26], "quantifi": [2, 16], "larg": [2, 5, 12, 14, 18, 24, 26, 27, 28], "languag": [2, 10, 11, 14, 15, 21, 24, 25, 26], "workshop": 2, "rtml": 2, "alex": [2, 26], "foot": [2, 11, 26], "esben": 2, "kran": 2, "ioanni": 2, "konsta": 2, "fazl": 2, "barez": 2, "elicit": 2, "latent": 2, "predict": [2, 5, 8, 10, 11, 14, 15, 16, 24, 25, 26], "tune": [2, 10, 18, 24, 26, 27], "len": [2, 8, 18], "nora": 2, "belros": 2, "zach": 2, "furman": 2, "logan": 2, "danni": 2, "halawi": 2, "igor": 2, "ostrovski": 2, "lev": 2, "mckinnei": 2, "stella": 2, "biderman": 2, "contribut": [2, 8, 11, 25], "being": [2, 8, 10, 11, 12, 16, 17, 20, 24, 25, 26], "induct": [2, 4, 15, 16, 18], "head": [2, 4, 5, 8, 11, 12, 13, 14, 15, 16, 18, 20, 24], "phase": 2, "replic": [2, 4, 11, 13, 15, 25, 26], "partial": [2, 25, 26], "context": [2, 8, 11, 17, 20, 24, 25, 26], "learn": [2, 3, 5, 12, 21, 24, 25, 26, 28], "connor": 2, "kissan": 2, "decis": [2, 3], "set": [2, 8, 10, 11, 12, 14, 15, 16, 17, 20, 21, 24, 25, 26], "script": [2, 5], "train": [2, 5, 6, 7, 8, 10, 11, 12, 15, 18, 24, 25, 28], "which": [2, 3, 5, 8, 10, 11, 12, 15, 16, 17, 18, 19, 20, 24, 25, 26], "intermedi": [2, 8, 11, 17, 26], "activ": [2, 3, 4, 5, 8, 10, 11, 12, 13, 17, 20, 24, 28], "perform": [2, 5, 14, 15, 17, 24, 25, 26], "attribut": [2, 4, 5, 8, 20, 24, 26], "ablat": [2, 25, 26], "up": [2, 3, 4, 8, 11, 12, 17, 20, 21, 24, 25, 26], "initi": [2, 6, 11, 12, 17, 23, 24, 25, 26], "work": [2, 3, 4, 5, 8, 10, 11, 14, 17, 18, 24, 25, 26, 28], "found": [2, 11, 12, 25, 26], "demo": [3, 13, 18, 27], "how": [3, 5, 8, 11, 16, 20, 21, 25, 26, 28], "basic": [3, 5, 11, 15, 24, 25], "To": [3, 4, 8, 11, 12, 14, 17, 18, 25, 26], "see": [3, 5, 8, 10, 11, 12, 14, 16, 18, 20, 24, 25, 26, 28], "exploratori": [3, 5, 16, 24, 26, 28], "analysi": [3, 5, 8, 11, 16, 24, 26, 28], "practic": [3, 4, 5, 25, 26], "look": [3, 4, 5, 6, 8, 11, 14, 16, 20, 25, 26], "out": [3, 5, 8, 11, 13, 20, 24, 25, 26], "my": [3, 5, 11, 12, 24, 25, 26, 28], "notebook": [3, 5, 25, 28], "analys": [3, 5, 8, 11, 26], "indirect": [3, 4, 5, 15], "object": [3, 4, 5, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 21, 24], "identif": [3, 4, 5, 15], "record": [3, 5, 26], "myself": [3, 5, 26], "veri": [3, 4, 5, 8, 12, 13, 15, 24, 25, 26, 28], "young": [3, 4, 26], "small": [3, 4, 5, 8, 11, 15, 18, 24, 25, 26, 27, 28], "field": [3, 4, 11, 24, 26, 28], "lot": [3, 4, 5, 8, 9, 19, 20, 24, 25, 26, 28], "open": [3, 4, 11, 15, 28], "problem": [3, 4, 26, 28], "would": [3, 4, 10, 14, 25, 26, 28], "help": [3, 4, 12, 20, 25, 26], "try": [3, 4, 8, 11, 16, 25, 26], "concret": [3, 4, 25, 26], "figur": [3, 20, 25, 26], "where": [3, 8, 9, 11, 12, 14, 16, 17, 18, 20, 21, 24, 25, 26], "skill": [3, 26], "kei": [3, 4, 8, 10, 11, 12, 14, 15, 16, 19, 20, 24, 25, 26], "resourc": [3, 4], "new": [3, 5, 8, 11, 17, 18, 19, 24, 25, 26], "tutori": [3, 4, 25, 26], "scratch": [3, 4, 25], "an": [3, 4, 5, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 28], "accompani": [3, 4, 5, 26], "templat": [3, 15], "yourself": [3, 11, 25, 26], "One": [3, 11, 25, 26, 28], "signific": [3, 17, 25, 26], "design": [3, 8, 25, 26, 28], "made": [3, 15, 25, 26], "wa": [3, 8, 10, 11, 12, 15, 20, 25, 26], "singl": [3, 8, 10, 11, 14, 19, 20, 24, 25, 26], "implement": [3, 10, 11, 20, 24, 25, 26], "could": [3, 25, 26], "support": [3, 5, 10, 11, 12, 16, 17, 24, 25, 26], "rang": [3, 4, 11, 12, 13, 16, 20, 24, 25, 26], "subtli": [3, 14], "differ": [3, 8, 10, 11, 12, 14, 15, 16, 17, 20, 24, 25, 26], "style": [3, 8, 10, 11, 12, 14, 16, 25, 26, 28], "upsid": 3, "just": [3, 4, 8, 11, 12, 15, 20, 24, 25, 26], "arbitrari": [3, 11, 25, 26], "name": [3, 8, 11, 12, 15, 16, 17, 18, 20, 21, 24], "But": [3, 8, 11, 20, 24, 25, 26], "downsid": 3, "py": [3, 10, 24], "compon": [3, 6, 7, 8, 10, 11, 24, 25, 26], "difficult": [3, 8], "recommend": [3, 6, 8, 11, 12, 13, 17, 25, 26], "clean": [3, 20, 24, 25, 26], "minim": [3, 26], "intern": [3, 8, 11, 20, 25, 26, 28], "architectur": [3, 10, 25], "significantli": [3, 10, 11, 15, 20, 25, 26], "clearer": 3, "better": [3, 11, 12, 15, 16, 18, 25, 26], "document": [3, 11, 24, 26], "pip": [3, 25, 26], "git": 3, "import": [3, 8, 11, 13, 15, 19, 20, 24, 28], "known": [3, 28], "easytransform": [3, 26, 28], "break": [3, 8, 25, 26], "been": [3, 8, 11, 24, 26], "sinc": [3, 8, 11, 14, 17, 25, 26], "renam": 3, "old": [3, 18, 26], "version": [3, 5, 11, 15, 17, 25, 26], "legaci": [3, 16], "run": [3, 8, 11, 14, 17, 18, 19, 20, 21, 25, 28], "v1": 3, "mean": [4, 8, 11, 12, 13, 14, 16, 17, 24, 25, 26], "": [4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 23, 24, 26, 28], "both": [4, 8, 11, 16, 17, 19, 25, 26], "low": [4, 9, 11, 14, 24, 26], "hang": [4, 26], "fruit": [4, 26], "bar": [4, 11], "entri": [4, 14, 19, 20, 26], "The": [4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28], "standard": [4, 11, 12, 25, 26], "answer": [4, 8, 20, 24, 25, 26], "why": [4, 8, 14, 24, 25, 26], "yet": [4, 10, 11, 25, 26, 28], "aren": [4, 18, 26], "t": [4, 8, 9, 10, 11, 12, 13, 14, 15, 18, 24, 25, 26, 28], "enough": [4, 8, 25, 26], "peopl": [4, 26], "guid": [4, 26], "arena": 4, "callum": [4, 26], "mcdougal": [4, 26], "comprehens": [4, 26], "introduct": 4, "mech": [4, 25], "interp": [4, 25], "written": [4, 5, 25], "snippet": 4, "copi": [4, 10, 25], "come": [4, 11, 20, 25, 26], "exercis": [4, 25], "solut": [4, 25, 26], "notabl": [4, 11, 17, 25, 26], "video": [4, 5, 25, 26], "me": [4, 18, 26, 28], "good": [4, 5, 8, 15, 24, 25, 26, 28], "cover": [4, 11, 26], "foundat": [4, 26], "concept": [4, 25, 26], "wild": [4, 8, 25, 26], "techniqu": [4, 5, 11, 20, 25, 26], "direct": [4, 8, 11, 13, 17, 20, 26], "logit": [4, 5, 8, 10, 11, 14, 15, 20, 24, 26], "patch": [4, 5, 6, 7], "paper": [4, 5, 8, 11, 12, 14, 15, 20, 26], "read": [4, 5, 8, 11, 26], "200": [4, 26], "explain": [4, 5, 25, 26], "jargon": 4, "unfamiliar": [4, 25], "term": [4, 8, 11, 25], "go": [4, 5, 20, 26], "across": [4, 8, 10, 11, 13, 18, 20, 23, 25, 26], "youtub": 4, "channel": 4, "content": [4, 15, 25, 26], "walkthrough": [4, 25, 26], "colab": [5, 25, 26, 28], "blob": 5, "ipynb": 5, "causal": [5, 10, 12, 20, 25, 26], "intervent": [5, 20, 25, 26], "identifi": [5, 11, 20, 25, 26], "matter": [5, 11, 20, 25, 26], "produc": [5, 11, 20, 25], "output": [5, 8, 10, 11, 12, 14, 16, 17, 20, 24, 25, 26], "incomplet": 5, "gradient": [5, 8, 17, 21, 26], "take": [5, 8, 11, 14, 17, 20, 24, 25, 26, 28], "approxim": [5, 25, 26], "individu": [5, 8, 11, 14, 25], "bad": [5, 11], "residu": [5, 8, 10, 11, 12, 14, 20, 26], "stream": [5, 8, 10, 11, 12, 14, 20, 24, 26], "probabl": [5, 11, 15, 16, 20, 24, 25, 26], "best": [5, 11, 25, 26], "after": [5, 8, 11, 12, 14, 17, 21, 25, 26, 28], "demonstr": [5, 13, 25, 26], "focus": [5, 25, 26], "less": [5, 11, 14, 25], "rigor": [5, 25, 26], "get": [5, 8, 10, 11, 12, 13, 14, 15, 16, 17, 20, 23, 25, 26, 28], "grasp": 5, "steal": 5, "liber": [5, 17], "phenomenon": 5, "memoris": 5, "data": [5, 11, 15, 24, 25, 26], "minimis": 5, "loss": [5, 8, 11, 15, 17, 20, 21, 24, 25, 26], "longer": 5, "generalis": [5, 25, 26], "lead": [5, 10, 17, 24, 26], "sharp": [5, 26], "decreas": [5, 14, 24, 25], "test": [5, 11, 15, 16, 24, 25, 26], "well": [5, 11, 13, 17, 20, 24, 25, 26], "show": [5, 11, 13, 16, 25, 26, 28], "task": [5, 10, 11, 12, 15, 20, 21, 25], "modular": [5, 24], "addit": [5, 10, 11, 25], "verifi": [5, 25, 26], "grok": 5, "light": 5, "explan": [5, 20, 25], "ll": [5, 11, 16, 25, 26], "pair": [5, 9, 11, 14, 16, 24, 25, 26], "seri": [5, 8, 26], "base": [5, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 21, 23, 24, 25, 26, 27], "detector": [5, 16], "detect": [5, 16, 25, 26], "sever": [5, 8, 11, 24, 25, 26], "creat": [5, 8, 11, 14, 17, 25, 26], "own": [5, 25, 26], "custom": [5, 11, 12, 14, 15, 17, 24, 25, 26], "algorithm": [5, 9, 12, 26, 28], "interact": [5, 25, 26], "neuroscop": [5, 26], "hacki": [5, 24], "bug": [5, 8, 12, 24, 26], "web": [5, 26], "visualis": [5, 25], "even": [5, 9, 11, 12, 14, 15, 18, 25, 26, 28], "profession": 5, "front": 5, "visual": [5, 26], "dynam": [5, 12, 26], "updat": [5, 11, 19, 20, 23, 25, 26], "llama": [5, 18, 27], "convert": [5, 10, 11, 24, 25, 26], "meta": [5, 11, 18, 24, 25, 26], "7b": [5, 18, 26, 27], "now": [5, 11, 25, 26], "until": [5, 8, 11, 17, 25, 26], "multi": [5, 8, 24, 26], "gpu": [5, 8, 9, 10, 11, 25, 26], "great": [5, 26, 28], "avail": [5, 8, 11, 12, 16, 18], "access": [5, 8, 12, 17, 24, 25], "know": [5, 8, 10, 25, 26], "No": [5, 26], "posit": [5, 8, 10, 11, 12, 14, 15, 16, 17, 18, 20, 24, 25, 26], "experi": [5, 12, 25, 26, 28], "embed": [5, 8, 10, 11, 12, 14, 25, 26], "previou": [5, 8, 11, 14, 16, 25, 26], "token": [5, 8, 10, 11, 12, 13, 14, 15, 16, 18, 20, 24, 25], "port": 5, "weight": [5, 10, 11, 12, 14, 21, 25, 26, 28], "excel": [5, 8, 25, 26, 28], "sequenc": [5, 10, 11, 12, 14, 15, 16, 17, 20, 24, 25, 26], "investig": [5, 8, 11, 16, 25, 26], "worth": [5, 8, 25, 26], "interest": [5, 10, 11, 25, 26], "topic": 5, "svd": [5, 9, 11, 13, 26], "conjectur": 5, "post": [5, 8, 13, 14, 25, 26], "singular": [5, 9, 11, 13, 26], "valu": [5, 8, 9, 10, 11, 12, 14, 16, 18, 19, 20, 24, 25, 26, 28], "decomposit": [5, 8, 9, 11, 25, 26], "matric": [5, 9, 11, 13, 14, 25, 26], "surprisingli": 5, "reproduc": [5, 12, 16], "further": [5, 8, 11, 24, 25, 26], "tracr": 5, "cool": 5, "deepmind": 5, "tool": [5, 26, 28], "compil": 5, "program": [5, 26, 28], "rasp": 5, "jax": 5, "form": [5, 8, 9, 11, 20, 25, 26], "pytorch": [5, 11, 12, 15, 17, 26], "brows": 6, "first": [6, 8, 11, 12, 15, 18, 20, 24, 25, 26], "activationcach": [6, 7, 10, 11, 16, 20, 24, 25, 26], "submodul": 6, "factoredmatrix": [6, 7, 10, 14, 24, 26], "hookedencod": [6, 7, 23], "hookedtransformerconfig": [6, 7, 11, 14, 18, 19, 23], "svdinterpret": [6, 7], "eval": [6, 7, 26], "head_detector": [6, 7], "hook_point": [6, 7, 11, 26], "past_key_value_cach": [6, 7], "util": [6, 7, 8, 9, 11, 16, 17, 18, 21, 25, 26], "subpackag": 6, "core": [8, 11, 25, 26, 28], "wrapper": [8, 10, 11, 20, 23, 26], "store": [8, 11, 12, 17, 19, 20, 21, 25, 26], "forward": [8, 10, 11, 12, 14, 17, 19, 26], "pass": [8, 11, 12, 14, 16, 17, 18, 19, 24, 26], "provid": [8, 10, 11, 14, 17, 23, 24], "varieti": [8, 26], "helper": [8, 11, 14, 15, 17, 20, 24, 26], "function": [8, 10, 11, 12, 14, 16, 17, 18, 20, 21, 23, 24, 26, 28], "them": [8, 11, 14, 17, 20, 24, 25, 26], "start": [8, 11, 14, 20, 24, 25, 26], "class": [8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 21, 24], "skim": 8, "method": [8, 10, 11, 12, 17, 18, 19, 24, 25, 26], "refer": [8, 11, 14, 17, 25, 26], "back": [8, 12, 14, 26], "depend": [8, 11, 26], "cache_dict": 8, "dict": [8, 10, 11, 12, 14, 15, 16, 17, 24], "str": [8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26], "tensor": [8, 9, 10, 11, 13, 14, 16, 19, 20, 24, 25, 26], "has_batch_dim": 8, "bool": [8, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 24], "wai": [8, 11, 17, 24, 25, 26], "run_with_cach": [8, 10, 11, 17, 25, 26], "particular": [8, 13, 16, 25, 26], "behaviour": [8, 11, 25, 26], "modal": 8, "step": [8, 11, 12, 18, 21, 24, 25, 26], "most": [8, 11, 17, 24, 25, 26, 28], "respons": [8, 12, 25], "prompt": [8, 11, 14, 15, 20, 24, 25, 26], "did": [8, 24, 25, 26], "chicken": 8, "road": [8, 24], "might": [8, 10, 25], "specif": [8, 10, 11, 14, 16, 20, 25, 26], "sublay": 8, "mlp": [8, 10, 11, 12, 14, 20, 24, 25, 26], "kind": [8, 25, 26], "commonli": 8, "fall": 8, "under": [8, 11], "categori": [8, 25], "dla": 8, "load": [8, 10, 11, 12, 15, 18, 24, 25, 28], "pretrain": [8, 10, 11, 12, 15, 18, 24, 25, 26], "_logit": 8, "residual_stream": 8, "label": [8, 11, 12, 14, 18, 25, 26], "decompose_resid": [8, 25], "return_label": [8, 25], "0": [8, 10, 11, 12, 13, 14, 16, 18, 21, 24, 25, 26], "emb": [8, 14, 24, 26], "pos_emb": [8, 12, 26], "0_attn_out": 8, "proceed": 8, "space": [8, 10, 11, 24, 25, 26], "match": [8, 11, 16, 25], "logit_attr": 8, "shape": [8, 10, 11, 14, 20, 24, 25, 26], "torch": [8, 10, 11, 12, 14, 17, 18, 20, 23, 24, 25, 26], "size": [8, 11, 12, 14, 15, 21, 24, 25, 26], "10": [8, 11, 13, 24, 25, 26, 27], "7": [8, 15, 25, 26, 27], "most_important_component_idx": 8, "argmax": [8, 25], "3_attn_out": 8, "dig": [8, 25, 26, 28], "granular": 8, "get_full_resid_decomposit": 8, "larger": [8, 15, 25, 26], "stack": [8, 10, 11, 20, 24, 25, 26], "remain": [8, 11, 17, 26], "equal": [8, 12], "struggl": 8, "construct": [8, 10], "joke": 8, "last": [8, 11, 24, 26], "trivial": 8, "few": [8, 10, 25, 26], "call": [8, 10, 11, 12, 14, 17, 18, 24, 25, 26], "accumulated_resid": [8, 25], "other": [8, 10, 11, 14, 16, 17, 18, 20, 25], "biggest": 8, "footgun": [8, 17], "sourc": [8, 11, 12, 14, 15, 20, 28], "keep": [8, 11, 17, 25, 26, 28], "track": [8, 25], "index": [8, 11, 12, 13, 14, 18, 20, 23, 24, 25, 26], "dimens": [8, 11, 12, 14, 17, 20, 24, 25, 26], "There": [8, 10, 16, 18, 24, 25, 26, 28], "vector": [8, 9, 11, 13, 14, 20, 25, 26], "q": [8, 11, 14, 20], "k": [8, 9, 11, 13, 14, 20, 24, 25, 26], "z": [8, 11, 16, 20, 25, 26], "batch": [8, 10, 11, 14, 15, 17, 19, 20, 21, 24, 25, 26], "po": [8, 10, 11, 14, 20, 24, 25, 26], "head_index": [8, 11, 13, 14, 20, 25, 26], "d_head": [8, 10, 11, 12, 14, 18, 19, 25, 26, 27], "pattern": [8, 11, 14, 16, 20, 26], "result": [8, 10, 11, 12, 14, 16, 18, 20, 24, 25, 26, 28], "softmax": [8, 11, 14, 24, 26], "attn_scor": [8, 14], "pre": [8, 11, 12, 14, 16, 24], "query_po": [8, 14, 25], "key_po": [8, 14, 25], "d_model": [8, 10, 11, 12, 14, 18, 25, 26, 27], "mid": [8, 25], "solu_ln": [8, 12], "between": [8, 11, 14, 16, 20, 24, 25, 26, 28], "layernorm": [8, 10, 11, 12, 14, 24, 25], "d_mlp": [8, 10, 11, 12, 14, 18, 24, 26, 27], "resid_pr": [8, 12, 14, 20, 25, 26], "resid_mid": [8, 20], "resid_post": [8, 12, 25], "attn_out": [8, 11, 12, 20, 25], "mlp_out": [8, 11, 12, 14, 20, 25], "normal": [8, 11, 12, 14, 24, 25, 26, 28], "ln": [8, 11, 12, 25, 26], "lnpre": [8, 12], "scale": [8, 11, 12, 14, 24, 25, 26], "sometim": [8, 15, 25], "miss": [8, 25], "becaus": [8, 9, 10, 11, 12, 14, 15, 24, 25, 26, 28], "appli": [8, 11, 12, 14, 20, 24, 25, 26], "remove_batch_dim": [8, 17, 24, 26], "batch_siz": [8, 10, 14, 15, 17, 19, 21, 25, 26], "robust": [8, 25], "annot": [8, 26], "layers_cov": 8, "queri": [8, 10, 11, 12, 14, 16, 20, 26], "batch_and_pos_dim": 8, "default": [8, 11, 12, 13, 14, 15, 16, 17, 18, 20, 24, 25, 26], "ve": [8, 11, 14, 15, 17, 25, 28], "remov": [8, 9, 11, 14, 17, 24, 25, 26, 28], "slice": [8, 24, 25], "dictionari": [8, 10, 11, 12, 16, 17, 24, 26], "whether": [8, 10, 11, 12, 14, 15, 17, 18, 20, 21, 24, 25, 26], "option": [8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24], "int": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26], "none": [8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 23, 24, 25, 26], "incl_mid": [8, 25], "fals": [8, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26], "apply_ln": [8, 25], "pos_slic": [8, 25], "union": [8, 10, 11, 13, 14, 16, 17, 19, 20, 23, 24, 25], "tupl": [8, 9, 10, 11, 14, 16, 17, 20, 24, 26], "ndarrai": [8, 11, 24], "mlp_input": [8, 11], "float": [8, 9, 10, 11, 12, 14, 16, 18, 19, 20, 21, 24, 25, 26], "accumul": [8, 11, 25], "sub": [8, 26], "www": 8, "lesswrong": 8, "ackrb8wdpdan6v6ru": 8, "thought": [8, 25, 26], "believ": [8, 15, 25], "point": [8, 10, 11, 12, 13, 17, 24, 25, 28], "vocabulari": [8, 12, 25, 26], "rememb": 8, "final": [8, 10, 11, 12, 14, 24, 25, 26], "norm": [8, 9, 11, 12, 14, 18, 21, 25, 26], "decod": 8, "therefor": [8, 11, 24], "multipli": [8, 11, 14, 16, 25, 26], "unembed": [8, 10, 11, 25, 26], "matrix": [8, 9, 10, 11, 13, 14, 16, 24, 25], "w_u": [8, 10, 11, 25, 26], "instead": [8, 11, 14, 17, 25, 26], "broken": [8, 17, 24, 25, 26], "down": [8, 11, 14, 25, 26], "einop": [8, 25, 26], "einsum": [8, 25, 26], "panda": [8, 20], "pd": [8, 20], "devic": [8, 10, 11, 12, 13, 14, 15, 17, 18, 19, 21, 22, 25, 26], "answer_token": [8, 25], "to_single_token": [8, 11, 25, 26], "2975": 8, "accum_resid": 8, "last_token_accum": 8, "9": [8, 24, 25, 26, 27], "64": [8, 18, 24, 26, 27], "50257": [8, 18, 26, 27], "layers_unembed": 8, "d_vocab": [8, 10, 11, 12, 13, 18, 20, 24, 26, 27], "rank": [8, 9, 11, 14, 24, 25, 26], "correct": [8, 20, 23, 24, 25, 26], "sorted_indic": 8, "argsort": 8, "dim": [8, 11, 24, 25, 26], "descend": [8, 26], "rank_answ": 8, "nonzero": 8, "as_tupl": 8, "0_pre": 8, "4442": 8, "1_pre": [8, 25], "382": 8, "2_pre": 8, "982": 8, "3_pre": 8, "1160": 8, "4_pre": 8, "408": 8, "5_pre": 8, "145": 8, "6_pre": 8, "78": 8, "7_pre": 8, "387": 8, "final_post": 8, "6": [8, 18, 24, 25, 26, 27], "dtype": [8, 10, 11, 12, 14, 18, 23, 25, 26], "int64": [8, 24], "exclud": [8, 16], "n_layer": [8, 10, 11, 12, 18, 20, 23, 25, 26, 27], "immedi": [8, 14, 25, 26], "indic": [8, 10, 14, 17, 20, 24, 25, 26], "taken": [8, 11, 26], "input": [8, 10, 11, 12, 14, 17, 18, 19, 20, 24, 25, 26], "l": [8, 11, 25, 26], "noth": [8, 10, 11, 24, 25, 26], "current": [8, 10, 11, 12, 14, 16, 25, 26], "essenti": [8, 11, 25, 26, 28], "rather": [8, 11, 12, 14, 20, 24, 25, 26], "than": [8, 11, 12, 14, 15, 16, 17, 20, 24, 25, 26], "graph": [8, 25, 26], "apply_ln_to_stack": [8, 11, 24, 25], "residual_stack": [8, 25], "num_compon": 8, "batch_slic": 8, "batch_and_pos_dims_out": 8, "eg": [8, 11, 15, 20, 24, 25, 26], "treat": [8, 11, 25, 26], "factor": [8, 9, 11, 25], "simul": [8, 11, 25, 26], "global": [8, 14, 17, 24, 25, 26], "entir": [8, 11, 20, 25], "element": [8, 11, 14, 16, 20, 24, 26], "unchang": [8, 10, 11, 24, 25, 26], "whose": [8, 10, 11, 15, 24, 25], "trail": [8, 9, 24], "assum": [8, 10, 11, 14, 17, 20, 21, 24, 25], "hook_scal": [8, 24, 25, 26], "unemb": [8, 11, 12, 14, 25, 26], "map": [8, 10, 11, 14, 16, 17, 25, 26], "ie": [8, 10, 11, 12, 14, 18, 20, 24, 25, 26], "ln2": [8, 24, 26], "ln1": [8, 12, 24, 26], "ln_final": [8, 25, 26], "over": [8, 11, 20, 24, 25, 26], "alreadi": [8, 11, 24, 25, 26], "apply_slice_to_batch_dim": 8, "compute_head_result": 8, "comput": [8, 9, 11, 14, 16, 17, 19, 20, 24, 25, 26, 28], "amount": [8, 12, 25], "sum": [8, 9, 11, 12, 14, 16, 24, 25, 26], "plu": 8, "b_o": [8, 10, 11, 26], "intend": [8, 12, 24], "enabl": [8, 11, 25, 26, 28], "use_attn_result": [8, 11, 12], "forget": 8, "liter": [8, 10, 11, 13, 16, 20], "incl_emb": 8, "decompos": 8, "incl": 8, "expand_neuron": 8, "bias": [8, 10, 11, 12, 21, 25], "expand": [8, 11], "everi": [8, 10, 11, 14, 17, 20, 21, 24, 25, 26], "get_neuron_result": 8, "neuron_slic": 8, "num_neuron": 8, "subset": [8, 12, 15, 25, 26], "specifi": [8, 10, 11, 12, 15, 16, 17, 23, 24, 26], "expens": [8, 9], "cheap": 8, "hook_emb": [8, 24, 26], "hook_pos_emb": [8, 26], "block": [8, 11, 12, 14, 20, 24, 25, 26], "hook_resid_pr": [8, 26], "incorrect_token": [8, 25], "typic": [8, 10, 11, 14, 16, 25, 26], "calcul": [8, 9, 10, 11, 12, 14, 16, 25, 26], "revers": [8, 9, 20, 24, 25, 26, 28], "dot": [8, 11, 14, 24], "product": [8, 9, 14, 26], "incorrect": [8, 11, 20, 25, 26], "select": [8, 24, 25, 26], "arxiv": [8, 11, 12, 14, 15], "org": [8, 11, 12, 14, 15, 26, 28], "ab": [8, 9, 11, 16, 25, 26], "2211": [8, 15], "00593": [8, 15], "john": [8, 25, 26], "mari": [8, 25, 26], "went": [8, 25, 26], "shop": [8, 25, 26], "gave": [8, 15, 25, 26], "bag": [8, 25], "were": [8, 11, 12, 15, 25, 26, 28], "choos": [8, 25, 26], "impact": 8, "final_ln": 8, "residual_stack_item": 8, "dure": [8, 17, 19, 26, 28], "stack_activ": 8, "activation_nam": [8, 20, 25], "sublayer_typ": 8, "flexibl": 8, "given": [8, 9, 10, 11, 13, 16, 17, 18, 20, 23, 24, 25, 26], "strictli": [8, 26], "befor": [8, 10, 11, 12, 14, 17, 24, 25, 26], "get_act_nam": [8, 24, 25, 26], "infer": [8, 11, 14, 20, 25, 26], "incl_remaind": 8, "stack_head_result": [8, 25], "axi": [8, 14, 20, 24, 25, 26], "length": [8, 10, 11, 12, 14, 24, 25, 26], "n_head": [8, 10, 11, 12, 14, 18, 19, 20, 25, 26, 27], "notat": [8, 25], "l0h0": 8, "stack_neuron_result": 8, "l0n0": 8, "super": [8, 11, 24, 26], "memori": [8, 9, 10, 11, 12, 25, 26], "short": [8, 24, 25, 26, 28], "move_model": 8, "move": [8, 10, 11, 20, 25, 26], "mostli": [8, 25, 26], "finish": [8, 11, 24, 25, 26], "save": [8, 11, 12, 16, 21, 24, 25, 26], "howev": [8, 15, 25, 26], "oper": [8, 25, 26], "slower": 8, "unless": [8, 11, 12, 15, 26], "deprec": 8, "toggle_autodiff": 8, "toggl": [8, 11], "autodiff": [8, 26], "set_grad_en": [8, 25, 26], "state": [8, 11, 17, 25, 26, 28], "pretti": [8, 11, 24, 25, 26], "danger": 8, "turn": [8, 11, 24, 25, 26], "off": [8, 11, 15, 24, 25, 26], "abil": [8, 20, 25], "complet": [8, 14, 25, 26], "easi": [8, 11, 24, 25, 26, 28], "bunch": [8, 10, 11, 17, 25, 26], "don": [8, 10, 11, 12, 13, 15, 24, 25, 26, 28], "realis": [8, 25], "consum": [8, 9], "downstream": 8, "delet": [8, 24, 25], "stick": [8, 25], "around": [8, 10, 11, 17, 20, 23, 25, 26], "often": [8, 11, 12, 18, 24, 25, 26], "troubl": 8, "its": [8, 11, 14, 17, 25, 26, 28], "mess": [8, 11, 24, 26], "inference_mod": 8, "decor": 8, "achiev": [8, 26], "similar": [8, 10, 11, 14, 16, 25, 26], "effect": [8, 11, 20, 25, 26], "requires_grad": 8, "repres": [9, 10, 12, 14, 16, 20, 24, 25, 26], "two": [9, 10, 14, 16, 18, 20, 24, 25, 26], "effici": [9, 14, 24, 26], "eigenvalu": 9, "ldim": [9, 26], "mdim": [9, 26], "rdim": [9, 26], "properti": [9, 10, 11, 14, 24, 25, 26], "leading_dim": [9, 24], "ba": 9, "sens": [9, 17, 25, 26], "u": [9, 11, 20, 24, 25, 26], "vh": [9, 11], "collapse_l": 9, "collaps": [9, 25, 26], "left": [9, 11, 14, 24, 25, 26, 28], "side": [9, 11], "orthogon": [9, 11], "self": [9, 10, 11, 14, 24, 26], "collapse_r": 9, "analog": [9, 25, 26], "apart": [9, 24, 25, 26], "zero": [9, 11, 14, 16, 24, 25, 26], "bav": 9, "kv": 9, "abav": 9, "kav": 9, "av": 9, "eigenvector": [9, 26], "get_corn": [9, 24, 25], "make_even": 9, "sqrt": [9, 11, 12], "diag": 9, "equival": [9, 11, 14, 25, 26], "factoris": [9, 11, 14, 26], "half": [9, 10, 11, 14, 15, 26], "row": [9, 11, 20], "col": 9, "ndim": 9, "frobeniu": [9, 26], "squar": [9, 14, 24, 26], "m": [9, 14, 24, 25, 26], "st": 9, "transpos": [9, 24], "obviou": [9, 11, 25], "thing": [9, 11, 12, 14, 20, 25, 26, 28], "unsqueez": [9, 24], "hook": [10, 11, 12, 14, 17, 25], "encod": [10, 14, 24, 26], "contain": [10, 11, 14, 15, 16, 17, 18, 19, 24, 25, 26], "bert": [10, 14, 18, 26, 27], "separ": [10, 11, 12, 17, 24, 25, 26], "move_to_devic": [10, 11], "kwarg": [10, 11, 18, 24, 25, 26], "hookedrootmodul": [10, 11, 17, 26], "hookpoint": [10, 11, 17, 25, 26], "inherit": [10, 26], "limit": [10, 11, 25], "mvp": 10, "mask": [10, 11, 14, 24, 25], "mlm": 10, "next": [10, 11, 24, 25, 26], "sentenc": [10, 11, 14, 16, 25, 26], "nsp": 10, "dropout": 10, "inconsist": [10, 13], "fine": [10, 26], "preprocess": [10, 25], "fold": [10, 11, 14, 18, 25], "ov": [10, 11, 13, 14, 25, 26], "qk": [10, 11, 14, 25], "w_e": [10, 11, 26], "conveni": [10, 11, 12, 17, 24, 26], "w_e_po": [10, 11], "n_ctx": [10, 11, 12, 14, 18, 26, 27], "concaten": [10, 11, 24, 25, 26], "w_po": [10, 11, 26], "overcomplet": [10, 11], "basi": [10, 11], "w_k": [10, 11, 12, 14, 26], "w_o": [10, 11, 14, 25, 26], "w_q": [10, 11, 14, 26], "w_v": [10, 11, 14, 26], "w_in": [10, 11, 13, 14, 26], "w_out": [10, 11, 13, 14, 26], "absolut": [10, 11, 12, 14, 16, 24, 25, 26], "all_head_label": [10, 11], "b_k": [10, 11, 26], "b_q": [10, 11, 26], "b_u": [10, 11, 25, 26], "b_v": [10, 11, 26], "b_in": [10, 11, 14, 26], "b_out": [10, 11, 14, 26], "buffer": [10, 11], "modifi": [10, 11], "cuda": [10, 11, 12, 15, 18], "associ": [10, 11, 17], "optim": [10, 11, 21, 25], "live": [10, 11, 25, 26], "while": [10, 11, 14, 17, 25, 26], "return_typ": [10, 11, 17, 25, 26], "token_type_id": [10, 14], "one_zero_attention_mask": 10, "binari": [10, 14], "id": [10, 11, 14], "belong": [10, 14], "cl": [10, 14, 26], "sep": [10, 14], "sequence_length": [10, 14, 16, 24], "attend": [10, 12, 14, 24, 25, 26], "ignor": [10, 11, 12, 14, 17, 24, 26], "primarili": 10, "pad": [10, 11, 14, 24, 25, 26], "variabl": 10, "instanc": [10, 14, 16, 17, 25], "shorter": [10, 11, 26], "right": [10, 11, 14, 20, 24, 25, 26], "classmethod": [10, 11, 12, 19], "model_nam": [10, 11, 12, 18, 26], "checkpoint_index": [10, 11, 12, 18, 26], "checkpoint_valu": [10, 11, 12, 18, 26], "hf_model": [10, 11], "float32": [10, 11, 12, 14, 18, 25], "from_pretrained_kwarg": [10, 11], "huggingfac": [10, 11, 12, 15, 18, 24, 26, 28], "bertformaskedlm": 10, "unlik": [10, 11, 20, 26], "mp": [10, 11], "model_arg": [10, 11, 17], "return_cache_object": [10, 11], "otherwis": [10, 11, 15, 16, 24], "device_or_dtyp": [10, 11, 23], "print_detail": [10, 11, 23, 24], "cast": [10, 11], "non_block": [10, 11], "memory_format": [10, 11], "channels_last": [10, 11], "Its": [10, 11], "complex": [10, 11, 12, 25, 26], "integr": [10, 11, 18], "tri": [10, 11, 25, 26, 28], "asynchron": [10, 11], "respect": [10, 11, 17, 24, 26], "host": [10, 11], "pin": [10, 11], "below": [10, 11, 25], "desir": [10, 11], "format": [10, 11, 17, 25, 26], "4d": [10, 11], "keyword": [10, 11, 17, 26], "argument": [10, 11, 12, 17, 18, 24, 26], "xdoctest": [10, 11], "ignore_w": [10, 11], "non": [10, 11, 12, 14, 15, 24, 25, 26], "determinist": [10, 11, 24, 25], "nn": [10, 11, 17, 26], "1913": [10, 11], "3420": [10, 11], "5113": [10, 11], "2325": [10, 11], "doubl": [10, 11], "in_featur": [10, 11], "out_featur": [10, 11], "bia": [10, 11, 12, 14, 25, 26], "float64": [10, 11], "requir": [10, 11, 20, 24], "env": [10, 11], "torch_doctest_cuda1": [10, 11], "gpu1": [10, 11], "1914": [10, 11], "5112": [10, 11], "2324": [10, 11], "float16": [10, 11], "cdoubl": [10, 11], "3741": [10, 11], "j": [10, 11, 12, 14, 18, 25, 26, 27], "2382": [10, 11], "5593": [10, 11], "4443": [10, 11], "complex128": [10, 11], "6122": [10, 11], "1150": [10, 11], "fairli": [11, 25, 26], "extract": [11, 26], "harder": [11, 20, 25], "aim": [11, 25, 28], "simplifi": [11, 25, 26], "attach": [11, 26], "within": [11, 14, 16, 17, 20, 24, 25, 26], "inspect": [11, 25], "alter": 11, "facilit": 11, "deeper": 11, "pretrainedtokenizerbas": 11, "default_padding_sid": 11, "50": [11, 21, 26], "initialis": [11, 12], "although": [11, 14, 17], "instanti": [11, 12, 26], "randomli": [11, 12, 26], "__init__": [11, 14, 17, 24, 26], "test_prompt": [11, 24, 25, 26], "w_gate": [11, 14], "gate": [11, 14], "tokenizer_nam": [11, 12], "cannot": [11, 24, 26], "explicitli": [11, 12, 14, 15, 18, 20, 26], "n_devic": [11, 12, 18, 23], "greater": [11, 16], "split": [11, 14, 18, 24, 25, 26], "multipl": [11, 16, 23, 24, 26], "accumulated_bia": 11, "include_mlp_bias": 11, "layers_accumulated_ov": 11, "all_composition_scor": [11, 24], "composit": [11, 25, 26], "score": [11, 14, 16, 20, 25], "l1": 11, "h1": 11, "l2": 11, "h2": [11, 25], "upper": [11, 14], "triangular": [11, 16, 24, 26], "third": [11, 26], "pub": [11, 24], "2021": 11, "framework": [11, 14, 25, 26], "html": [11, 24, 25], "20abov": 11, "20diagram": 11, "20show": 11, "20q": 11, "2d": [11, 24], "2c": 11, "20k": [11, 24], "20and": 11, "20v": 11, "2dcomposit": 11, "three": [11, 20, 24, 25], "metric": [11, 16, 20, 25, 26], "center_unemb": [11, 25], "state_dict": 11, "center": [11, 12, 14, 25, 26], "subtract": [11, 16, 25], "themselv": 11, "As": [11, 25, 26], "translat": [11, 25, 26], "invari": 11, "log": [11, 21, 24, 25, 26], "prob": [11, 24, 25, 26], "slightli": [11, 24, 25], "misl": 11, "someth": [11, 15, 25], "center_writing_weight": [11, 25, 26], "fold_layer_norm": [11, 18], "check_hooks_to_add": [11, 17], "hook_point_nam": [11, 17], "dir": [11, 17], "fwd": [11, 17], "is_perman": [11, 17], "prepend": [11, 12, 15, 17, 18, 24, 26], "overrid": [11, 12, 17, 18, 24], "consist": [11, 25, 26], "neighbour": 11, "further_com": [11, 12], "md": [11, 12], "fold_value_bias": 11, "alwai": [11, 12, 20, 25, 26], "constant": [11, 14, 25, 26], "togeth": [11, 24, 25, 26], "doesn": [11, 15, 24, 25, 26], "easier": [11, 15, 25, 26, 28], "formal": 11, "b_o_new": 11, "b_o_origin": 11, "sum_head": 11, "b_v_head": 11, "w_o_head": 11, "loss_per_token": 11, "prepend_bo": [11, 12, 15, 18, 24, 25], "use_default_valu": 11, "padding_sid": [11, 24, 25], "start_at_lay": 11, "shortformer_pos_emb": [11, 14], "attention_mask": [11, 14, 19, 24], "stop_at_lay": 11, "past_kv_cach": [11, 14], "hookedtransformerkeyvaluecach": [11, 14, 19], "either": [11, 16, 17, 18, 20, 25, 26], "flag": [11, 12, 15, 17, 20, 24, 25, 26], "entropi": [11, 24, 25, 26], "per": [11, 20, 24, 25, 26], "averag": [11, 15, 25, 26], "scalar": [11, 14, 17, 26], "default_prepend_bo": [11, 12, 15, 18, 24, 26], "bo": [11, 12, 16, 18, 24, 25, 26], "impli": 11, "usag": [11, 25], "accordingli": [11, 12, 14, 18, 25, 26], "lose": [11, 12, 18], "empir": [11, 12, 18, 20, 26], "seem": [11, 12, 15, 18, 25, 26], "inclus": 11, "skip": [11, 25, 26], "neg": [11, 24, 25, 26], "shortform": [11, 12, 14, 18], "positional_embedding_typ": [11, 12, 14], "stop": 11, "exclus": [11, 24], "etc": [11, 20, 25, 26, 28], "24": [11, 24, 25, 26, 27], "frozen": [11, 19], "pai": [11, 14, 25], "through": [11, 25, 26], "correctli": 11, "okai": 11, "twice": [11, 15, 25, 26], "accid": 11, "second": [11, 15, 25, 26], "fold_ln": [11, 18, 25, 26], "refactor_factored_attn_matric": [11, 25], "automodelforcausallm": 11, "process": [11, 12, 18, 24, 25, 26], "autoregress": [11, 21], "neo": [11, 14, 18, 26, 27], "gptj": [11, 18], "opt": [11, 18, 26, 27], "solu": [11, 12, 18, 24, 26, 27], "checkpoint": [11, 12, 18, 21], "stanford": [11, 12, 14, 18, 26, 27], "crfm": [11, 18, 26], "load_and_process_state_dict": 11, "alia": [11, 18, 24, 26], "subsequ": [11, 18, 25, 26], "regular": 11, "batchnorm": [11, 25, 26], "mathemat": [11, 14, 25, 26], "w_": 11, "b_": 11, "w": 11, "layernormpr": [11, 14], "eff": 11, "ext": 11, "wise": [11, 16], "computation": [11, 26], "handl": [11, 17], "wish": 11, "defin": [11, 14, 17, 25, 26], "x_1": [11, 26], "x_0": [11, 26], "x_2": [11, 26], "frac": [11, 26], "x_3": 11, "cdot": 11, "x_4": 11, "due": [11, 26], "relat": [11, 25, 26], "idea": [11, 14, 20, 25, 26, 28], "preced": [11, 25, 26], "never": [11, 26], "w_write": 11, "keepdim": 11, "affect": [11, 20, 25], "fed": [11, 16], "exactli": [11, 18, 25, 26], "1000": [11, 15, 24, 26], "recreat": 11, "onto": [11, 18, 25], "By": [11, 15, 17, 18, 20, 24, 25, 26], "els": [11, 12, 14, 18, 25, 26], "mix": [11, 24, 25, 26], "linearli": 11, "technic": [11, 25, 26], "deriv": [11, 26], "h": [11, 25, 26], "broadcast_b_v": 11, "broadcast": 11, "And": [11, 20, 25, 26], "destination_posit": [11, 26], "source_posit": [11, 26], "along": [11, 14, 24, 25, 26], "source_": 11, "destin": [11, 12, 20, 26], "behavior": [11, 12, 18, 25], "cache_dir": [11, 24], "torch_dtyp": 11, "compat": [11, 18], "especi": [11, 25, 26], "bfloat16": 11, "from_pretrained_no_process": 11, "boolean": [11, 17, 20, 24, 25, 26], "max_new_token": [11, 26], "stop_at_eo": 11, "eos_token_id": [11, 24], "do_sampl": 11, "top_k": [11, 24, 25, 26], "top_p": [11, 24], "temperatur": [11, 24, 26], "freq_penalti": [11, 24], "use_past_kv_cach": 11, "verbos": 11, "pos_plus_new_token": 11, "sampl": [11, 15, 24], "eos_token": 11, "reach": [11, 26], "avoid": [11, 19, 24, 25, 26], "fiddl": 11, "rag": 11, "eot": 11, "throw": 11, "awai": [11, 25], "enter": [11, 25, 26, 28], "messi": [11, 26], "maximum": [11, 12, 14, 21, 26], "stable_lm": 11, "distribut": [11, 23, 24, 25, 26], "greedi": [11, 24], "search": [11, 16, 25, 26], "max": [11, 25], "mass": 11, "top": [11, 24, 25, 26], "cumul": [11, 24], "higher": [11, 25], "random": [11, 12, 15, 21, 25, 26], "temp": [11, 24], "inf": 11, "uniform": [11, 24], "frequenc": [11, 24, 25], "penalti": [11, 24], "penalis": 11, "speed": [11, 25], "applic": [11, 24], "whatev": [11, 25], "tqdm": [11, 26], "get_token_posit": [11, 25, 26], "single_token": [11, 26], "present": 11, "gotcha": [11, 13, 25], "Be": 11, "care": [11, 14, 17, 25, 26], "weird": [11, 12, 25, 26], "carefulli": [11, 25], "correspond": [11, 16, 20, 24, 25, 26], "dummi": [11, 17, 26], "init_weight": [11, 12], "std": 11, "initializer_rang": [11, 12], "02": [11, 18], "roughli": [11, 15, 25, 26], "scheme": 11, "truncat": [11, 15, 24, 26], "halv": 11, "empti": [11, 17], "bulk": 11, "seed": [11, 12, 21, 26], "ensur": [11, 25], "determin": [11, 14, 20, 23, 24, 25, 26], "NOT": [11, 17, 24, 26], "far": [11, 24, 25, 26], "tell": [11, 15, 25, 26], "date": 11, "gotten": 11, "round": [11, 15, 25, 26], "issu": [11, 25, 26], "18182": 11, "transformerencod": 11, "exact": 11, "72253": 11, "mup": 11, "haven": 11, "those": [11, 17, 24, 25], "2203": 11, "03466": 11, "input_to_emb": 11, "relev": [11, 12, 14, 20, 24, 25, 26], "special": [11, 26], "redwood": [11, 25, 26], "load_sample_training_dataset": 11, "dataset": [11, 15, 21, 24, 26], "10k": [11, 15, 24], "get_dataset": [11, 24], "appropri": [11, 26], "info": [11, 12, 20, 24, 26], "download": [11, 24, 26], "locat": [11, 20, 25], "pt": 11, "openwebtext": [11, 15, 24], "karma": [11, 15], "reddit": [11, 15], "hard": [11, 25, 26], "pile": [11, 15, 18, 24, 26, 27], "imperfectli": 11, "suppli": 11, "valid": [11, 15, 25], "loss_fn": [11, 26], "per_token": [11, 24, 26], "lm_cross_entropy_loss": [11, 24], "move_model_modules_to_devic": 11, "process_weights_": 11, "allow": [11, 16, 20, 24, 25, 26], "cleaner": 11, "experiment": 11, "argu": [11, 26], "somewhat": [11, 25, 26], "w_qk": [11, 14, 26], "w_ov": [11, 14, 26], "mani": [11, 14, 19, 20, 21, 25, 26], "hopefulli": [11, 28], "attempt": 11, "column": [11, 20, 24], "rotat": [11, 12, 14, 26], "nth": 11, "formula": 11, "r": 11, "think": [11, 15, 24, 25, 26], "setup": [11, 17, 20], "refactor": 11, "diagon": [11, 25, 26], "asymmetri": 11, "fiddli": 11, "deal": [11, 14, 24, 25], "preserv": [11, 25, 26], "too": [11, 20, 25], "bilinear": [11, 26], "dimension": [11, 12], "coordin": 11, "sample_datapoint": 11, "implicitli": [11, 20, 26], "hasn": 11, "manual": [11, 24, 26], "replac": [11, 12, 20, 25, 26, 28], "choic": [11, 25], "set_token": [11, 12], "pretrainedtoken": 11, "set_use_attn_in": 11, "use_attn_in": [11, 12], "set_use_attn_result": 11, "expos": [11, 28], "easili": [11, 24, 25, 26], "burn": 11, "set_use_hook_mlp_in": 11, "use_hook_mlp_in": [11, 12], "set_use_split_qkv_input": 11, "use_split_qkv_input": [11, 12], "to_single_str_token": 11, "int_token": 11, "uncertain": 11, "to_token": [11, 24, 25, 26], "to_str_token": [11, 13, 25, 26], "weirdli": [11, 25, 26], "gotcha2": 11, "letter": [11, 26], "capit": [11, 25, 26], "shoot": [11, 26], "gotcha3": 11, "exce": 11, "str_token": [11, 25], "to_str": [11, 25, 26], "numpi": [11, 12, 24, 25], "arrai": [11, 13, 24], "long": [11, 26], "window": [11, 12, 24], "tokens_to_residual_direct": [11, 25], "mislead": [11, 25], "integ": [11, 24, 25, 26], "residual_direct": 11, "namedtupl": 11, "dataclass": [12, 17], "configur": [12, 21, 23], "act_fn": [12, 27], "ep": 12, "1e": [12, 18], "05": [12, 18], "use_attn_scal": 12, "use_local_attn": 12, "original_architectur": 12, "from_checkpoint": 12, "checkpoint_label_typ": [12, 26], "window_s": [12, 14], "attn_typ": [12, 14], "init_mod": 12, "normalization_typ": 12, "attention_dir": 12, "attn_onli": [12, 27], "scale_attn_by_inverse_layer_idx": 12, "final_rm": 12, "d_vocab_out": [12, 14], "parallel_attn_mlp": 12, "rotary_dim": [12, 14], "n_param": [12, 27], "use_hook_token": 12, "gated_mlp": 12, "tokenizer_prepends_bo": 12, "post_embedding_ln": 12, "rotary_bas": 12, "10000": [12, 14, 26], "trust_remote_cod": 12, "rotary_adjacent_pair": 12, "AND": 12, "feedforward": 12, "network": [12, 25, 26], "vocab": 12, "lowercas": 12, "relu": [12, 27], "gelu": [12, 14, 18, 26, 27], "silu": [12, 27], "gelu_new": [12, 24], "gelu_fast": [12, 24], "epsilon": 12, "5": [12, 14, 15, 16, 20, 24, 25, 26, 27], "THEN": 12, "intens": 12, "famili": [12, 26], "certain": [12, 20], "distanc": [12, 14, 25], "weight_init_mod": 12, "pipelin": 12, "parallel": [12, 24, 25], "aka": 12, "unidirect": 12, "bidirect": [12, 26], "deviat": [12, 26], "8": [12, 14, 15, 16, 25, 26, 27], "layer_id": [12, 14], "mistral": [12, 15, 18], "numer": [12, 13, 14, 26], "stabil": [12, 14, 26], "fp16": 12, "rotari": [12, 14], "describ": [12, 24, 25], "blog": [12, 14], "eleuth": [12, 14, 24, 26], "ai": [12, 14, 24, 26], "res_stream": 12, "sinusoid": 12, "rmsnorm": [12, 14], "dumb": 12, "origin": [12, 13, 14, 25, 26], "mainli": 12, "curs": 12, "hidden": [12, 26], "law": 12, "pdf": [12, 14, 15], "2001": 12, "08361": 12, "meaning": [12, 20], "Will": [12, 20], "let": [12, 24, 25, 26, 28], "interven": [12, 17, 20, 25], "add_bos_token": [12, 24], "control": [12, 20, 25, 26], "from_dict": 12, "config_dict": 12, "set_seed_everywher": 12, "to_dict": 12, "get_singular_vector": 13, "vector_typ": 13, "layer_index": [13, 25], "num_vector": 13, "plot": [13, 26], "pysvelt": [13, 26], "instabl": 13, "d": [13, 15, 16, 18, 25, 27], "medium": [13, 18, 27], "svd_interpret": 13, "22": [13, 15, 24, 25, 26], "all_token": 13, "np": [13, 24, 25], "def": [13, 25, 26], "plot_matrix": 13, "filter": [13, 17, 18, 24, 26], "topk": [13, 25], "topktabl": 13, "obj_typ": 13, "pure": 14, "glossari": 14, "order": [14, 20, 24, 25], "sorri": 14, "underli": [14, 20, 25, 26], "destination_residu": 14, "destination_po": 14, "source_po": [14, 26], "param": [14, 21, 26], "convent": [14, 25, 26], "256": [14, 26, 27], "Not": 14, "moment": 14, "mistal": 14, "reason": [14, 25, 26], "apply_causal_mask": 14, "pos_plus_past_kv_pos_offset": 14, "past_kv_pos_offset": [14, 24], "offset_po": [14, 24], "apply_rotari": 14, "calculate_sin_cos_rotari": 14, "sine": 14, "cosin": 14, "wave": 14, "inexplic": 14, "adjac": [14, 25], "neox": [14, 18, 26, 27], "clue": [14, 25], "resolv": 14, "static": [14, 15], "create_alibi_bia": 14, "head_idx": 14, "alibi": 14, "2108": 14, "12409": 14, "broad": [14, 25], "behind": [14, 25], "proport": [14, 24], "encourag": [14, 24], "distant": 14, "0000": [14, 25], "0625": 14, "1250": 14, "1875": 14, "0039": 14, "0078": 14, "0117": 14, "create_alibi_multipli": 14, "geometr": 14, "ratio": [14, 24, 25, 26], "With": [14, 26], "16": [14, 24, 25, 26, 27], "5000": 14, "2500": [14, 25], "0312": 14, "0156": 14, "7071": 14, "3536": 14, "1768": 14, "0884": 14, "0442": 14, "0221": 14, "0110": 14, "0055": 14, "create_alibi_slop": 14, "slope": 14, "triangl": 14, "lower": [14, 15, 16, 24, 25, 26], "bottom": [14, 26], "corner": 14, "query_input": 14, "key_input": 14, "value_input": 14, "past_kv_cache_entri": 14, "hookedtransformerkeyvaluecacheentri": [14, 19], "additive_attention_mask": 14, "irrelev": [14, 25, 26], "past": [14, 19, 25], "rotate_every_two": 14, "x0": 14, "x1": 14, "bertblock": 14, "transformerblock": 14, "except": [14, 25, 26], "overridden": [14, 17, 24], "subclass": [14, 17], "recip": [14, 17], "afterward": [14, 17], "former": [14, 17], "regist": [14, 17], "latter": [14, 17, 26], "silent": [14, 17], "bertemb": 14, "input_id": 14, "bertmlmhead": 14, "purpos": [14, 15, 25, 26], "resid": 14, "gatedmlp": 14, "equat": 14, "pre_linear": 14, "normalis": [14, 25], "posemb": 14, "rm": 14, "root": [14, 26], "rmsnormpr": 14, "tokentypeemb": 14, "1810": 14, "04805": 14, "block_index": 14, "positional_embeddings_typ": 14, "_description_": 14, "_type_": [14, 17], "evalu": [15, 17, 25, 26], "rough": [15, 26], "anyth": [15, 25], "properli": [15, 25], "cheapli": 15, "compar": [15, 26, 28], "baselin": 15, "ioidataset": 15, "noun": 15, "num_sampl": 15, "symmetr": 15, "ioi_ev": 15, "100": [15, 25, 26], "476": 15, "met": 15, "alic": 15, "bob": 15, "charli": 15, "ball": [15, 25], "book": 15, "397": 15, "get_default_nam": 15, "get_default_noun": 15, "get_default_templ": 15, "get_sampl": 15, "evaluate_on_dataset": 15, "data_load": 15, "induction_loss": [15, 26], "subseq_len": 15, "384": [15, 26], "accuraci": [15, 16, 24], "make_code_data_load": 15, "codeparrot": [15, 24], "dump": 15, "presum": [15, 25], "natur": [15, 25, 26], "make_owt_data_load": 15, "corpu": [15, 24], "make_pile_data_load": 15, "eleutherai": [15, 18], "english": [15, 26, 28], "academ": 15, "internet": [15, 26], "make_wiki_data_load": 15, "wikitext": 15, "wikipedia": [15, 24, 26], "articl": [15, 24, 25, 26], "realli": [15, 16, 24, 25, 26], "expect": [15, 16, 25, 26], "anyon": 15, "bother": 15, "quarantin": 15, "nowadai": 15, "leakag": 15, "though": [15, 24, 25, 26], "sanity_check": 15, "feed": [15, 24, 26], "paragraph": [15, 26], "zoom": [15, 20, 25], "quick": [15, 16, 26], "saniti": [15, 25], "ok": [15, 25, 26], "gone": [15, 25, 26], "wrong": [15, 17, 25], "compute_head_attention_similarity_scor": 16, "attention_pattern": [16, 26], "detection_pattern": 16, "exclude_bo": 16, "exclude_current_token": 16, "error_measur": 16, "mul": 16, "comparison": 16, "exclude_bcurrent_token": 16, "detect_head": 16, "seq": [16, 24], "previous_token_head": 16, "duplicate_token_head": 16, "induction_head": 16, "headnam": 16, "itself": [16, 24, 25], "divid": [16, 24, 25], "straightforward": [16, 25], "big": [16, 18, 24, 25, 26], "fraction": 16, "alloc": 16, "prohibit": 16, "disabl": [16, 17, 25], "cours": [16, 25], "raw": [16, 25], "interv": 16, "perfect": [16, 25], "mismatch": 16, "precis": [16, 20, 25, 26], "examin": 16, "switch": 16, "advantag": 16, "closer": 16, "head_nam": 16, "exist": [16, 25, 26], "ntensor": 16, "ioi": [16, 25, 26], "spacifi": 16, "analyz": 16, "paid": [16, 25, 26], "get_duplicate_token_head_detection_pattern": 16, "duplic": [16, 25, 26], "dynalist": 16, "n2zwtnoyhru1s4vnfsaq519j": 16, "2ukvedzonghl5uhugvhroxeo": 16, "get_induction_head_detection_pattern": 16, "_tfvup5csv5orithmqwj0gsi": 16, "get_previous_token_head_detection_pattern": 16, "0o5vohe9xezn8ertywkh7ioc": 16, "get_supported_head": 16, "inspir": [17, 26, 28], "garcon": [17, 26, 28], "act": [17, 20, 24, 25, 26], "ident": [17, 24, 25, 26], "wrap": [17, 26], "add_hook": [17, 25], "fn": 17, "hook_nam": 17, "add_perma_hook": [17, 26], "clear_context": 17, "remove_hook": 17, "including_perman": 17, "build": [17, 26, 28], "interfac": [17, 26, 28], "nice": [17, 25], "variou": [17, 25, 26], "run_with_hook": [17, 25, 26], "temporari": [17, 24, 26], "persist": 17, "debug": [17, 18, 21], "fix": [17, 25, 26], "still": [17, 25], "solv": [17, 25, 26, 28], "intent": 17, "reset_hook": [17, 26], "accident": 17, "goe": [17, 25, 26], "reset_hooks_end": [17, 25], "add_caching_hook": 17, "names_filt": [17, 25], "callabl": [17, 20], "incl_bwd": 17, "namesfilt": 17, "lambda": [17, 25, 26], "cache_al": 17, "cache_som": 17, "check_and_add_hook": 17, "get_caching_hook": 17, "fwd_hook": [17, 25, 26], "bwd_hook": 17, "exit": [17, 24], "clear": [17, 26], "whenev": 17, "reset": 17, "my_hook": 17, "hooked_loss": 17, "remove_all_hook_fn": 17, "model_kwarg": 17, "everyth": [17, 20, 26], "degrad": 17, "lenshandl": 17, "removablehandl": 17, "context_level": 17, "hold": 17, "perman": 17, "hug": 18, "face": 18, "hub": [18, 24], "768": [18, 25, 26, 27], "layer_norm_ep": 18, "init_rang": 18, "1024": [18, 24, 26, 27], "3072": [18, 26, 27], "12": [18, 25, 26, 27], "model_alias": 18, "arthurconmi": 18, "redwood_attn_2l": [18, 27], "baidicoot": 18, "codellama": [18, 27], "instruct": [18, 26, 27], "hf": 18, "codellamallama": [18, 27], "6b": [18, 26, 27], "3b": [18, 26, 27], "125m": [18, 26, 27], "20b": [18, 26, 27], "pythia": [18, 27], "4b": [18, 27], "dedup": [18, 27], "v0": [18, 27], "12b": [18, 27], "13b": [18, 26, 27], "14m": [18, 27], "160m": [18, 27], "seed1": [18, 27], "seed2": [18, 27], "seed3": [18, 27], "1b": [18, 27], "800m": 18, "8b": [18, 26, 27], "31m": [18, 27], "410m": [18, 27], "350m": 18, "9b": [18, 27], "70m": [18, 27], "19m": [18, 27], "chat": [18, 26, 27], "2l512w": 18, "lr": [18, 21], "attn_only_1l512w_c4_cod": 18, "c4": [18, 24, 26], "attn_only_2l512w_c4_cod": 18, "attn_only_3l512w_c4_cod": 18, "attn_only_4l512w_c4_cod": 18, "gelu_1l512w_c4_cod": 18, "gelu_2l512w_c4_cod": 18, "gelu_3l512w_c4_cod": 18, "gelu_4l512w_c4_cod": 18, "solu_10l1280w_c4_cod": 18, "10l": [18, 26, 27], "solu_10l_v22_old": 18, "solu_12l1536w_c4_cod": 18, "12l": [18, 26, 27], "solu_12l_v23_old": 18, "solu_1l512w_c4_cod": 18, "solu_1l512w_wiki_finetun": 18, "wiki": [18, 24, 25, 26, 27], "finetun": 18, "solu_1l_v9_old": 18, "solu_2l512w_c4_cod": 18, "solu_2l_v10_old": 18, "solu_3l512w_c4_cod": 18, "solu_4l512w_c4_cod": 18, "solu_4l512w_wiki_finetun": 18, "solu_4l_v11_old": 18, "solu_6l768w_c4_cod": 18, "6l": [18, 26, 27], "solu_6l_v13_old": 18, "solu_8l1024w_c4_cod": 18, "8l": [18, 26, 27], "solu_8l_v21_old": 18, "qwen": [18, 27], "14b": [18, 27], "1_8b": 18, "bigcod": 18, "santacod": [18, 27], "bigscienc": 18, "560m": [18, 27], "distilgpt2": [18, 26], "distillgpt2": [18, 27], "distil": [18, 26], "facebook": 18, "xxl": 18, "30b": [18, 26, 27], "xxxl": 18, "xl": [18, 26, 27], "66b": [18, 26, 27], "xxxxl": 18, "65b": [18, 27], "roneneldan": 18, "tinystori": 18, "1layer": 18, "21m": [18, 27], "28m": [18, 27], "2layer": 18, "33m": [18, 27], "3m": [18, 27], "8m": [18, 27], "instuct": 18, "stabilityai": 18, "stablelm": [18, 26, 27], "alpha": [18, 27], "x21": 18, "arwen": 18, "battlestar": 18, "x49": 18, "beren": 18, "caprica": 18, "x81": 18, "celebrimbor": 18, "darkmatt": 18, "x343": 18, "durin": 18, "eowyn": 18, "x777": 18, "expans": 18, "alias": 18, "offici": [18, 26], "convert_bloom_weight": 18, "convert_coder_weight": 18, "convert_qwen_weight": 18, "get_checkpoint_label": [18, 26], "label_typ": 18, "get_num_params_of_pretrain": 18, "suffici": [18, 25], "get_pretrained_model_config": 18, "automodel": 18, "autoconfig": 18, "infrastructur": [18, 25, 26, 28], "ourselv": [19, 26, 28], "previous_attention_mask": 19, "pos_so_far": 19, "append": [19, 25, 26], "prefix": 19, "append_attention_mask": 19, "new_token": 19, "freez": 19, "init_cach": 19, "unfreez": 19, "past_kei": 19, "jaxtyp": [19, 25, 26], "past_valu": 19, "new_kei": 19, "new_valu": 19, "init_cache_entri": 19, "structur": [20, 26], "generic_activation_patch": 20, "specialis": [20, 25], "introduc": [20, 25], "rome": [20, 25, 26], "baulab": 20, "shift": [20, 26], "corrupt": [20, 25, 26], "continu": [20, 25, 26], "iter": [20, 24, 25, 26], "increas": [20, 25, 26], "localis": [20, 25, 26], "__from__": 20, "__to": 20, "__the": 20, "confid": [20, 25, 26], "intuit": [20, 25, 26], "diffus": [20, 25], "spread": [20, 25], "connect": [20, 25], "ultim": [20, 25], "engin": [20, 25, 26, 28], "least": [20, 26], "tend": [20, 26], "extrem": [20, 25, 26, 28], "eiffel": 20, "tower": 20, "pari": 20, "factual": [20, 25], "recal": [20, 25], "colosseum": 20, "anywher": 20, "corrupted_token": [20, 25, 26], "clean_cach": [20, 25, 26], "patching_metr": 20, "patch_sett": 20, "index_axis_nam": 20, "src_po": [20, 25], "dest_po": [20, 25, 26], "index_df": 20, "datafram": 20, "return_index_df": 20, "counterfactu": [20, 25, 26], "Then": 20, "index_to_act_nam": 20, "recov": [20, 25, 26], "diff": [20, 25], "corrupted_activ": 20, "chunk": 20, "fill": 20, "flatten": [20, 25, 26], "patched_output": 20, "get_act_patch_attn_head_all_pos_everi": 20, "patch_typ": 20, "get_act_patch_attn_head_by_pos_everi": 20, "get_act_patch_attn_head_k_all_po": 20, "corruptedactiv": 20, "patchedactiv": 20, "layer_head_vector_patch_sett": 20, "axisnam": 20, "get_act_patch_attn_head_k_by_po": 20, "layer_pos_head_vector_patch_sett": 20, "get_act_patch_attn_head_out_all_po": 20, "get_act_patch_attn_head_out_by_po": 20, "get_act_patch_attn_head_pattern_all_po": 20, "layer_head_pattern_patch_sett": 20, "get_act_patch_attn_head_pattern_by_po": 20, "layer_head_pos_pattern_patch_sett": 20, "get_act_patch_attn_head_pattern_dest_src_po": 20, "layer_head_dest_src_pos_pattern_patch_sett": 20, "get_act_patch_attn_head_q_all_po": 20, "get_act_patch_attn_head_q_by_po": 20, "get_act_patch_attn_head_v_all_po": 20, "get_act_patch_attn_head_v_by_po": 20, "get_act_patch_attn_out": 20, "layer_pos_patch_sett": 20, "get_act_patch_block_everi": 20, "get_act_patch_mlp_out": 20, "get_act_patch_resid_mid": 20, "get_act_patch_resid_pr": 20, "clean_activ": 20, "hookedtransformertrainconfig": 21, "num_epoch": 21, "001": 21, "momentum": 21, "max_grad_norm": 21, "weight_decai": 21, "optimizer_nam": 21, "adam": 21, "warmup_step": 21, "save_everi": 21, "save_dir": 21, "wandb": 21, "wandb_project_nam": 21, "print_everi": 21, "max_step": 21, "hyperparamet": [21, 24], "epoch": 21, "rate": [21, 26], "decai": 21, "warmup": 21, "wandb_project": 21, "termin": 21, "assist": 23, "get_device_for_block_index": 23, "target": 23, "move_to_and_update_config": 23, "vari": [24, 25], "throughout": [24, 26], "locallyoverridendefault": 24, "restor": 24, "overriden": 24, "input_slic": 24, "syntax": [24, 25, 26], "reduc": [24, 25, 26], "extra": 24, "leav": [24, 26], "elif": 24, "1d": 24, "sliceinput": 24, "valueerror": 24, "abov": [24, 25, 26], "max_ctx": 24, "int32": 24, "composition_scor": 24, "home": 24, "runner": 24, "broadcast_dim": 24, "leading_dims_left_and_right": 24, "download_file_from_hf": 24, "repo_nam": 24, "file_nam": 24, "subfold": 24, "force_is_torch": 24, "json": 24, "pth": 24, "extens": [24, 25], "layer_typ": [24, 25], "shorthand": 24, "feedback": [24, 25, 26, 28], "loop": [24, 25, 26, 28], "hack": [24, 26], "stuff": [24, 26], "readabl": 24, "digit": [24, 26], "word": [24, 25, 26], "k6": 24, "scale4ln1": 24, "appear": [24, 26], "distinguish": [24, 25], "hook_k": [24, 26], "hook_pr": [24, 26], "27": [24, 25, 26], "hook_norm": [24, 26], "pre5": 24, "get_attention_mask": 24, "leftmost": 24, "rightmost": 24, "consid": 24, "get_cumsum_along_dim": 24, "dataset_nam": 24, "explor": [24, 26], "000": [24, 26], "enorm": [24, 26], "100gb": 24, "2tb": 24, "effort": [24, 25], "dataload": 24, "fanci": 24, "data_dir": 24, "approx": [24, 25, 26], "co": 24, "ton": [24, 28], "divers": [24, 25, 26], "coloss": 24, "crawl": 24, "bigger": 24, "c4_code": 24, "friendli": 24, "22m": [24, 26], "5m": 24, "20220301": 24, "en": [24, 26], "get_devic": [24, 25, 26], "get_input_with_manually_prepended_bo": 24, "autotoken": 24, "get_nested_attr": 24, "obj": 24, "attr_str": 24, "retriev": 24, "nest": 24, "hierarchi": 24, "get_offset_position_id": 24, "offset": [24, 25, 26], "get_tokenizer_with_bo": 24, "Such": [24, 25], "llamatoken": 24, "get_tokens_with_bos_remov": 24, "is_lower_triangular": 24, "is_squar": 24, "keep_single_column": 24, "col_nam": 24, "lm_accuraci": 24, "seq_len": [24, 25, 26], "altern": 24, "override_or_use_default_valu": 24, "default_flag": 24, "print_gpu_mem": 24, "step_nam": 24, "sample_logit": 24, "final_logit": [24, 25], "vocab_s": 24, "high": [24, 25, 26], "argmaxi": 24, "90": 24, "renormalis": 24, "mutual": 24, "neither": [24, 25], "input_token": 24, "todo": 24, "edg": 24, "randn": [24, 26], "uniqu": 24, "return_count": 24, "set_nested_attr": 24, "prepend_space_to_answ": 24, "eleph": 24, "endoftext": [24, 25, 26], "14": [24, 25, 26], "51": [24, 26], "0th": [24, 25], "59": [24, 26, 27], "ground": [24, 25], "1th": [24, 25], "41": [24, 26], "18": [24, 25, 26], "tree": 24, "2th": [24, 25], "3th": [24, 25], "45": [24, 26], "car": 24, "4th": [24, 25], "13": [24, 25, 26], "92": [24, 25], "55": [24, 25, 26], "river": 24, "5th": [24, 25], "79": 24, "25": [24, 25, 26, 27], "street": 24, "6th": [24, 25], "77": 24, "21": [24, 25, 26], "7th": [24, 25], "75": 24, "hill": 24, "8th": [24, 25], "swing": 24, "9th": [24, 25], "46": [24, 26], "61": [24, 27], "park": [24, 25], "ever": 24, "improv": [24, 25, 26], "to_numpi": [24, 25, 26], "tokenize_and_concaten": 24, "max_length": 24, "column_nam": 24, "num_proc": 24, "eo": [24, 26], "reshap": [24, 25], "____": 24, "drop": [24, 26], "faster": [24, 25, 26], "parallelis": [24, 26], "chop": 24, "20": [24, 25, 26, 27], "privileg": 24, "earli": [24, 26], "cnn": [24, 26], "bos_token_id": 24, "swap": [24, 25], "regardless": 24, "runtim": [25, 26], "hardwar": [25, 26], "acceler": [25, 26], "tabl": [25, 26], "pane": [25, 26], "sidebar": [25, 26], "navig": [25, 26], "vscode": [25, 26], "outlin": 25, "tab": 25, "section": [25, 26], "dropdown": [25, 26], "arrow": [25, 26], "page": [25, 26], "ctrl": [25, 26], "repo": 25, "in_colab": [25, 26], "circuitsvi": [25, 26], "node": [25, 26], "curl": [25, 26], "fssl": [25, 26], "deb": [25, 26], "nodesourc": [25, 26], "setup_16": [25, 26], "sudo": [25, 26], "bash": [25, 26], "apt": [25, 26], "nodej": [25, 26], "noqa": [25, 26], "ipython": [25, 26], "get_ipython": [25, 26], "ip": [25, 26], "extension_manag": [25, 26], "autoreload": [25, 26], "functool": [25, 26], "plotli": [25, 26], "express": [25, 26], "px": [25, 26], "pio": [25, 26], "attention_head": 25, "fancy_einsum": [25, 26], "ifram": 25, "differenti": [25, 26], "simplic": 25, "imshow": [25, 26], "color_continuous_midpoint": [25, 26], "color_continuous_scal": [25, 26], "rdbu": [25, 26], "line": [25, 26], "scatter": [25, 26], "xaxi": [25, 26], "yaxi": [25, 26], "caxi": [25, 26], "color": [25, 26], "principl": [25, 26, 28], "fun": [25, 26, 28], "ml": [25, 26, 28], "gap": [25, 26, 28], "feel": [25, 26, 28], "plai": [25, 26, 28], "flow": [25, 26, 28], "goal": [25, 26, 28], "toolkit": [25, 26], "stylist": 25, "slowli": 25, "convei": 25, "simpl": [25, 26], "tag": 25, "asid": 25, "flavour": 25, "weed": 25, "star": 25, "tagexampl": 25, "capabl": [25, 26], "interview": [25, 26], "kevin": [25, 26], "wang": 25, "twitter": 25, "thread": 25, "overview": 25, "bottl": [25, 26], "milk": [25, 26], "26": [25, 26], "Their": 25, "skimp": 25, "rigour": 25, "suggest": 25, "evid": 25, "our": [25, 26], "80m": [25, 26], "simplif": 25, "nbval_ignore_output": [25, 26], "stabl": 25, "example_prompt": 25, "example_answ": 25, "39": [25, 26], "lt": [25, 26], "gt": [25, 26], "09": [25, 26], "70": 25, "07": [25, 26], "15": [25, 26], "38": [25, 26], "67": 25, "35": [25, 26], "54": [25, 26], "11": [25, 26, 27], "84": [25, 26], "73": 25, "hi": [25, 26], "06": 25, "her": [25, 26], "74": 25, "52": [25, 26, 27], "49": [25, 26], "jesu": 25, "97": 25, "42": [25, 26], "him": 25, "subword": 25, "frequent": 25, "substr": [25, 26], "massiv": [25, 26], "headach": 25, "annoi": [25, 26], "total": [25, 26], "devot": 25, "sensibl": 25, "later": [25, 26], "wherev": 25, "flesh": 25, "prompt_format": 25, "jame": 25, "dan": 25, "sid": 25, "appl": 25, "martin": 25, "ami": 25, "drink": 25, "correct_token": 25, "insert": 25, "easiest": 25, "filler": 25, "newlin": 25, "intellig": 25, "complic": 25, "adjust": [25, 26], "aggreg": 25, "original_logit": 25, "upon": 25, "subject": [25, 26], "logits_to_ave_logit_diff": 25, "per_prompt": 25, "answer_logit": 25, "gather": 25, "answer_logit_diff": 25, "detach": [25, 26], "decim": [25, 26], "original_average_logit_diff": 25, "3370": 25, "2020": 25, "7090": 25, "7970": 25, "7200": 25, "2810": 25, "6010": 25, "7670": 25, "552": 25, "put": [25, 26], "33": [25, 26], "dive": 25, "spend": [25, 26], "question": [25, 26], "engag": 25, "decent": [25, 26], "hypothes": 25, "cheat": [25, 26], "hypothesi": 25, "scienc": 25, "belief": 25, "trap": 25, "confus": [25, 26], "flounder": 25, "dogmat": 25, "Being": 25, "overconfid": 25, "unwil": 25, "realiti": 25, "contradict": 25, "flinch": 25, "disconfirm": 25, "imagin": 25, "focu": 25, "primit": 25, "nearbi": 25, "came": 25, "trigram": 25, "symmetri": 25, "earlier": [25, 26], "cancel": 25, "inhibit": 25, "spoiler": 25, "abl": [25, 26], "simplist": 25, "background": 25, "central": 25, "importantli": [25, 26], "perfectli": [25, 26], "final_residual_stream": 25, "motiv": 25, "eleg": 25, "particularli": 25, "aspect": 25, "nicer": 25, "inde": 25, "log_prob": 25, "log_softmax": 25, "logsumexp": 25, "isol": 25, "decid": 25, "pronoun": 25, "person": 25, "refin": 25, "happen": [25, 26], "rel": 25, "friendlier": 25, "varianc": 25, "almost": 25, "answer_residual_direct": 25, "logit_diff_direct": 25, "account": 25, "w_u_fold": 25, "layer_norm": 25, "unigram": [25, 26], "statist": [25, 26], "occur": [25, 26], "opposit": 25, "hook_normalis": 25, "sub_layer_typ": 25, "final_token_residual_stream": 25, "scaled_final_token_residual_stream": 25, "average_logit_diff": 25, "residual_stack_to_logit_diff": 25, "scaled_residual_stack": 25, "fascinatingli": 25, "utterli": 25, "unabl": 25, "hover": [25, 26], "n_pre": 25, "n_mid": 25, "n_post": 25, "middl": [25, 26], "accumulated_residu": 25, "logit_lens_logit_diff": 25, "arang": 25, "hover_nam": [25, 26], "terminologi": 25, "overload": 25, "kth": 25, "again": 25, "per_layer_residu": 25, "per_layer_logit_diff": 25, "independ": [25, 26, 28], "overal": 25, "l9h6": 25, "l9h9": 25, "l10h7": 25, "l11h10": 25, "harm": 25, "discuss": 25, "strongli": 25, "observ": [25, 26], "144": 25, "hand": [25, 26], "claim": 25, "abstract": [25, 26], "surpris": 25, "7x": 25, "per_head_residu": 25, "per_head_logit_diff": 25, "rearrang": 25, "weren": 25, "alan": [25, 26], "coonei": [25, 26], "illustr": [25, 26], "mistak": 25, "mayb": [25, 26], "sai": [25, 26], "period": [25, 26], "summari": 25, "sole": 25, "17": [25, 26], "visualize_attention_pattern": 25, "local_cach": 25, "local_token": 25, "max_width": 25, "700": 25, "isinst": 25, "batch_index": 25, "combin": [25, 26], "attention_head_nam": 25, "show_cod": 25, "title_html": 25, "br": 25, "div": 25, "width": [25, 26], "simpli": 25, "top_positive_logit_attr_head": 25, "positive_html": 25, "top_negative_logit_attr_head": 25, "negative_html": 25, "conceptu": 25, "clearli": 25, "compos": [25, 26], "ideal": [25, 26], "david": [25, 26], "bau": [25, 26], "meng": [25, 26], "trace": [25, 26], "anim": 25, "piec": 25, "lai": 25, "pro": 25, "con": 25, "Or": 25, "bake": 25, "claus": 25, "tack": 25, "gaussian": 25, "nois": 25, "beforehand": 25, "19": [25, 26], "corrupted_prompt": [25, 26], "corrupted_logit": [25, 26], "corrupted_cach": 25, "corrupted_average_logit_diff": 25, "temporarili": [25, 26], "patch_residual_compon": 25, "corrupted_residual_compon": 25, "normalize_patched_logit_diff": 25, "patched_logit_diff": [25, 26], "wors": [25, 26], "patched_residual_stream_diff": 25, "hook_fn": 25, "patched_logit": [25, 26], "abus": 25, "prompt_position_label": 25, "tok": 25, "_": [25, 26], "enumer": [25, 26], "reus": 25, "23": [25, 26], "patched_attn_diff": 25, "patched_mlp_diff": 25, "patched_attn_logit": 25, "patched_attn_logit_diff": 25, "patched_mlp_logit": 25, "patched_mlp_logit_diff": 25, "late": [25, 26], "contrast": 25, "statement": 25, "mlp0": 25, "destroi": 25, "guess": 25, "frame": 25, "unprincipl": 25, "invers": [25, 26], "plausibli": 25, "dedic": 25, "overcom": 25, "love": 25, "someon": 25, "That": 25, "patch_head_vector": 25, "corrupted_head_vector": 25, "patched_head_z_diff": 25, "l8h6": 25, "l8h10": 25, "l7h9": 25, "l5h5": 25, "l6h9": 25, "l3h0": 25, "semi": 25, "disentangl": 25, "familiar": 25, "28": [25, 26, 27], "patched_head_v_diff": 25, "heatmap": 25, "29": [25, 26], "against": 25, "lesson": 25, "30": [25, 26], "head_label": 25, "range_x": 25, "range_i": 25, "fact": [25, 26, 28], "31": [25, 26], "patch_head_pattern": 25, "corrupted_head_pattern": 25, "patched_head_attn_diff": 25, "32": [25, 26, 27], "reconsolid": 25, "At": 25, "transit": 25, "extend": 25, "l7h3": 25, "specul": 25, "mysteri": [25, 26], "top_heads_by_output_patch": 25, "first_mid_lay": 25, "first_late_lay": 25, "early_head": 25, "mid_head": 25, "logical_and": 25, "late_head": 25, "diagram": 25, "l1h2": 25, "latest": 25, "definit": 25, "priori": 25, "stroke": 25, "didn": 25, "bracket": 25, "minor": 25, "serv": [25, 26], "particip": 25, "behav": 25, "l5h0": 25, "had": [25, 26], "wrote": [25, 26, 28], "whole": [25, 26], "overkil": 25, "simpler": 25, "repurpos": 25, "machineri": 25, "life": [25, 26], "built": 25, "34": [25, 26], "example_text": [25, 26], "seek": 25, "machin": [25, 26], "example_repeated_text": 25, "example_repeated_token": 25, "example_repeated_logit": 25, "example_repeated_cach": 25, "induction_head_label": 25, "81": 25, "65": 25, "800": 25, "accord": 25, "wildli": 25, "mark": [25, 26], "success": 25, "characteris": 25, "superfici": 25, "boost": [25, 26], "anti": 25, "suppress": [25, 26], "pick": [25, 26], "signal": 25, "hook_": 25, "hook_attn": 25, "token_po": 25, "previous": 25, "metadata": 25, "36": [25, 26, 27], "prev_token_scor": 25, "prev_token_hook": 25, "dim1": [25, 26], "dim2": [25, 26], "duplicate_token_scor": 25, "duplicate_token_hook": 25, "induction_scor": [25, 26], "induction_hook": 25, "manual_se": [25, 26], "original_token": 25, "randint": [25, 26], "20000": [25, 26], "repeated_token": [25, 26], "pattern_filt": 25, "act_nam": [25, 26], "endswith": [25, 26], "hook_pattern": [25, 26], "0390": 25, "0310": 25, "1890": 25, "1720": 25, "0680": 25, "1570": 25, "0210": 25, "4820": 25, "0030": 25, "1320": 25, "0050": 25, "0020": 25, "0090": 25, "0040": 25, "0010": 25, "instantli": 25, "37": [25, 26], "bit": [25, 26], "seen": [25, 26], "proof": 25, "mosaic": 25, "40": [25, 26, 27], "fascin": 25, "knock": 25, "naiv": [25, 26], "convers": 25, "flaw": 25, "knockout": 25, "send": 25, "redund": 25, "job": 25, "underestim": 25, "57": [25, 26], "99": [25, 26], "hook_z": [25, 26], "top_name_mov": 25, "top_name_mover_lay": 25, "top_name_mover_head": 25, "ablate_top_head_hook": 25, "ablated_logit": 25, "ablated_cach": 25, "2f": [25, 26], "l10h10": 25, "margin": 25, "obvious": 25, "per_head_ablated_residu": 25, "per_head_ablated_logit_diff": 25, "04": [25, 26], "uniformli": [25, 26], "042": 25, "5200": 25, "4700": 25, "8200": 25, "5100": 25, "2600": 25, "1800": 25, "4300": 25, "5700": 25, "3500": 25, "2900": 25, "6800": 25, "4900": 25, "8700": 25, "4200": 25, "reader": [25, 26], "becom": [25, 26], "gentler": 26, "tip": 26, "o": 26, "development_mod": 26, "in_github": 26, "getenv": 26, "github_act": 26, "render": 26, "argh": 26, "notebook_connect": 26, "cv": 26, "hello": 26, "auto": 26, "autograd": 26, "grad_mod": 26, "0x7f24817abf10": 26, "todai": [26, 28], "speak": [26, 28], "human": [26, 28], "palm": [26, 28], "nor": [26, 28], "offend": [26, 28], "greatli": [26, 28], "jump": 26, "anthrop": [26, 28], "team": [26, 28], "got": [26, 28], "frustrat": [26, 28], "deepspe": [26, 28], "littl": [26, 28], "industri": [26, 28], "heavili": [26, 28], "credit": [26, 28], "nelson": [26, 28], "elhag": [26, 28], "chri": [26, 28], "olah": [26, 28], "model_description_text": 26, "hyper": 26, "1758": 26, "box": 26, "On": 26, "insid": 26, "kinda": 26, "gpt2_cache_no_batch_dim": 26, "gpt2_cach": 26, "gpt2_text": 26, "summar": 26, "supervis": 26, "taskspecif": 26, "gpt2_token": 26, "gpt2_logit": 26, "lock": 26, "grid": 26, "gpt2_str_token": 26, "neural": 26, "system": 26, "perspect": 26, "surgic": 26, "power": 26, "surround": 26, "current_activation_valu": 26, "new_activation_valu": 26, "substitut": 26, "relationship": 26, "underr": 26, "incredibli": 26, "janki": 26, "shamelessli": 26, "probepoint": 26, "qualiti": 26, "head_ablation_hook": 26, "layer_to_abl": 26, "head_index_to_abl": 26, "original_loss": 26, "ablated_loss": 26, "3f": 26, "999": 26, "453": 26, "stai": 26, "clean_prompt": 26, "clean_token": 26, "logits_to_logit_diff": 26, "correct_answ": 26, "incorrect_answ": 26, "correct_index": 26, "incorrect_index": 26, "clean_logit": 26, "clean_logit_diff": 26, "corrupted_logit_diff": 26, "276": 26, "738": 26, "residual_stream_patching_hook": 26, "clean_resid_pr": 26, "num_posit": 26, "ioi_patching_result": 26, "temp_hook_fn": 26, "ish": 26, "token_label": 26, "workflow": 26, "michael": 26, "jordan": 26, "surnam": 26, "terribl": 26, "halfwai": 26, "input_tensor": 26, "random_token": 26, "repeated_logit": 26, "correct_log_prob": 26, "loss_by_posit": 26, "manipul": 26, "hook_funct": 26, "induction_score_stor": 26, "induction_score_hook": 26, "induction_strip": 26, "pattern_hook_names_filt": 26, "highli": 26, "stripe": 26, "induction_head_lay": 26, "induction_head_index": 26, "single_random_sequ": 26, "repeated_random_sequ": 26, "visualize_pattern_hook": 26, "3d": 26, "four": 26, "300m": 26, "soon": 26, "distilgpt": 26, "distilgpt2_induction_score_stor": 26, "classic": 26, "openai": 26, "85m": [26, 27], "700m": 26, "5b": [26, 27], "22b": 26, "300b": 26, "180b": 26, "600": 26, "265": 26, "108m": 26, "bookscorpu": 26, "free": 26, "512": [26, 27], "tractabl": 26, "motif": 26, "80": [26, 27], "shuffl": 26, "scan": 26, "hope": 26, "40m": 26, "100m": 26, "200m": 26, "340m": [26, 27], "older": 26, "15b": 26, "13m": [26, 27], "digress": 26, "usefulli": 26, "variengien": 26, "websit": 26, "adapt": 26, "cleantransformerdemo": 26, "new_activ": 26, "old_activ": 26, "remind": 26, "50267": 26, "named_paramet": 26, "startswith": 26, "fallback": 26, "spam": 26, "dest_posit": 26, "brown": 26, "fox": 26, "lazi": 26, "dog": 26, "num": 26, "print_name_shape_hook_funct": 26, "not_in_late_block_filt": 26, "hook_q": 26, "hook_v": 26, "hook_attn_scor": 26, "hook_attn_out": 26, "hook_resid_mid": 26, "hook_post": 26, "hook_mlp_out": 26, "hook_resid_post": 26, "preconcept": 26, "pain": 26, "overhead": 26, "elementwis": 26, "consequ": 26, "rare": 26, "dramat": 26, "degre": 26, "punctuat": 26, "ass": 26, "randomredditor": 26, "unembed_bia": 26, "bias_valu": 26, "bias_indic": 26, "sort": 26, "repr": 26, "03": 26, "98": 26, "68": 26, "48": [26, 27], "47": 26, "88": 26, "72": [26, 27], "44": [26, 27], "82": 26, "\u30b5\u30fc\u30c6\u30a3": 26, "83": 26, "x18": 26, "x14": 26, "\u9f8d": 26, "x1b": 26, "x05": 26, "x00": 26, "x06": 26, "x07": 26, "x0c": 26, "x02": 26, "oreandonlin": 26, "x11": 26, "x10": 26, "favour": 26, "6x": 26, "john_bia": 26, "mary_bia": 26, "4f": 26, "exp": 26, "8995": 26, "6034": 26, "6550x": 26, "mention": 26, "finit": 26, "invert": 26, "de": 26, "uncommon": 26, "iz": 26, "charact": 26, "example_text_str_token": 26, "example_text_token": 26, "50256": 26, "464": 26, "717": 26, "1517": 26, "345": 26, "761": 26, "284": 26, "3785": 26, "503": 26, "318": 26, "1635": 26, "4919": 26, "1243": 26, "389": 26, "11241": 26, "1143": 26, "4600": 26, "19849": 26, "1462": 26, "62": 26, "2536": 26, "482": 26, "641": 26, "63": 26, "30778": 26, "257": 26, "4731": 26, "656": 26, "262": 26, "16326": 26, "292": 26, "1351": 26, "286": 26, "850": 26, "37336": 26, "25666": 26, "290": 26, "523": 26, "8781": 26, "7301": 26, "644": 26, "2420": 26, "3073": 26, "588": 26, "1675": 26, "10176": 26, "428": 26, "1309": 26, "338": 26, "779": 26, "340": 26, "319": 26, "7322": 26, "signifi": 26, "example_multi_text": 26, "cat": 26, "sat": 26, "mat": 26, "example_multi_text_token": 26, "3797": 26, "3332": 26, "2603": 26, "1107": 26, "1327": 26, "th": 26, "cat_text": 26, "cat_logit": 26, "cat_prob": 26, "capital_the_token_index": 26, "ascii": 26, "squeez": 26, "annoy": 26, "arithmet": 26, "impress": 26, "2342": 26, "2017": 26, "21445": 26, "1000000": 26, "999999": 26, "214": 26, "000000": 26, "9999": 26, "tim": 26, "ne": 26, "el": 26, "messier": 26, "takeawai": 26, "unexpect": 26, "notic": 26, "trip": 26, "confusingli": 26, "forth": 26, "despit": 26, "ioi_logits_with_bo": 26, "clair": 26, "mary_logit_with_bo": 26, "claire_logit_with_bo": 26, "ioi_logits_without_bo": 26, "mary_logit_without_bo": 26, "claire_logit_without_bo": 26, "754": 26, "782": 26, "air": 26, "understood": 26, "requisit": 26, "attention_scor": 26, "ab_factor": 26, "9105": 26, "linalg": 26, "eig": 26, "2877e": 26, "00": 26, "8626e": 26, "3121e": 26, "9038e": 26, "08": 26, "1527e": 26, "2877": 26, "3121": 26, "3126e": 26, "3963e": 26, "2029e": 26, "7690e": 26, "2164e": 26, "3126": 26, "3963": 26, "smallest": 26, "300": 26, "abc": 26, "abc_factor": 26, "unfactor": 26, "160": 26, "0830": 26, "43": 26, "ab_unfactor": 26, "isclos": 26, "subspac": 26, "coincid": 26, "assert": 26, "negat": 26, "proxi": 26, "lambda_i": 26, "ov_circuit_all_head": 26, "ov_circuit_all_heads_eigenvalu": 26, "complex64": 26, "ov_copying_scor": 26, "zmax": 26, "zmin": 26, "l11h11": 26, "imag": 26, "imaginari": 26, "full_ov_circuit": 26, "full_ov_circuit_eigenvalu": 26, "full_ov_copying_scor": 26, "interestingli": 26, "correl": 26, "outlier": 26, "thank": 26, "ansh": 26, "radhakrishnan": 26, "establish": 26, "53": 26, "presid": 26, "barack": 26, "obama": 26, "caught": 26, "embarrass": 26, "scandal": 26, "nthe": 26, "financi": 26, "said": 26, "he": 26, "talk": 26, "wife": 26, "chelsea": 26, "she": 26, "woman": 26, "lightweight": 26, "bundl": 26, "squarethenadd": 26, "hook_squar": 26, "twolayermodel": 26, "layer1": 26, "layer2": 26, "hook_in": 26, "hook_mid": 26, "hook_out": 26, "x_in": 26, "x_mid": 26, "x_out": 26, "model_out": 26, "cache_object": 26, "780": 26, "784": 26, "56": [26, 27], "set_to_zero_hook": 26, "num_checkpoint": 26, "piecewis": 26, "schedul": 26, "crash": 26, "11b": [26, 27], "centr": 26, "hoc": 26, "count": 26, "checkpoint_label": 26, "log_i": 26, "marker": 26, "brief": 26, "suddenli": 26, "500": 26, "visibl": 26, "bump": 26, "curv": 26, "briefli": 26, "deliber": 26, "justic": 26, "chosen": 26, "60": [26, 27], "500m": 26, "58": 26, "arbitrarili": 26, "fast": 26, "checkpoint_indic": 26, "checkpointed_model": 26, "tokens_trained_on": 26, "model_for_this_checkpoint": 26, "tokens_seen_for_this_checkpoint": 26, "induction_loss_for_this_checkpoint": 26, "contextualis": 26, "strategi": 26, "95": 26, "log_x": 26, "302m": 27, "4096": 27, "708m": 27, "1280": 27, "5120": 27, "1600": 27, "6400": 27, "42m": 27, "2048": 27, "50272": 27, "2b": 27, "8192": 27, "2560": 27, "10240": 27, "128": 27, "16384": 27, "20480": 27, "7168": 27, "28672": 27, "9216": 27, "36864": 27, "50400": 27, "6144": 27, "50432": 27, "96": 27, "24576": 27, "2m": 27, "50304": 27, "7m": 27, "805m": 27, "50688": 27, "50278": 27, "736": 27, "2944": 27, "101m": 27, "197m": 27, "1536": 27, "48262": 27, "4m": 27, "0m": 27, "50277": 27, "524k": 27, "50259": 27, "0b": 27, "32000": 27, "11008": 27, "13824": 27, "25b": 27, "6656": 27, "17920": 27, "50b": 27, "22016": 27, "32016": 27, "25m": 27, "28996": 27, "393k": 27, "6m": 27, "250880": 27, "49280": 27, "944m": 27, "151936": 27, "5504": 27, "152064": 27, "13696": 27, "formerli": 28, "transfer": 28}, "objects": {"transformer_lens": [[8, 0, 0, "-", "ActivationCache"], [9, 0, 0, "-", "FactoredMatrix"], [10, 0, 0, "-", "HookedEncoder"], [11, 0, 0, "-", "HookedTransformer"], [12, 0, 0, "-", "HookedTransformerConfig"], [13, 0, 0, "-", "SVDInterpreter"], [14, 0, 0, "-", "components"], [15, 0, 0, "-", "evals"], [16, 0, 0, "-", "head_detector"], [17, 0, 0, "-", "hook_points"], [18, 0, 0, "-", "loading_from_pretrained"], [19, 0, 0, "-", "past_key_value_caching"], [20, 0, 0, "-", "patching"], [21, 0, 0, "-", "train"], [24, 0, 0, "-", "utils"]], "transformer_lens.ActivationCache": [[8, 1, 1, "", "ActivationCache"]], "transformer_lens.ActivationCache.ActivationCache": [[8, 2, 1, "", "accumulated_resid"], [8, 2, 1, "", "apply_ln_to_stack"], [8, 2, 1, "", "apply_slice_to_batch_dim"], [8, 2, 1, "", "compute_head_results"], [8, 2, 1, "", "decompose_resid"], [8, 2, 1, "", "get_full_resid_decomposition"], [8, 2, 1, "", "get_neuron_results"], [8, 2, 1, "", "items"], [8, 2, 1, "", "keys"], [8, 2, 1, "", "logit_attrs"], [8, 2, 1, "", "remove_batch_dim"], [8, 2, 1, "", "stack_activation"], [8, 2, 1, "", "stack_head_results"], [8, 2, 1, "", "stack_neuron_results"], [8, 2, 1, "", "to"], [8, 2, 1, "", "toggle_autodiff"], [8, 2, 1, "", "values"]], "transformer_lens.FactoredMatrix": [[9, 1, 1, "", "FactoredMatrix"]], "transformer_lens.FactoredMatrix.FactoredMatrix": [[9, 3, 1, "", "AB"], [9, 3, 1, "", "BA"], [9, 3, 1, "", "S"], [9, 3, 1, "", "T"], [9, 3, 1, "", "U"], [9, 3, 1, "", "Vh"], [9, 2, 1, "", "collapse_l"], [9, 2, 1, "", "collapse_r"], [9, 3, 1, "", "eigenvalues"], [9, 2, 1, "", "get_corner"], [9, 2, 1, "", "make_even"], [9, 3, 1, "", "ndim"], [9, 2, 1, "", "norm"], [9, 3, 1, "", "pair"], [9, 2, 1, "", "svd"], [9, 2, 1, "", "unsqueeze"]], "transformer_lens.HookedEncoder": [[10, 1, 1, "", "HookedEncoder"]], "transformer_lens.HookedEncoder.HookedEncoder": [[10, 3, 1, "", "OV"], [10, 3, 1, "", "QK"], [10, 3, 1, "", "W_E"], [10, 3, 1, "", "W_E_pos"], [10, 3, 1, "", "W_K"], [10, 3, 1, "", "W_O"], [10, 3, 1, "", "W_Q"], [10, 3, 1, "", "W_U"], [10, 3, 1, "", "W_V"], [10, 3, 1, "", "W_in"], [10, 3, 1, "", "W_out"], [10, 3, 1, "", "W_pos"], [10, 2, 1, "", "all_head_labels"], [10, 3, 1, "", "b_K"], [10, 3, 1, "", "b_O"], [10, 3, 1, "", "b_Q"], [10, 3, 1, "", "b_U"], [10, 3, 1, "", "b_V"], [10, 3, 1, "", "b_in"], [10, 3, 1, "", "b_out"], [10, 2, 1, "", "cpu"], [10, 2, 1, "", "cuda"], [10, 2, 1, "", "forward"], [10, 2, 1, "", "from_pretrained"], [10, 2, 1, "", "mps"], [10, 2, 1, "", "run_with_cache"], [10, 2, 1, "", "to"]], "transformer_lens.HookedTransformer": [[11, 1, 1, "", "HookedTransformer"], [11, 1, 1, "", "Output"]], "transformer_lens.HookedTransformer.HookedTransformer": [[11, 3, 1, "", "OV"], [11, 3, 1, "", "QK"], [11, 3, 1, "", "W_E"], [11, 3, 1, "", "W_E_pos"], [11, 3, 1, "", "W_K"], [11, 3, 1, "", "W_O"], [11, 3, 1, "", "W_Q"], [11, 3, 1, "", "W_U"], [11, 3, 1, "", "W_V"], [11, 3, 1, "", "W_gate"], [11, 3, 1, "", "W_in"], [11, 3, 1, "", "W_out"], [11, 3, 1, "", "W_pos"], [11, 2, 1, "", "__init__"], [11, 2, 1, "", "accumulated_bias"], [11, 2, 1, "", "all_composition_scores"], [11, 2, 1, "", "all_head_labels"], [11, 3, 1, "", "b_K"], [11, 3, 1, "", "b_O"], [11, 3, 1, "", "b_Q"], [11, 3, 1, "", "b_U"], [11, 3, 1, "", "b_V"], [11, 3, 1, "", "b_in"], [11, 3, 1, "", "b_out"], [11, 2, 1, "", "center_unembed"], [11, 2, 1, "", "center_writing_weights"], [11, 2, 1, "", "check_hooks_to_add"], [11, 2, 1, "", "cpu"], [11, 2, 1, "", "cuda"], [11, 2, 1, "", "fold_layer_norm"], [11, 2, 1, "", "fold_value_biases"], [11, 2, 1, "", "forward"], [11, 2, 1, "", "from_pretrained"], [11, 2, 1, "", "from_pretrained_no_processing"], [11, 2, 1, "", "generate"], [11, 2, 1, "", "get_token_position"], [11, 2, 1, "", "init_weights"], [11, 2, 1, "", "input_to_embed"], [11, 2, 1, "", "load_and_process_state_dict"], [11, 2, 1, "", "load_sample_training_dataset"], [11, 2, 1, "", "loss_fn"], [11, 2, 1, "", "move_model_modules_to_device"], [11, 2, 1, "", "mps"], [11, 2, 1, "", "process_weights_"], [11, 2, 1, "", "refactor_factored_attn_matrices"], [11, 2, 1, "", "run_with_cache"], [11, 2, 1, "", "sample_datapoint"], [11, 2, 1, "", "set_tokenizer"], [11, 2, 1, "", "set_use_attn_in"], [11, 2, 1, "", "set_use_attn_result"], [11, 2, 1, "", "set_use_hook_mlp_in"], [11, 2, 1, "", "set_use_split_qkv_input"], [11, 2, 1, "", "to"], [11, 2, 1, "", "to_single_str_token"], [11, 2, 1, "", "to_single_token"], [11, 2, 1, "", "to_str_tokens"], [11, 2, 1, "", "to_string"], [11, 2, 1, "", "to_tokens"], [11, 2, 1, "", "tokens_to_residual_directions"]], "transformer_lens.HookedTransformer.Output": [[11, 4, 1, "", "logits"], [11, 4, 1, "", "loss"]], "transformer_lens.HookedTransformerConfig": [[12, 1, 1, "", "HookedTransformerConfig"]], "transformer_lens.HookedTransformerConfig.HookedTransformerConfig": [[12, 4, 1, "", "act_fn"], [12, 4, 1, "", "attention_dir"], [12, 4, 1, "", "attn_only"], [12, 4, 1, "", "attn_types"], [12, 4, 1, "", "checkpoint_index"], [12, 4, 1, "", "checkpoint_label_type"], [12, 4, 1, "", "checkpoint_value"], [12, 4, 1, "", "d_head"], [12, 4, 1, "", "d_mlp"], [12, 4, 1, "", "d_model"], [12, 4, 1, "", "d_vocab"], [12, 4, 1, "", "d_vocab_out"], [12, 4, 1, "", "default_prepend_bos"], [12, 4, 1, "", "device"], [12, 4, 1, "", "dtype"], [12, 4, 1, "", "eps"], [12, 4, 1, "", "final_rms"], [12, 4, 1, "", "from_checkpoint"], [12, 2, 1, "", "from_dict"], [12, 4, 1, "", "gated_mlp"], [12, 4, 1, "", "init_mode"], [12, 4, 1, "", "init_weights"], [12, 4, 1, "", "initializer_range"], [12, 4, 1, "", "model_name"], [12, 4, 1, "", "n_ctx"], [12, 4, 1, "", "n_devices"], [12, 4, 1, "", "n_heads"], [12, 4, 1, "", "n_layers"], [12, 4, 1, "", "n_params"], [12, 4, 1, "", "normalization_type"], [12, 4, 1, "", "original_architecture"], [12, 4, 1, "", "parallel_attn_mlp"], [12, 4, 1, "", "positional_embedding_type"], [12, 4, 1, "", "post_embedding_ln"], [12, 4, 1, "", "rotary_adjacent_pairs"], [12, 4, 1, "", "rotary_base"], [12, 4, 1, "", "rotary_dim"], [12, 4, 1, "", "scale_attn_by_inverse_layer_idx"], [12, 4, 1, "", "seed"], [12, 2, 1, "", "set_seed_everywhere"], [12, 2, 1, "", "to_dict"], [12, 4, 1, "", "tokenizer_name"], [12, 4, 1, "", "tokenizer_prepends_bos"], [12, 4, 1, "", "trust_remote_code"], [12, 4, 1, "", "use_attn_in"], [12, 4, 1, "", "use_attn_result"], [12, 4, 1, "", "use_attn_scale"], [12, 4, 1, "", "use_hook_mlp_in"], [12, 4, 1, "", "use_hook_tokens"], [12, 4, 1, "", "use_local_attn"], [12, 4, 1, "", "use_split_qkv_input"], [12, 4, 1, "", "window_size"]], "transformer_lens.SVDInterpreter": [[13, 1, 1, "", "SVDInterpreter"]], "transformer_lens.SVDInterpreter.SVDInterpreter": [[13, 2, 1, "", "get_singular_vectors"]], "transformer_lens.components": [[14, 1, 1, "", "Attention"], [14, 1, 1, "", "BertBlock"], [14, 1, 1, "", "BertEmbed"], [14, 1, 1, "", "BertMLMHead"], [14, 1, 1, "", "Embed"], [14, 1, 1, "", "GatedMLP"], [14, 1, 1, "", "LayerNorm"], [14, 1, 1, "", "LayerNormPre"], [14, 1, 1, "", "MLP"], [14, 1, 1, "", "PosEmbed"], [14, 1, 1, "", "RMSNorm"], [14, 1, 1, "", "RMSNormPre"], [14, 1, 1, "", "TokenTypeEmbed"], [14, 1, 1, "", "TransformerBlock"], [14, 1, 1, "", "Unembed"]], "transformer_lens.components.Attention": [[14, 3, 1, "", "OV"], [14, 3, 1, "", "QK"], [14, 2, 1, "", "__init__"], [14, 2, 1, "", "apply_causal_mask"], [14, 2, 1, "", "apply_rotary"], [14, 2, 1, "", "calculate_sin_cos_rotary"], [14, 2, 1, "", "create_alibi_bias"], [14, 2, 1, "", "create_alibi_multipliers"], [14, 2, 1, "", "create_alibi_slope"], [14, 2, 1, "", "forward"], [14, 2, 1, "", "rotate_every_two"]], "transformer_lens.components.BertBlock": [[14, 2, 1, "", "forward"]], "transformer_lens.components.BertEmbed": [[14, 2, 1, "", "forward"]], "transformer_lens.components.BertMLMHead": [[14, 2, 1, "", "forward"]], "transformer_lens.components.Embed": [[14, 2, 1, "", "forward"]], "transformer_lens.components.GatedMLP": [[14, 2, 1, "", "forward"]], "transformer_lens.components.LayerNorm": [[14, 2, 1, "", "__init__"], [14, 2, 1, "", "forward"]], "transformer_lens.components.LayerNormPre": [[14, 2, 1, "", "__init__"], [14, 2, 1, "", "forward"]], "transformer_lens.components.MLP": [[14, 2, 1, "", "forward"]], "transformer_lens.components.PosEmbed": [[14, 2, 1, "", "forward"]], "transformer_lens.components.RMSNorm": [[14, 2, 1, "", "__init__"], [14, 2, 1, "", "forward"]], "transformer_lens.components.RMSNormPre": [[14, 2, 1, "", "__init__"], [14, 2, 1, "", "forward"]], "transformer_lens.components.TokenTypeEmbed": [[14, 2, 1, "", "forward"]], "transformer_lens.components.TransformerBlock": [[14, 2, 1, "", "forward"]], "transformer_lens.components.Unembed": [[14, 2, 1, "", "forward"]], "transformer_lens.evals": [[15, 1, 1, "", "IOIDataset"], [15, 5, 1, "", "evaluate"], [15, 5, 1, "", "evaluate_on_dataset"], [15, 5, 1, "", "induction_loss"], [15, 5, 1, "", "ioi_eval"], [15, 5, 1, "", "make_code_data_loader"], [15, 5, 1, "", "make_owt_data_loader"], [15, 5, 1, "", "make_pile_data_loader"], [15, 5, 1, "", "make_wiki_data_loader"], [15, 5, 1, "", "sanity_check"]], "transformer_lens.evals.IOIDataset": [[15, 2, 1, "", "get_default_names"], [15, 2, 1, "", "get_default_nouns"], [15, 2, 1, "", "get_default_templates"], [15, 2, 1, "", "get_sample"]], "transformer_lens.head_detector": [[16, 5, 1, "", "compute_head_attention_similarity_score"], [16, 5, 1, "", "detect_head"], [16, 5, 1, "", "get_duplicate_token_head_detection_pattern"], [16, 5, 1, "", "get_induction_head_detection_pattern"], [16, 5, 1, "", "get_previous_token_head_detection_pattern"], [16, 5, 1, "", "get_supported_heads"]], "transformer_lens.hook_points": [[17, 1, 1, "", "HookPoint"], [17, 1, 1, "", "HookedRootModule"], [17, 1, 1, "", "LensHandle"]], "transformer_lens.hook_points.HookPoint": [[17, 2, 1, "", "add_hook"], [17, 2, 1, "", "add_perma_hook"], [17, 2, 1, "", "clear_context"], [17, 2, 1, "", "forward"], [17, 2, 1, "", "layer"], [17, 2, 1, "", "remove_hooks"]], "transformer_lens.hook_points.HookedRootModule": [[17, 2, 1, "", "add_caching_hooks"], [17, 2, 1, "", "add_hook"], [17, 2, 1, "", "add_perma_hook"], [17, 2, 1, "", "cache_all"], [17, 2, 1, "", "cache_some"], [17, 2, 1, "", "check_and_add_hook"], [17, 2, 1, "", "check_hooks_to_add"], [17, 2, 1, "", "clear_contexts"], [17, 2, 1, "", "get_caching_hooks"], [17, 2, 1, "", "hook_points"], [17, 2, 1, "", "hooks"], [17, 2, 1, "", "remove_all_hook_fns"], [17, 2, 1, "", "reset_hooks"], [17, 2, 1, "", "run_with_cache"], [17, 2, 1, "", "run_with_hooks"], [17, 2, 1, "", "setup"]], "transformer_lens.hook_points.LensHandle": [[17, 4, 1, "", "context_level"], [17, 4, 1, "", "hook"], [17, 4, 1, "", "is_permanent"]], "transformer_lens.loading_from_pretrained": [[18, 1, 1, "", "Config"], [18, 6, 1, "", "MODEL_ALIASES"], [18, 6, 1, "", "OFFICIAL_MODEL_NAMES"], [18, 5, 1, "", "convert_bloom_weights"], [18, 5, 1, "", "convert_coder_weights"], [18, 5, 1, "", "convert_qwen_weights"], [18, 5, 1, "", "get_checkpoint_labels"], [18, 5, 1, "", "get_num_params_of_pretrained"], [18, 5, 1, "", "get_pretrained_model_config"]], "transformer_lens.loading_from_pretrained.Config": [[18, 4, 1, "", "d_head"], [18, 4, 1, "", "d_mlp"], [18, 4, 1, "", "d_model"], [18, 4, 1, "", "d_vocab"], [18, 4, 1, "", "debug"], [18, 4, 1, "", "init_range"], [18, 4, 1, "", "layer_norm_eps"], [18, 4, 1, "", "n_ctx"], [18, 4, 1, "", "n_heads"], [18, 4, 1, "", "n_layers"]], "transformer_lens.past_key_value_caching": [[19, 1, 1, "", "HookedTransformerKeyValueCache"], [19, 1, 1, "", "HookedTransformerKeyValueCacheEntry"]], "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache": [[19, 2, 1, "", "append_attention_mask"], [19, 4, 1, "", "entries"], [19, 2, 1, "", "freeze"], [19, 4, 1, "", "frozen"], [19, 2, 1, "", "init_cache"], [19, 4, 1, "", "previous_attention_mask"], [19, 2, 1, "", "unfreeze"]], "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry": [[19, 2, 1, "", "append"], [19, 4, 1, "", "frozen"], [19, 2, 1, "", "init_cache_entry"], [19, 4, 1, "", "past_keys"], [19, 4, 1, "", "past_values"]], "transformer_lens.patching": [[20, 5, 1, "", "generic_activation_patch"], [20, 5, 1, "", "get_act_patch_attn_head_all_pos_every"], [20, 5, 1, "", "get_act_patch_attn_head_by_pos_every"], [20, 5, 1, "", "get_act_patch_attn_head_k_all_pos"], [20, 5, 1, "", "get_act_patch_attn_head_k_by_pos"], [20, 5, 1, "", "get_act_patch_attn_head_out_all_pos"], [20, 5, 1, "", "get_act_patch_attn_head_out_by_pos"], [20, 5, 1, "", "get_act_patch_attn_head_pattern_all_pos"], [20, 5, 1, "", "get_act_patch_attn_head_pattern_by_pos"], [20, 5, 1, "", "get_act_patch_attn_head_pattern_dest_src_pos"], [20, 5, 1, "", "get_act_patch_attn_head_q_all_pos"], [20, 5, 1, "", "get_act_patch_attn_head_q_by_pos"], [20, 5, 1, "", "get_act_patch_attn_head_v_all_pos"], [20, 5, 1, "", "get_act_patch_attn_head_v_by_pos"], [20, 5, 1, "", "get_act_patch_attn_out"], [20, 5, 1, "", "get_act_patch_block_every"], [20, 5, 1, "", "get_act_patch_mlp_out"], [20, 5, 1, "", "get_act_patch_resid_mid"], [20, 5, 1, "", "get_act_patch_resid_pre"], [20, 5, 1, "", "layer_head_dest_src_pos_pattern_patch_setter"], [20, 5, 1, "", "layer_head_pattern_patch_setter"], [20, 5, 1, "", "layer_head_pos_pattern_patch_setter"], [20, 5, 1, "", "layer_head_vector_patch_setter"], [20, 5, 1, "", "layer_pos_head_vector_patch_setter"], [20, 5, 1, "", "layer_pos_patch_setter"]], "transformer_lens.train": [[21, 1, 1, "", "HookedTransformerTrainConfig"], [21, 5, 1, "", "train"]], "transformer_lens.train.HookedTransformerTrainConfig": [[21, 4, 1, "", "batch_size"], [21, 4, 1, "", "device"], [21, 4, 1, "", "lr"], [21, 4, 1, "", "max_grad_norm"], [21, 4, 1, "", "max_steps"], [21, 4, 1, "", "momentum"], [21, 4, 1, "", "num_epochs"], [21, 4, 1, "", "optimizer_name"], [21, 4, 1, "", "print_every"], [21, 4, 1, "", "save_dir"], [21, 4, 1, "", "save_every"], [21, 4, 1, "", "seed"], [21, 4, 1, "", "wandb"], [21, 4, 1, "", "wandb_project_name"], [21, 4, 1, "", "warmup_steps"], [21, 4, 1, "", "weight_decay"]], "transformer_lens.utilities": [[23, 0, 0, "-", "devices"]], "transformer_lens.utilities.devices": [[23, 5, 1, "", "get_device_for_block_index"], [23, 5, 1, "", "move_to_and_update_config"]], "transformer_lens.utils": [[24, 1, 1, "", "LocallyOverridenDefaults"], [24, 1, 1, "", "Slice"], [24, 6, 1, "", "SliceInput"], [24, 5, 1, "", "composition_scores"], [24, 5, 1, "", "download_file_from_hf"], [24, 5, 1, "", "gelu_fast"], [24, 5, 1, "", "gelu_new"], [24, 5, 1, "", "get_act_name"], [24, 5, 1, "", "get_attention_mask"], [24, 5, 1, "", "get_corner"], [24, 5, 1, "", "get_cumsum_along_dim"], [24, 5, 1, "", "get_dataset"], [24, 5, 1, "", "get_device"], [24, 5, 1, "", "get_input_with_manually_prepended_bos"], [24, 5, 1, "", "get_nested_attr"], [24, 5, 1, "", "get_offset_position_ids"], [24, 5, 1, "", "get_tokenizer_with_bos"], [24, 5, 1, "", "get_tokens_with_bos_removed"], [24, 5, 1, "", "is_lower_triangular"], [24, 5, 1, "", "is_square"], [24, 5, 1, "", "keep_single_column"], [24, 5, 1, "", "lm_accuracy"], [24, 5, 1, "", "lm_cross_entropy_loss"], [24, 5, 1, "", "override_or_use_default_value"], [24, 5, 1, "", "print_gpu_mem"], [24, 5, 1, "", "remove_batch_dim"], [24, 5, 1, "", "sample_logits"], [24, 5, 1, "", "set_nested_attr"], [24, 5, 1, "", "solu"], [24, 5, 1, "", "test_prompt"], [24, 5, 1, "", "to_numpy"], [24, 5, 1, "", "tokenize_and_concatenate"], [24, 5, 1, "", "transpose"]], "transformer_lens.utils.LocallyOverridenDefaults": [[24, 2, 1, "", "__init__"]], "transformer_lens.utils.Slice": [[24, 2, 1, "", "__init__"], [24, 2, 1, "", "apply"], [24, 2, 1, "", "indices"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:property", "4": "py:attribute", "5": "py:function", "6": "py:data"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "function", "Python function"], "6": ["py", "data", "Python data"]}, "titleterms": {"citat": 0, "contribut": 1, "setup": [1, 25, 26], "devcontain": 1, "manual": 1, "test": 1, "run": [1, 26], "format": 1, "document": 1, "docstr": 1, "style": 1, "guid": 1, "section": 1, "order": 1, "support": 1, "sphinx": 1, "properti": [1, 27], "refer": 1, "other": [1, 26], "function": [1, 25], "class": [1, 26], "math": 1, "markup": 1, "galleri": 2, "get": [3, 4], "start": [3, 4, 5], "advic": 3, "read": [3, 25], "code": 3, "instal": 3, "mechanist": [4, 28], "interpret": [4, 26, 28], "tutori": 5, "where": 5, "To": 5, "demo": [5, 25, 26], "transform": [6, 26], "len": [6, 25, 26], "api": 6, "content": 6, "transformer_len": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "submodul": [7, 22], "subpackag": 7, "activationcach": 8, "factoredmatrix": 9, "hookedencod": 10, "hookedtransform": 11, "hookedtransformerconfig": 12, "svdinterpret": 13, "compon": 14, "eval": 15, "head_detector": 16, "hook_point": 17, "loading_from_pretrain": 18, "past_key_value_cach": 19, "patch": [20, 25, 26], "train": [21, 26], "util": [22, 23, 24], "devic": 23, "exploratori": 25, "analysi": 25, "tip": 25, "thi": 25, "environ": 25, "ignor": 25, "import": [25, 26], "pytorch": 25, "plot": 25, "helper": 25, "introduct": [25, 26], "indirect": [25, 26], "object": [25, 26], "identif": [25, 26], "brainstorm": 25, "what": 25, "": 25, "actual": 25, "go": 25, "On": 25, "option": 25, "direct": 25, "logit": 25, "attribut": 25, "layer": 25, "head": [25, 26], "attent": 25, "activ": [25, 26], "residu": 25, "stream": 25, "decompos": 25, "consolid": 25, "understand": 25, "visual": 25, "pattern": 25, "compar": 25, "paper": 25, "bonu": 25, "explor": 25, "anomali": 25, "earli": 25, "ar": 25, "induct": [25, 26], "implic": 25, "backup": 25, "name": [25, 26], "mover": 25, "main": 26, "notebook": 26, "load": 26, "model": [26, 27, 28], "cach": 26, "all": 26, "hook": 26, "interven": 26, "task": 26, "access": 26, "avail": 26, "an": 26, "overview": 26, "open": 26, "sourc": 26, "librari": [26, 28], "some": 26, "friendli": 26, "i": 26, "ve": 26, "includ": 26, "resourc": 26, "architectur": 26, "paramet": 26, "fold": 26, "layernorm": 26, "For": 26, "curiou": 26, "featur": 26, "deal": 26, "token": 26, "gotcha": 26, "prepend_bo": 26, "factor": 26, "matrix": 26, "basic": 26, "exampl": 26, "medium": 26, "eigenvalu": 26, "copi": 26, "score": 26, "gener": [26, 28], "text": 26, "point": 26, "toi": 26, "pre": 26, "checkpoint": 26, "phase": 26, "transit": 26, "tabl": 27, "transformerlen": 28, "A": 28, "languag": 28}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx": 57}, "alltitles": {"Citation": [[0, "citation"]], "Contributing": [[1, "contributing"]], "Setup": [[1, "setup"], [25, "Setup"], [26, "Setup"]], "DevContainer": [[1, "devcontainer"]], "Manual Setup": [[1, "manual-setup"]], "Testing": [[1, "testing"]], "Running the tests": [[1, "running-the-tests"]], "Formatting": [[1, "formatting"]], "Documentation": [[1, "documentation"]], "Docstring Style Guide": [[1, "docstring-style-guide"]], "Sections and Order": [[1, "sections-and-order"]], "Supported Sphinx Properties": [[1, "supported-sphinx-properties"]], "References to Other Functions/Classes": [[1, "references-to-other-functions-classes"]], "Maths": [[1, "maths"]], "Markup": [[1, "markup"]], "Gallery": [[2, "gallery"]], "Getting Started": [[3, "getting-started"]], "Advice for Reading the Code": [[3, "advice-for-reading-the-code"]], "Installation": [[3, "installation"]], "Getting Started in Mechanistic Interpretability": [[4, "getting-started-in-mechanistic-interpretability"]], "Tutorials": [[5, "tutorials"]], "Where To Start": [[5, "where-to-start"]], "Demos": [[5, "demos"]], "Transformer Lens API": [[6, "transformer-lens-api"]], "Contents": [[6, "contents"]], "transformer_lens": [[7, "transformer-lens"]], "Submodules": [[7, "submodules"], [22, "submodules"]], "Subpackages": [[7, "subpackages"]], "transformer_lens.ActivationCache": [[8, "module-transformer_lens.ActivationCache"]], "transformer_lens.FactoredMatrix": [[9, "module-transformer_lens.FactoredMatrix"]], "transformer_lens.HookedEncoder": [[10, "module-transformer_lens.HookedEncoder"]], "transformer_lens.HookedTransformer": [[11, "module-transformer_lens.HookedTransformer"]], "transformer_lens.HookedTransformerConfig": [[12, "module-transformer_lens.HookedTransformerConfig"]], "transformer_lens.SVDInterpreter": [[13, "module-transformer_lens.SVDInterpreter"]], "transformer_lens.components": [[14, "module-transformer_lens.components"]], "transformer_lens.evals": [[15, "module-transformer_lens.evals"]], "transformer_lens.head_detector": [[16, "module-transformer_lens.head_detector"]], "transformer_lens.hook_points": [[17, "module-transformer_lens.hook_points"]], "transformer_lens.loading_from_pretrained": [[18, "module-transformer_lens.loading_from_pretrained"]], "transformer_lens.past_key_value_caching": [[19, "module-transformer_lens.past_key_value_caching"]], "transformer_lens.patching": [[20, "module-transformer_lens.patching"]], "transformer_lens.train": [[21, "module-transformer_lens.train"]], "transformer_lens.utilities": [[22, "transformer-lens-utilities"]], "transformer_lens.utilities.devices": [[23, "module-transformer_lens.utilities.devices"]], "transformer_lens.utils": [[24, "module-transformer_lens.utils"]], "Exploratory Analysis Demo": [[25, "Exploratory-Analysis-Demo"]], "Tips for Reading This": [[25, "Tips-for-Reading-This"]], "Environment Setup (ignore)": [[25, "Environment-Setup-(ignore)"]], "Imports": [[25, "Imports"]], "PyTorch Setup": [[25, "PyTorch-Setup"]], "Plotting Helper Functions (ignore)": [[25, "Plotting-Helper-Functions-(ignore)"]], "Introduction": [[25, "Introduction"], [26, "Introduction"]], "Indirect Object Identification": [[25, "Indirect-Object-Identification"]], "Brainstorm What\u2019s Actually Going On (Optional)": [[25, "Brainstorm-What's-Actually-Going-On-(Optional)"]], "Direct Logit Attribution": [[25, "Direct-Logit-Attribution"]], "Logit Lens": [[25, "Logit-Lens"]], "Layer Attribution": [[25, "Layer-Attribution"]], "Head Attribution": [[25, "Head-Attribution"]], "Attention Analysis": [[25, "Attention-Analysis"]], "Activation Patching": [[25, "Activation-Patching"]], "Residual Stream": [[25, "Residual-Stream"]], "Layers": [[25, "Layers"]], "Heads": [[25, "Heads"]], "Decomposing Heads": [[25, "Decomposing-Heads"]], "Consolidating Understanding": [[25, "Consolidating-Understanding"]], "Visualizing Attention Patterns": [[25, "Visualizing-Attention-Patterns"]], "Comparing to the Paper": [[25, "Comparing-to-the-Paper"]], "Bonus: Exploring Anomalies": [[25, "Bonus:-Exploring-Anomalies"]], "Early Heads are Induction Heads(?!)": [[25, "Early-Heads-are-Induction-Heads(?!)"]], "Implications": [[25, "Implications"]], "Backup Name Mover Heads": [[25, "Backup-Name-Mover-Heads"]], "Transformer Lens Main Demo Notebook": [[26, "Transformer-Lens-Main-Demo-Notebook"]], "Loading and Running Models": [[26, "Loading-and-Running-Models"]], "Caching all Activations": [[26, "Caching-all-Activations"]], "Hooks: Intervening on Activations": [[26, "Hooks:-Intervening-on-Activations"]], "Activation Patching on the Indirect Object Identification Task": [[26, "Activation-Patching-on-the-Indirect-Object-Identification-Task"]], "Hooks: Accessing Activations": [[26, "Hooks:-Accessing-Activations"]], "Available Models": [[26, "Available-Models"]], "An overview of the important open source models in the library": [[26, "An-overview-of-the-important-open-source-models-in-the-library"]], "An overview of some interpretability-friendly models I\u2019ve trained and included": [[26, "An-overview-of-some-interpretability-friendly-models-I've-trained-and-included"]], "Other Resources:": [[26, "Other-Resources:"]], "Transformer architecture": [[26, "Transformer-architecture"]], "Parameter Names": [[26, "Parameter-Names"]], "Activation + Hook Names": [[26, "Activation-+-Hook-Names"]], "Folding LayerNorm (For the Curious)": [[26, "Folding-LayerNorm-(For-the-Curious)"]], "Features": [[26, "Features"]], "Dealing with tokens": [[26, "Dealing-with-tokens"]], "Gotcha: prepend_bos": [[26, "Gotcha:-prepend_bos"]], "Factored Matrix Class": [[26, "Factored-Matrix-Class"]], "Basic Examples": [[26, "Basic-Examples"]], "Medium Example: Eigenvalue Copying Scores": [[26, "Medium-Example:-Eigenvalue-Copying-Scores"]], "Generating Text": [[26, "Generating-Text"]], "Hook Points": [[26, "Hook-Points"]], "Toy Example": [[26, "Toy-Example"]], "Loading Pre-Trained Checkpoints": [[26, "Loading-Pre-Trained-Checkpoints"]], "Example: Induction Head Phase Transition": [[26, "Example:-Induction-Head-Phase-Transition"]], "Model Properties Table": [[27, "model-properties-table"]], "TransformerLens": [[28, "transformerlens"]], "A Library for Mechanistic Interpretability of Generative Language Models": [[28, "a-library-for-mechanistic-interpretability-of-generative-language-models"]]}, "indexentries": {"activationcache (class in transformer_lens.activationcache)": [[8, "transformer_lens.ActivationCache.ActivationCache"]], "accumulated_resid() (transformer_lens.activationcache.activationcache method)": [[8, "transformer_lens.ActivationCache.ActivationCache.accumulated_resid"]], "apply_ln_to_stack() (transformer_lens.activationcache.activationcache method)": [[8, "transformer_lens.ActivationCache.ActivationCache.apply_ln_to_stack"]], "apply_slice_to_batch_dim() (transformer_lens.activationcache.activationcache method)": [[8, "transformer_lens.ActivationCache.ActivationCache.apply_slice_to_batch_dim"]], "compute_head_results() (transformer_lens.activationcache.activationcache method)": [[8, "transformer_lens.ActivationCache.ActivationCache.compute_head_results"]], "decompose_resid() (transformer_lens.activationcache.activationcache method)": [[8, "transformer_lens.ActivationCache.ActivationCache.decompose_resid"]], "get_full_resid_decomposition() (transformer_lens.activationcache.activationcache method)": [[8, "transformer_lens.ActivationCache.ActivationCache.get_full_resid_decomposition"]], "get_neuron_results() (transformer_lens.activationcache.activationcache method)": [[8, "transformer_lens.ActivationCache.ActivationCache.get_neuron_results"]], "items() (transformer_lens.activationcache.activationcache method)": [[8, "transformer_lens.ActivationCache.ActivationCache.items"]], "keys() (transformer_lens.activationcache.activationcache method)": [[8, "transformer_lens.ActivationCache.ActivationCache.keys"]], "logit_attrs() (transformer_lens.activationcache.activationcache method)": [[8, "transformer_lens.ActivationCache.ActivationCache.logit_attrs"]], "module": [[8, "module-transformer_lens.ActivationCache"], [9, "module-transformer_lens.FactoredMatrix"], [10, "module-transformer_lens.HookedEncoder"], [11, "module-transformer_lens.HookedTransformer"], [12, "module-transformer_lens.HookedTransformerConfig"], [13, "module-transformer_lens.SVDInterpreter"], [14, "module-transformer_lens.components"], [15, "module-transformer_lens.evals"], [16, "module-transformer_lens.head_detector"], [17, "module-transformer_lens.hook_points"], [18, "module-transformer_lens.loading_from_pretrained"], [19, "module-transformer_lens.past_key_value_caching"], [20, "module-transformer_lens.patching"], [21, "module-transformer_lens.train"], [23, "module-transformer_lens.utilities.devices"], [24, "module-transformer_lens.utils"]], "remove_batch_dim() (transformer_lens.activationcache.activationcache method)": [[8, "transformer_lens.ActivationCache.ActivationCache.remove_batch_dim"]], "stack_activation() (transformer_lens.activationcache.activationcache method)": [[8, "transformer_lens.ActivationCache.ActivationCache.stack_activation"]], "stack_head_results() (transformer_lens.activationcache.activationcache method)": [[8, "transformer_lens.ActivationCache.ActivationCache.stack_head_results"]], "stack_neuron_results() (transformer_lens.activationcache.activationcache method)": [[8, "transformer_lens.ActivationCache.ActivationCache.stack_neuron_results"]], "to() (transformer_lens.activationcache.activationcache method)": [[8, "transformer_lens.ActivationCache.ActivationCache.to"]], "toggle_autodiff() (transformer_lens.activationcache.activationcache method)": [[8, "transformer_lens.ActivationCache.ActivationCache.toggle_autodiff"]], "transformer_lens.activationcache": [[8, "module-transformer_lens.ActivationCache"]], "values() (transformer_lens.activationcache.activationcache method)": [[8, "transformer_lens.ActivationCache.ActivationCache.values"]], "ab (transformer_lens.factoredmatrix.factoredmatrix property)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.AB"]], "ba (transformer_lens.factoredmatrix.factoredmatrix property)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.BA"]], "factoredmatrix (class in transformer_lens.factoredmatrix)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix"]], "s (transformer_lens.factoredmatrix.factoredmatrix property)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.S"]], "t (transformer_lens.factoredmatrix.factoredmatrix property)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.T"]], "u (transformer_lens.factoredmatrix.factoredmatrix property)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.U"]], "vh (transformer_lens.factoredmatrix.factoredmatrix property)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.Vh"]], "collapse_l() (transformer_lens.factoredmatrix.factoredmatrix method)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.collapse_l"]], "collapse_r() (transformer_lens.factoredmatrix.factoredmatrix method)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.collapse_r"]], "eigenvalues (transformer_lens.factoredmatrix.factoredmatrix property)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.eigenvalues"]], "get_corner() (transformer_lens.factoredmatrix.factoredmatrix method)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.get_corner"]], "make_even() (transformer_lens.factoredmatrix.factoredmatrix method)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.make_even"]], "ndim (transformer_lens.factoredmatrix.factoredmatrix property)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.ndim"]], "norm() (transformer_lens.factoredmatrix.factoredmatrix method)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.norm"]], "pair (transformer_lens.factoredmatrix.factoredmatrix property)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.pair"]], "svd() (transformer_lens.factoredmatrix.factoredmatrix method)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.svd"]], "transformer_lens.factoredmatrix": [[9, "module-transformer_lens.FactoredMatrix"]], "unsqueeze() (transformer_lens.factoredmatrix.factoredmatrix method)": [[9, "transformer_lens.FactoredMatrix.FactoredMatrix.unsqueeze"]], "hookedencoder (class in transformer_lens.hookedencoder)": [[10, "transformer_lens.HookedEncoder.HookedEncoder"]], "ov (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.OV"]], "qk (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.QK"]], "w_e (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.W_E"]], "w_e_pos (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.W_E_pos"]], "w_k (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.W_K"]], "w_o (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.W_O"]], "w_q (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.W_Q"]], "w_u (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.W_U"]], "w_v (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.W_V"]], "w_in (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.W_in"]], "w_out (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.W_out"]], "w_pos (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.W_pos"]], "all_head_labels() (transformer_lens.hookedencoder.hookedencoder method)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.all_head_labels"]], "b_k (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.b_K"]], "b_o (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.b_O"]], "b_q (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.b_Q"]], "b_u (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.b_U"]], "b_v (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.b_V"]], "b_in (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.b_in"]], "b_out (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.b_out"]], "cpu() (transformer_lens.hookedencoder.hookedencoder method)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.cpu"]], "cuda() (transformer_lens.hookedencoder.hookedencoder method)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.cuda"]], "forward() (transformer_lens.hookedencoder.hookedencoder method)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.forward"]], "from_pretrained() (transformer_lens.hookedencoder.hookedencoder class method)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.from_pretrained"]], "mps() (transformer_lens.hookedencoder.hookedencoder method)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.mps"]], "run_with_cache() (transformer_lens.hookedencoder.hookedencoder method)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.run_with_cache"]], "to() (transformer_lens.hookedencoder.hookedencoder method)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.to"]], "transformer_lens.hookedencoder": [[10, "module-transformer_lens.HookedEncoder"]], "hookedtransformer (class in transformer_lens.hookedtransformer)": [[11, "transformer_lens.HookedTransformer.HookedTransformer"]], "ov (transformer_lens.hookedtransformer.hookedtransformer property)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.OV"]], "output (class in transformer_lens.hookedtransformer)": [[11, "transformer_lens.HookedTransformer.Output"]], "qk (transformer_lens.hookedtransformer.hookedtransformer property)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.QK"]], "w_e (transformer_lens.hookedtransformer.hookedtransformer property)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.W_E"]], "w_e_pos (transformer_lens.hookedtransformer.hookedtransformer property)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.W_E_pos"]], "w_k (transformer_lens.hookedtransformer.hookedtransformer property)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.W_K"]], "w_o (transformer_lens.hookedtransformer.hookedtransformer property)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.W_O"]], "w_q (transformer_lens.hookedtransformer.hookedtransformer property)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.W_Q"]], "w_u (transformer_lens.hookedtransformer.hookedtransformer property)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.W_U"]], "w_v (transformer_lens.hookedtransformer.hookedtransformer property)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.W_V"]], "w_gate (transformer_lens.hookedtransformer.hookedtransformer property)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.W_gate"]], "w_in (transformer_lens.hookedtransformer.hookedtransformer property)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.W_in"]], "w_out (transformer_lens.hookedtransformer.hookedtransformer property)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.W_out"]], "w_pos (transformer_lens.hookedtransformer.hookedtransformer property)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.W_pos"]], "__init__() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.__init__"]], "accumulated_bias() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.accumulated_bias"]], "all_composition_scores() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.all_composition_scores"]], "all_head_labels() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.all_head_labels"]], "b_k (transformer_lens.hookedtransformer.hookedtransformer property)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.b_K"]], "b_o (transformer_lens.hookedtransformer.hookedtransformer property)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.b_O"]], "b_q (transformer_lens.hookedtransformer.hookedtransformer property)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.b_Q"]], "b_u (transformer_lens.hookedtransformer.hookedtransformer property)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.b_U"]], "b_v (transformer_lens.hookedtransformer.hookedtransformer property)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.b_V"]], "b_in (transformer_lens.hookedtransformer.hookedtransformer property)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.b_in"]], "b_out (transformer_lens.hookedtransformer.hookedtransformer property)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.b_out"]], "center_unembed() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.center_unembed"]], "center_writing_weights() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.center_writing_weights"]], "check_hooks_to_add() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.check_hooks_to_add"]], "cpu() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.cpu"]], "cuda() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.cuda"]], "fold_layer_norm() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.fold_layer_norm"]], "fold_value_biases() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.fold_value_biases"]], "forward() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.forward"]], "from_pretrained() (transformer_lens.hookedtransformer.hookedtransformer class method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.from_pretrained"]], "from_pretrained_no_processing() (transformer_lens.hookedtransformer.hookedtransformer class method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.from_pretrained_no_processing"]], "generate() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.generate"]], "get_token_position() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.get_token_position"]], "init_weights() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.init_weights"]], "input_to_embed() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.input_to_embed"]], "load_and_process_state_dict() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.load_and_process_state_dict"]], "load_sample_training_dataset() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.load_sample_training_dataset"]], "logits (transformer_lens.hookedtransformer.output attribute)": [[11, "transformer_lens.HookedTransformer.Output.logits"]], "loss (transformer_lens.hookedtransformer.output attribute)": [[11, "transformer_lens.HookedTransformer.Output.loss"]], "loss_fn() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.loss_fn"]], "move_model_modules_to_device() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.move_model_modules_to_device"]], "mps() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.mps"]], "process_weights_() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.process_weights_"]], "refactor_factored_attn_matrices() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.refactor_factored_attn_matrices"]], "run_with_cache() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.run_with_cache"]], "sample_datapoint() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.sample_datapoint"]], "set_tokenizer() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.set_tokenizer"]], "set_use_attn_in() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.set_use_attn_in"]], "set_use_attn_result() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.set_use_attn_result"]], "set_use_hook_mlp_in() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.set_use_hook_mlp_in"]], "set_use_split_qkv_input() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.set_use_split_qkv_input"]], "to() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.to"]], "to_single_str_token() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.to_single_str_token"]], "to_single_token() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.to_single_token"]], "to_str_tokens() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.to_str_tokens"]], "to_string() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.to_string"]], "to_tokens() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.to_tokens"]], "tokens_to_residual_directions() (transformer_lens.hookedtransformer.hookedtransformer method)": [[11, "transformer_lens.HookedTransformer.HookedTransformer.tokens_to_residual_directions"]], "transformer_lens.hookedtransformer": [[11, "module-transformer_lens.HookedTransformer"]], "hookedtransformerconfig (class in transformer_lens.hookedtransformerconfig)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig"]], "act_fn (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.act_fn"]], "attention_dir (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attention_dir"]], "attn_only (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attn_only"]], "attn_types (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attn_types"]], "checkpoint_index (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.checkpoint_index"]], "checkpoint_label_type (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.checkpoint_label_type"]], "checkpoint_value (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.checkpoint_value"]], "d_head (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_head"]], "d_mlp (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_mlp"]], "d_model (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_model"]], "d_vocab (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_vocab"]], "d_vocab_out (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_vocab_out"]], "default_prepend_bos (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.default_prepend_bos"]], "device (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.device"]], "dtype (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.dtype"]], "eps (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.eps"]], "final_rms (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.final_rms"]], "from_checkpoint (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.from_checkpoint"]], "from_dict() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig class method)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.from_dict"]], "gated_mlp (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.gated_mlp"]], "init_mode (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.init_mode"]], "init_weights (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.init_weights"]], "initializer_range (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.initializer_range"]], "model_name (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.model_name"]], "n_ctx (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_ctx"]], "n_devices (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_devices"]], "n_heads (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_heads"]], "n_layers (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_layers"]], "n_params (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_params"]], "normalization_type (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.normalization_type"]], "original_architecture (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.original_architecture"]], "parallel_attn_mlp (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.parallel_attn_mlp"]], "positional_embedding_type (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.positional_embedding_type"]], "post_embedding_ln (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.post_embedding_ln"]], "rotary_adjacent_pairs (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.rotary_adjacent_pairs"]], "rotary_base (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.rotary_base"]], "rotary_dim (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.rotary_dim"]], "scale_attn_by_inverse_layer_idx (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.scale_attn_by_inverse_layer_idx"]], "seed (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.seed"]], "set_seed_everywhere() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig method)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.set_seed_everywhere"]], "to_dict() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig method)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.to_dict"]], "tokenizer_name (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.tokenizer_name"]], "tokenizer_prepends_bos (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.tokenizer_prepends_bos"]], "transformer_lens.hookedtransformerconfig": [[12, "module-transformer_lens.HookedTransformerConfig"]], "trust_remote_code (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.trust_remote_code"]], "use_attn_in (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_attn_in"]], "use_attn_result (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_attn_result"]], "use_attn_scale (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_attn_scale"]], "use_hook_mlp_in (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_hook_mlp_in"]], "use_hook_tokens (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_hook_tokens"]], "use_local_attn (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_local_attn"]], "use_split_qkv_input (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_split_qkv_input"]], "window_size (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[12, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.window_size"]], "svdinterpreter (class in transformer_lens.svdinterpreter)": [[13, "transformer_lens.SVDInterpreter.SVDInterpreter"]], "get_singular_vectors() (transformer_lens.svdinterpreter.svdinterpreter method)": [[13, "transformer_lens.SVDInterpreter.SVDInterpreter.get_singular_vectors"]], "transformer_lens.svdinterpreter": [[13, "module-transformer_lens.SVDInterpreter"]], "attention (class in transformer_lens.components)": [[14, "transformer_lens.components.Attention"]], "bertblock (class in transformer_lens.components)": [[14, "transformer_lens.components.BertBlock"]], "bertembed (class in transformer_lens.components)": [[14, "transformer_lens.components.BertEmbed"]], "bertmlmhead (class in transformer_lens.components)": [[14, "transformer_lens.components.BertMLMHead"]], "embed (class in transformer_lens.components)": [[14, "transformer_lens.components.Embed"]], "gatedmlp (class in transformer_lens.components)": [[14, "transformer_lens.components.GatedMLP"]], "layernorm (class in transformer_lens.components)": [[14, "transformer_lens.components.LayerNorm"]], "layernormpre (class in transformer_lens.components)": [[14, "transformer_lens.components.LayerNormPre"]], "mlp (class in transformer_lens.components)": [[14, "transformer_lens.components.MLP"]], "ov (transformer_lens.components.attention property)": [[14, "transformer_lens.components.Attention.OV"]], "posembed (class in transformer_lens.components)": [[14, "transformer_lens.components.PosEmbed"]], "qk (transformer_lens.components.attention property)": [[14, "transformer_lens.components.Attention.QK"]], "rmsnorm (class in transformer_lens.components)": [[14, "transformer_lens.components.RMSNorm"]], "rmsnormpre (class in transformer_lens.components)": [[14, "transformer_lens.components.RMSNormPre"]], "tokentypeembed (class in transformer_lens.components)": [[14, "transformer_lens.components.TokenTypeEmbed"]], "transformerblock (class in transformer_lens.components)": [[14, "transformer_lens.components.TransformerBlock"]], "unembed (class in transformer_lens.components)": [[14, "transformer_lens.components.Unembed"]], "__init__() (transformer_lens.components.attention method)": [[14, "transformer_lens.components.Attention.__init__"]], "__init__() (transformer_lens.components.layernorm method)": [[14, "transformer_lens.components.LayerNorm.__init__"]], "__init__() (transformer_lens.components.layernormpre method)": [[14, "transformer_lens.components.LayerNormPre.__init__"]], "__init__() (transformer_lens.components.rmsnorm method)": [[14, "transformer_lens.components.RMSNorm.__init__"]], "__init__() (transformer_lens.components.rmsnormpre method)": [[14, "transformer_lens.components.RMSNormPre.__init__"]], "apply_causal_mask() (transformer_lens.components.attention method)": [[14, "transformer_lens.components.Attention.apply_causal_mask"]], "apply_rotary() (transformer_lens.components.attention method)": [[14, "transformer_lens.components.Attention.apply_rotary"]], "calculate_sin_cos_rotary() (transformer_lens.components.attention method)": [[14, "transformer_lens.components.Attention.calculate_sin_cos_rotary"]], "create_alibi_bias() (transformer_lens.components.attention static method)": [[14, "transformer_lens.components.Attention.create_alibi_bias"]], "create_alibi_multipliers() (transformer_lens.components.attention static method)": [[14, "transformer_lens.components.Attention.create_alibi_multipliers"]], "create_alibi_slope() (transformer_lens.components.attention static method)": [[14, "transformer_lens.components.Attention.create_alibi_slope"]], "forward() (transformer_lens.components.attention method)": [[14, "transformer_lens.components.Attention.forward"]], "forward() (transformer_lens.components.bertblock method)": [[14, "transformer_lens.components.BertBlock.forward"]], "forward() (transformer_lens.components.bertembed method)": [[14, "transformer_lens.components.BertEmbed.forward"]], "forward() (transformer_lens.components.bertmlmhead method)": [[14, "transformer_lens.components.BertMLMHead.forward"]], "forward() (transformer_lens.components.embed method)": [[14, "transformer_lens.components.Embed.forward"]], "forward() (transformer_lens.components.gatedmlp method)": [[14, "transformer_lens.components.GatedMLP.forward"]], "forward() (transformer_lens.components.layernorm method)": [[14, "transformer_lens.components.LayerNorm.forward"]], "forward() (transformer_lens.components.layernormpre method)": [[14, "transformer_lens.components.LayerNormPre.forward"]], "forward() (transformer_lens.components.mlp method)": [[14, "transformer_lens.components.MLP.forward"]], "forward() (transformer_lens.components.posembed method)": [[14, "transformer_lens.components.PosEmbed.forward"]], "forward() (transformer_lens.components.rmsnorm method)": [[14, "transformer_lens.components.RMSNorm.forward"]], "forward() (transformer_lens.components.rmsnormpre method)": [[14, "transformer_lens.components.RMSNormPre.forward"]], "forward() (transformer_lens.components.tokentypeembed method)": [[14, "transformer_lens.components.TokenTypeEmbed.forward"]], "forward() (transformer_lens.components.transformerblock method)": [[14, "transformer_lens.components.TransformerBlock.forward"]], "forward() (transformer_lens.components.unembed method)": [[14, "transformer_lens.components.Unembed.forward"]], "rotate_every_two() (transformer_lens.components.attention method)": [[14, "transformer_lens.components.Attention.rotate_every_two"]], "transformer_lens.components": [[14, "module-transformer_lens.components"]], "ioidataset (class in transformer_lens.evals)": [[15, "transformer_lens.evals.IOIDataset"]], "evaluate() (in module transformer_lens.evals)": [[15, "transformer_lens.evals.evaluate"]], "evaluate_on_dataset() (in module transformer_lens.evals)": [[15, "transformer_lens.evals.evaluate_on_dataset"]], "get_default_names() (transformer_lens.evals.ioidataset static method)": [[15, "transformer_lens.evals.IOIDataset.get_default_names"]], "get_default_nouns() (transformer_lens.evals.ioidataset static method)": [[15, "transformer_lens.evals.IOIDataset.get_default_nouns"]], "get_default_templates() (transformer_lens.evals.ioidataset static method)": [[15, "transformer_lens.evals.IOIDataset.get_default_templates"]], "get_sample() (transformer_lens.evals.ioidataset method)": [[15, "transformer_lens.evals.IOIDataset.get_sample"]], "induction_loss() (in module transformer_lens.evals)": [[15, "transformer_lens.evals.induction_loss"]], "ioi_eval() (in module transformer_lens.evals)": [[15, "transformer_lens.evals.ioi_eval"]], "make_code_data_loader() (in module transformer_lens.evals)": [[15, "transformer_lens.evals.make_code_data_loader"]], "make_owt_data_loader() (in module transformer_lens.evals)": [[15, "transformer_lens.evals.make_owt_data_loader"]], "make_pile_data_loader() (in module transformer_lens.evals)": [[15, "transformer_lens.evals.make_pile_data_loader"]], "make_wiki_data_loader() (in module transformer_lens.evals)": [[15, "transformer_lens.evals.make_wiki_data_loader"]], "sanity_check() (in module transformer_lens.evals)": [[15, "transformer_lens.evals.sanity_check"]], "transformer_lens.evals": [[15, "module-transformer_lens.evals"]], "compute_head_attention_similarity_score() (in module transformer_lens.head_detector)": [[16, "transformer_lens.head_detector.compute_head_attention_similarity_score"]], "detect_head() (in module transformer_lens.head_detector)": [[16, "transformer_lens.head_detector.detect_head"]], "get_duplicate_token_head_detection_pattern() (in module transformer_lens.head_detector)": [[16, "transformer_lens.head_detector.get_duplicate_token_head_detection_pattern"]], "get_induction_head_detection_pattern() (in module transformer_lens.head_detector)": [[16, "transformer_lens.head_detector.get_induction_head_detection_pattern"]], "get_previous_token_head_detection_pattern() (in module transformer_lens.head_detector)": [[16, "transformer_lens.head_detector.get_previous_token_head_detection_pattern"]], "get_supported_heads() (in module transformer_lens.head_detector)": [[16, "transformer_lens.head_detector.get_supported_heads"]], "transformer_lens.head_detector": [[16, "module-transformer_lens.head_detector"]], "hookpoint (class in transformer_lens.hook_points)": [[17, "transformer_lens.hook_points.HookPoint"]], "hookedrootmodule (class in transformer_lens.hook_points)": [[17, "transformer_lens.hook_points.HookedRootModule"]], "lenshandle (class in transformer_lens.hook_points)": [[17, "transformer_lens.hook_points.LensHandle"]], "add_caching_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[17, "transformer_lens.hook_points.HookedRootModule.add_caching_hooks"]], "add_hook() (transformer_lens.hook_points.hookpoint method)": [[17, "transformer_lens.hook_points.HookPoint.add_hook"]], "add_hook() (transformer_lens.hook_points.hookedrootmodule method)": [[17, "transformer_lens.hook_points.HookedRootModule.add_hook"]], "add_perma_hook() (transformer_lens.hook_points.hookpoint method)": [[17, "transformer_lens.hook_points.HookPoint.add_perma_hook"]], "add_perma_hook() (transformer_lens.hook_points.hookedrootmodule method)": [[17, "transformer_lens.hook_points.HookedRootModule.add_perma_hook"]], "cache_all() (transformer_lens.hook_points.hookedrootmodule method)": [[17, "transformer_lens.hook_points.HookedRootModule.cache_all"]], "cache_some() (transformer_lens.hook_points.hookedrootmodule method)": [[17, "transformer_lens.hook_points.HookedRootModule.cache_some"]], "check_and_add_hook() (transformer_lens.hook_points.hookedrootmodule method)": [[17, "transformer_lens.hook_points.HookedRootModule.check_and_add_hook"]], "check_hooks_to_add() (transformer_lens.hook_points.hookedrootmodule method)": [[17, "transformer_lens.hook_points.HookedRootModule.check_hooks_to_add"]], "clear_context() (transformer_lens.hook_points.hookpoint method)": [[17, "transformer_lens.hook_points.HookPoint.clear_context"]], "clear_contexts() (transformer_lens.hook_points.hookedrootmodule method)": [[17, "transformer_lens.hook_points.HookedRootModule.clear_contexts"]], "context_level (transformer_lens.hook_points.lenshandle attribute)": [[17, "transformer_lens.hook_points.LensHandle.context_level"]], "forward() (transformer_lens.hook_points.hookpoint method)": [[17, "transformer_lens.hook_points.HookPoint.forward"]], "get_caching_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[17, "transformer_lens.hook_points.HookedRootModule.get_caching_hooks"]], "hook (transformer_lens.hook_points.lenshandle attribute)": [[17, "transformer_lens.hook_points.LensHandle.hook"]], "hook_points() (transformer_lens.hook_points.hookedrootmodule method)": [[17, "transformer_lens.hook_points.HookedRootModule.hook_points"]], "hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[17, "transformer_lens.hook_points.HookedRootModule.hooks"]], "is_permanent (transformer_lens.hook_points.lenshandle attribute)": [[17, "transformer_lens.hook_points.LensHandle.is_permanent"]], "layer() (transformer_lens.hook_points.hookpoint method)": [[17, "transformer_lens.hook_points.HookPoint.layer"]], "remove_all_hook_fns() (transformer_lens.hook_points.hookedrootmodule method)": [[17, "transformer_lens.hook_points.HookedRootModule.remove_all_hook_fns"]], "remove_hooks() (transformer_lens.hook_points.hookpoint method)": [[17, "transformer_lens.hook_points.HookPoint.remove_hooks"]], "reset_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[17, "transformer_lens.hook_points.HookedRootModule.reset_hooks"]], "run_with_cache() (transformer_lens.hook_points.hookedrootmodule method)": [[17, "transformer_lens.hook_points.HookedRootModule.run_with_cache"]], "run_with_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[17, "transformer_lens.hook_points.HookedRootModule.run_with_hooks"]], "setup() (transformer_lens.hook_points.hookedrootmodule method)": [[17, "transformer_lens.hook_points.HookedRootModule.setup"]], "transformer_lens.hook_points": [[17, "module-transformer_lens.hook_points"]], "config (class in transformer_lens.loading_from_pretrained)": [[18, "transformer_lens.loading_from_pretrained.Config"]], "model_aliases (in module transformer_lens.loading_from_pretrained)": [[18, "transformer_lens.loading_from_pretrained.MODEL_ALIASES"]], "official_model_names (in module transformer_lens.loading_from_pretrained)": [[18, "transformer_lens.loading_from_pretrained.OFFICIAL_MODEL_NAMES"]], "convert_bloom_weights() (in module transformer_lens.loading_from_pretrained)": [[18, "transformer_lens.loading_from_pretrained.convert_bloom_weights"]], "convert_coder_weights() (in module transformer_lens.loading_from_pretrained)": [[18, "transformer_lens.loading_from_pretrained.convert_coder_weights"]], "convert_qwen_weights() (in module transformer_lens.loading_from_pretrained)": [[18, "transformer_lens.loading_from_pretrained.convert_qwen_weights"]], "d_head (transformer_lens.loading_from_pretrained.config attribute)": [[18, "transformer_lens.loading_from_pretrained.Config.d_head"]], "d_mlp (transformer_lens.loading_from_pretrained.config attribute)": [[18, "transformer_lens.loading_from_pretrained.Config.d_mlp"]], "d_model (transformer_lens.loading_from_pretrained.config attribute)": [[18, "transformer_lens.loading_from_pretrained.Config.d_model"]], "d_vocab (transformer_lens.loading_from_pretrained.config attribute)": [[18, "transformer_lens.loading_from_pretrained.Config.d_vocab"]], "debug (transformer_lens.loading_from_pretrained.config attribute)": [[18, "transformer_lens.loading_from_pretrained.Config.debug"]], "get_checkpoint_labels() (in module transformer_lens.loading_from_pretrained)": [[18, "transformer_lens.loading_from_pretrained.get_checkpoint_labels"]], "get_num_params_of_pretrained() (in module transformer_lens.loading_from_pretrained)": [[18, "transformer_lens.loading_from_pretrained.get_num_params_of_pretrained"]], "get_pretrained_model_config() (in module transformer_lens.loading_from_pretrained)": [[18, "transformer_lens.loading_from_pretrained.get_pretrained_model_config"]], "init_range (transformer_lens.loading_from_pretrained.config attribute)": [[18, "transformer_lens.loading_from_pretrained.Config.init_range"]], "layer_norm_eps (transformer_lens.loading_from_pretrained.config attribute)": [[18, "transformer_lens.loading_from_pretrained.Config.layer_norm_eps"]], "n_ctx (transformer_lens.loading_from_pretrained.config attribute)": [[18, "transformer_lens.loading_from_pretrained.Config.n_ctx"]], "n_heads (transformer_lens.loading_from_pretrained.config attribute)": [[18, "transformer_lens.loading_from_pretrained.Config.n_heads"]], "n_layers (transformer_lens.loading_from_pretrained.config attribute)": [[18, "transformer_lens.loading_from_pretrained.Config.n_layers"]], "transformer_lens.loading_from_pretrained": [[18, "module-transformer_lens.loading_from_pretrained"]], "hookedtransformerkeyvaluecache (class in transformer_lens.past_key_value_caching)": [[19, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache"]], "hookedtransformerkeyvaluecacheentry (class in transformer_lens.past_key_value_caching)": [[19, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry"]], "append() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry method)": [[19, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.append"]], "append_attention_mask() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache method)": [[19, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.append_attention_mask"]], "entries (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache attribute)": [[19, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.entries"]], "freeze() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache method)": [[19, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.freeze"]], "frozen (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache attribute)": [[19, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.frozen"]], "frozen (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry attribute)": [[19, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.frozen"]], "init_cache() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache class method)": [[19, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.init_cache"]], "init_cache_entry() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry class method)": [[19, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.init_cache_entry"]], "past_keys (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry attribute)": [[19, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.past_keys"]], "past_values (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry attribute)": [[19, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.past_values"]], "previous_attention_mask (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache attribute)": [[19, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.previous_attention_mask"]], "transformer_lens.past_key_value_caching": [[19, "module-transformer_lens.past_key_value_caching"]], "unfreeze() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache method)": [[19, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.unfreeze"]], "generic_activation_patch() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.generic_activation_patch"]], "get_act_patch_attn_head_all_pos_every() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.get_act_patch_attn_head_all_pos_every"]], "get_act_patch_attn_head_by_pos_every() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.get_act_patch_attn_head_by_pos_every"]], "get_act_patch_attn_head_k_all_pos() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.get_act_patch_attn_head_k_all_pos"]], "get_act_patch_attn_head_k_by_pos() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.get_act_patch_attn_head_k_by_pos"]], "get_act_patch_attn_head_out_all_pos() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.get_act_patch_attn_head_out_all_pos"]], "get_act_patch_attn_head_out_by_pos() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.get_act_patch_attn_head_out_by_pos"]], "get_act_patch_attn_head_pattern_all_pos() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.get_act_patch_attn_head_pattern_all_pos"]], "get_act_patch_attn_head_pattern_by_pos() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.get_act_patch_attn_head_pattern_by_pos"]], "get_act_patch_attn_head_pattern_dest_src_pos() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.get_act_patch_attn_head_pattern_dest_src_pos"]], "get_act_patch_attn_head_q_all_pos() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.get_act_patch_attn_head_q_all_pos"]], "get_act_patch_attn_head_q_by_pos() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.get_act_patch_attn_head_q_by_pos"]], "get_act_patch_attn_head_v_all_pos() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.get_act_patch_attn_head_v_all_pos"]], "get_act_patch_attn_head_v_by_pos() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.get_act_patch_attn_head_v_by_pos"]], "get_act_patch_attn_out() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.get_act_patch_attn_out"]], "get_act_patch_block_every() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.get_act_patch_block_every"]], "get_act_patch_mlp_out() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.get_act_patch_mlp_out"]], "get_act_patch_resid_mid() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.get_act_patch_resid_mid"]], "get_act_patch_resid_pre() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.get_act_patch_resid_pre"]], "layer_head_dest_src_pos_pattern_patch_setter() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.layer_head_dest_src_pos_pattern_patch_setter"]], "layer_head_pattern_patch_setter() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.layer_head_pattern_patch_setter"]], "layer_head_pos_pattern_patch_setter() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.layer_head_pos_pattern_patch_setter"]], "layer_head_vector_patch_setter() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.layer_head_vector_patch_setter"]], "layer_pos_head_vector_patch_setter() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.layer_pos_head_vector_patch_setter"]], "layer_pos_patch_setter() (in module transformer_lens.patching)": [[20, "transformer_lens.patching.layer_pos_patch_setter"]], "transformer_lens.patching": [[20, "module-transformer_lens.patching"]], "hookedtransformertrainconfig (class in transformer_lens.train)": [[21, "transformer_lens.train.HookedTransformerTrainConfig"]], "batch_size (transformer_lens.train.hookedtransformertrainconfig attribute)": [[21, "transformer_lens.train.HookedTransformerTrainConfig.batch_size"]], "device (transformer_lens.train.hookedtransformertrainconfig attribute)": [[21, "transformer_lens.train.HookedTransformerTrainConfig.device"]], "lr (transformer_lens.train.hookedtransformertrainconfig attribute)": [[21, "transformer_lens.train.HookedTransformerTrainConfig.lr"]], "max_grad_norm (transformer_lens.train.hookedtransformertrainconfig attribute)": [[21, "transformer_lens.train.HookedTransformerTrainConfig.max_grad_norm"]], "max_steps (transformer_lens.train.hookedtransformertrainconfig attribute)": [[21, "transformer_lens.train.HookedTransformerTrainConfig.max_steps"]], "momentum (transformer_lens.train.hookedtransformertrainconfig attribute)": [[21, "transformer_lens.train.HookedTransformerTrainConfig.momentum"]], "num_epochs (transformer_lens.train.hookedtransformertrainconfig attribute)": [[21, "transformer_lens.train.HookedTransformerTrainConfig.num_epochs"]], "optimizer_name (transformer_lens.train.hookedtransformertrainconfig attribute)": [[21, "transformer_lens.train.HookedTransformerTrainConfig.optimizer_name"]], "print_every (transformer_lens.train.hookedtransformertrainconfig attribute)": [[21, "transformer_lens.train.HookedTransformerTrainConfig.print_every"]], "save_dir (transformer_lens.train.hookedtransformertrainconfig attribute)": [[21, "transformer_lens.train.HookedTransformerTrainConfig.save_dir"]], "save_every (transformer_lens.train.hookedtransformertrainconfig attribute)": [[21, "transformer_lens.train.HookedTransformerTrainConfig.save_every"]], "seed (transformer_lens.train.hookedtransformertrainconfig attribute)": [[21, "transformer_lens.train.HookedTransformerTrainConfig.seed"]], "train() (in module transformer_lens.train)": [[21, "transformer_lens.train.train"]], "transformer_lens.train": [[21, "module-transformer_lens.train"]], "wandb (transformer_lens.train.hookedtransformertrainconfig attribute)": [[21, "transformer_lens.train.HookedTransformerTrainConfig.wandb"]], "wandb_project_name (transformer_lens.train.hookedtransformertrainconfig attribute)": [[21, "transformer_lens.train.HookedTransformerTrainConfig.wandb_project_name"]], "warmup_steps (transformer_lens.train.hookedtransformertrainconfig attribute)": [[21, "transformer_lens.train.HookedTransformerTrainConfig.warmup_steps"]], "weight_decay (transformer_lens.train.hookedtransformertrainconfig attribute)": [[21, "transformer_lens.train.HookedTransformerTrainConfig.weight_decay"]], "get_device_for_block_index() (in module transformer_lens.utilities.devices)": [[23, "transformer_lens.utilities.devices.get_device_for_block_index"]], "move_to_and_update_config() (in module transformer_lens.utilities.devices)": [[23, "transformer_lens.utilities.devices.move_to_and_update_config"]], "transformer_lens.utilities.devices": [[23, "module-transformer_lens.utilities.devices"]], "locallyoverridendefaults (class in transformer_lens.utils)": [[24, "transformer_lens.utils.LocallyOverridenDefaults"]], "slice (class in transformer_lens.utils)": [[24, "transformer_lens.utils.Slice"]], "sliceinput (in module transformer_lens.utils)": [[24, "transformer_lens.utils.SliceInput"]], "__init__() (transformer_lens.utils.locallyoverridendefaults method)": [[24, "transformer_lens.utils.LocallyOverridenDefaults.__init__"]], "__init__() (transformer_lens.utils.slice method)": [[24, "transformer_lens.utils.Slice.__init__"]], "apply() (transformer_lens.utils.slice method)": [[24, "transformer_lens.utils.Slice.apply"]], "composition_scores() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.composition_scores"]], "download_file_from_hf() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.download_file_from_hf"]], "gelu_fast() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.gelu_fast"]], "gelu_new() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.gelu_new"]], "get_act_name() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.get_act_name"]], "get_attention_mask() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.get_attention_mask"]], "get_corner() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.get_corner"]], "get_cumsum_along_dim() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.get_cumsum_along_dim"]], "get_dataset() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.get_dataset"]], "get_device() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.get_device"]], "get_input_with_manually_prepended_bos() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.get_input_with_manually_prepended_bos"]], "get_nested_attr() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.get_nested_attr"]], "get_offset_position_ids() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.get_offset_position_ids"]], "get_tokenizer_with_bos() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.get_tokenizer_with_bos"]], "get_tokens_with_bos_removed() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.get_tokens_with_bos_removed"]], "indices() (transformer_lens.utils.slice method)": [[24, "transformer_lens.utils.Slice.indices"]], "is_lower_triangular() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.is_lower_triangular"]], "is_square() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.is_square"]], "keep_single_column() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.keep_single_column"]], "lm_accuracy() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.lm_accuracy"]], "lm_cross_entropy_loss() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.lm_cross_entropy_loss"]], "override_or_use_default_value() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.override_or_use_default_value"]], "print_gpu_mem() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.print_gpu_mem"]], "remove_batch_dim() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.remove_batch_dim"]], "sample_logits() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.sample_logits"]], "set_nested_attr() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.set_nested_attr"]], "solu() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.solu"]], "test_prompt() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.test_prompt"]], "to_numpy() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.to_numpy"]], "tokenize_and_concatenate() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.tokenize_and_concatenate"]], "transformer_lens.utils": [[24, "module-transformer_lens.utils"]], "transpose() (in module transformer_lens.utils)": [[24, "transformer_lens.utils.transpose"]]}})