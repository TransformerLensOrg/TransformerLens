<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>Coverage for transformer_lens/utils.py: 67%</title>
    <link rel="icon" sizes="32x32" href="favicon_32.png">
    <link rel="stylesheet" href="style.css" type="text/css">
    <script type="text/javascript" src="coverage_html.js" defer></script>
</head>
<body class="pyfile">
<header>
    <div class="content">
        <h1>
            <span class="text">Coverage for </span><b>transformer_lens/utils.py</b>:
            <span class="pc_cov">67%</span>
        </h1>
        <aside id="help_panel_wrapper">
            <input id="help_panel_state" type="checkbox">
            <label for="help_panel_state">
                <img id="keyboard_icon" src="keybd_closed.png" alt="Show/hide keyboard shortcuts" />
            </label>
            <div id="help_panel">
                <p class="legend">Shortcuts on this page</p>
                <div class="keyhelp">
                    <p>
                        <kbd>r</kbd>
                        <kbd>m</kbd>
                        <kbd>x</kbd>
                        <kbd>p</kbd>
                        &nbsp; toggle line displays
                    </p>
                    <p>
                        <kbd>j</kbd>
                        <kbd>k</kbd>
                        &nbsp; next/prev highlighted chunk
                    </p>
                    <p>
                        <kbd>0</kbd> &nbsp; (zero) top of page
                    </p>
                    <p>
                        <kbd>1</kbd> &nbsp; (one) first highlighted chunk
                    </p>
                    <p>
                        <kbd>[</kbd>
                        <kbd>]</kbd>
                        &nbsp; prev/next file
                    </p>
                    <p>
                        <kbd>u</kbd> &nbsp; up to the index
                    </p>
                    <p>
                        <kbd>?</kbd> &nbsp; show/hide this help
                    </p>
                </div>
            </div>
        </aside>
        <h2>
            <span class="text">433 statements &nbsp;</span>
            <button type="button" class="run button_toggle_run" value="run" data-shortcut="r" title="Toggle lines run">311<span class="text"> run</span></button>
            <button type="button" class="mis show_mis button_toggle_mis" value="mis" data-shortcut="m" title="Toggle lines missing">122<span class="text"> missing</span></button>
            <button type="button" class="exc show_exc button_toggle_exc" value="exc" data-shortcut="x" title="Toggle lines excluded">0<span class="text"> excluded</span></button>
            <button type="button" class="par run show_par button_toggle_par" value="par" data-shortcut="p" title="Toggle lines partially run">16<span class="text"> partial</span></button>
        </h2>
        <p class="text">
            <a id="prevFileLink" class="nav" href="d_b2114f845e0399b7_devices_py.html">&#xab; prev</a> &nbsp; &nbsp;
            <a id="indexLink" class="nav" href="index.html">&Hat; index</a> &nbsp; &nbsp;
            <a id="nextFileLink" class="nav" href="index.html">&#xbb; next</a>
            &nbsp; &nbsp; &nbsp;
            <a class="nav" href="https://coverage.readthedocs.io/en/7.4.4">coverage.py v7.4.4</a>,
            created at 2024-07-06 00:32 +0000
        </p>
        <aside class="hidden">
            <button type="button" class="button_next_chunk" data-shortcut="j"/>
            <button type="button" class="button_prev_chunk" data-shortcut="k"/>
            <button type="button" class="button_top_of_page" data-shortcut="0"/>
            <button type="button" class="button_first_chunk" data-shortcut="1"/>
            <button type="button" class="button_prev_file" data-shortcut="["/>
            <button type="button" class="button_next_file" data-shortcut="]"/>
            <button type="button" class="button_to_index" data-shortcut="u"/>
            <button type="button" class="button_show_hide_help" data-shortcut="?"/>
        </aside>
    </div>
</header>
<main id="source">
    <p class="pln"><span class="n"><a id="t1" href="#t1">1</a></span><span class="t"><span class="str">"""Utils.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t2" href="#t2">2</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t3" href="#t3">3</a></span><span class="t"><span class="str">This module contains varied utility functions used throughout the library.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t4" href="#t4">4</a></span><span class="t"><span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t5" href="#t5">5</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t6" href="#t6">6</a></span><span class="t"><span class="key">from</span> <span class="nam">__future__</span> <span class="key">import</span> <span class="nam">annotations</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t7" href="#t7">7</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t8" href="#t8">8</a></span><span class="t"><span class="key">import</span> <span class="nam">inspect</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t9" href="#t9">9</a></span><span class="t"><span class="key">import</span> <span class="nam">json</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t10" href="#t10">10</a></span><span class="t"><span class="key">import</span> <span class="nam">os</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t11" href="#t11">11</a></span><span class="t"><span class="key">import</span> <span class="nam">re</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t12" href="#t12">12</a></span><span class="t"><span class="key">import</span> <span class="nam">shutil</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t13" href="#t13">13</a></span><span class="t"><span class="key">from</span> <span class="nam">copy</span> <span class="key">import</span> <span class="nam">deepcopy</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t14" href="#t14">14</a></span><span class="t"><span class="key">from</span> <span class="nam">typing</span> <span class="key">import</span> <span class="nam">Any</span><span class="op">,</span> <span class="nam">Callable</span><span class="op">,</span> <span class="nam">Dict</span><span class="op">,</span> <span class="nam">List</span><span class="op">,</span> <span class="nam">Optional</span><span class="op">,</span> <span class="nam">Tuple</span><span class="op">,</span> <span class="nam">Union</span><span class="op">,</span> <span class="nam">cast</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t15" href="#t15">15</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t16" href="#t16">16</a></span><span class="t"><span class="key">import</span> <span class="nam">einops</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t17" href="#t17">17</a></span><span class="t"><span class="key">import</span> <span class="nam">numpy</span> <span class="key">as</span> <span class="nam">np</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t18" href="#t18">18</a></span><span class="t"><span class="key">import</span> <span class="nam">torch</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t19" href="#t19">19</a></span><span class="t"><span class="key">import</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">nn</span> <span class="key">as</span> <span class="nam">nn</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t20" href="#t20">20</a></span><span class="t"><span class="key">import</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">nn</span><span class="op">.</span><span class="nam">functional</span> <span class="key">as</span> <span class="nam">F</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t21" href="#t21">21</a></span><span class="t"><span class="key">import</span> <span class="nam">transformers</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t22" href="#t22">22</a></span><span class="t"><span class="key">from</span> <span class="nam">datasets</span><span class="op">.</span><span class="nam">arrow_dataset</span> <span class="key">import</span> <span class="nam">Dataset</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t23" href="#t23">23</a></span><span class="t"><span class="key">from</span> <span class="nam">datasets</span><span class="op">.</span><span class="nam">load</span> <span class="key">import</span> <span class="nam">load_dataset</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t24" href="#t24">24</a></span><span class="t"><span class="key">from</span> <span class="nam">huggingface_hub</span> <span class="key">import</span> <span class="nam">hf_hub_download</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t25" href="#t25">25</a></span><span class="t"><span class="key">from</span> <span class="nam">jaxtyping</span> <span class="key">import</span> <span class="nam">Float</span><span class="op">,</span> <span class="nam">Int</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t26" href="#t26">26</a></span><span class="t"><span class="key">from</span> <span class="nam">rich</span> <span class="key">import</span> <span class="nam">print</span> <span class="key">as</span> <span class="nam">rprint</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t27" href="#t27">27</a></span><span class="t"><span class="key">from</span> <span class="nam">transformers</span> <span class="key">import</span> <span class="nam">AutoTokenizer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t28" href="#t28">28</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t29" href="#t29">29</a></span><span class="t"><span class="key">from</span> <span class="nam">transformer_lens</span><span class="op">.</span><span class="nam">FactoredMatrix</span> <span class="key">import</span> <span class="nam">FactoredMatrix</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t30" href="#t30">30</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t31" href="#t31">31</a></span><span class="t"><span class="nam">CACHE_DIR</span> <span class="op">=</span> <span class="nam">transformers</span><span class="op">.</span><span class="nam">TRANSFORMERS_CACHE</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t32" href="#t32">32</a></span><span class="t"><span class="nam">USE_DEFAULT_VALUE</span> <span class="op">=</span> <span class="key">None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t33" href="#t33">33</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t34" href="#t34">34</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t35" href="#t35">35</a></span><span class="t"><span class="key">def</span> <span class="nam">select_compatible_kwargs</span><span class="op">(</span><span class="nam">kwargs_dict</span><span class="op">:</span> <span class="nam">Dict</span><span class="op">[</span><span class="nam">str</span><span class="op">,</span> <span class="nam">Any</span><span class="op">]</span><span class="op">,</span> <span class="nam">callable</span><span class="op">:</span> <span class="nam">Callable</span><span class="op">)</span> <span class="op">-></span> <span class="nam">Dict</span><span class="op">[</span><span class="nam">str</span><span class="op">,</span> <span class="nam">Any</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t36" href="#t36">36</a></span><span class="t">    <span class="str">"""Return a dict with the elements kwargs_dict that are parameters of callable"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t37" href="#t37">37</a></span><span class="t">    <span class="key">return</span> <span class="op">{</span><span class="nam">k</span><span class="op">:</span> <span class="nam">v</span> <span class="key">for</span> <span class="nam">k</span><span class="op">,</span> <span class="nam">v</span> <span class="key">in</span> <span class="nam">kwargs_dict</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span> <span class="key">if</span> <span class="nam">k</span> <span class="key">in</span> <span class="nam">inspect</span><span class="op">.</span><span class="nam">getfullargspec</span><span class="op">(</span><span class="nam">callable</span><span class="op">)</span><span class="op">.</span><span class="nam">args</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t38" href="#t38">38</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t39" href="#t39">39</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t40" href="#t40">40</a></span><span class="t"><span class="key">def</span> <span class="nam">download_file_from_hf</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t41" href="#t41">41</a></span><span class="t">    <span class="nam">repo_name</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t42" href="#t42">42</a></span><span class="t">    <span class="nam">file_name</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t43" href="#t43">43</a></span><span class="t">    <span class="nam">subfolder</span><span class="op">=</span><span class="str">"."</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t44" href="#t44">44</a></span><span class="t">    <span class="nam">cache_dir</span><span class="op">=</span><span class="nam">CACHE_DIR</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t45" href="#t45">45</a></span><span class="t">    <span class="nam">force_is_torch</span><span class="op">=</span><span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t46" href="#t46">46</a></span><span class="t">    <span class="op">**</span><span class="nam">kwargs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t47" href="#t47">47</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t48" href="#t48">48</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t49" href="#t49">49</a></span><span class="t"><span class="str">    Helper function to download files from the HuggingFace Hub, from subfolder/file_name in repo_name, saving locally to cache_dir and returning the loaded file (if a json or Torch object) and the file path otherwise.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t50" href="#t50">50</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t51" href="#t51">51</a></span><span class="t"><span class="str">    If it's a Torch file without the ".pth" extension, set force_is_torch=True to load it as a Torch object.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t52" href="#t52">52</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t53" href="#t53">53</a></span><span class="t">    <span class="nam">file_path</span> <span class="op">=</span> <span class="nam">hf_hub_download</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t54" href="#t54">54</a></span><span class="t">        <span class="nam">repo_id</span><span class="op">=</span><span class="nam">repo_name</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t55" href="#t55">55</a></span><span class="t">        <span class="nam">filename</span><span class="op">=</span><span class="nam">file_name</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t56" href="#t56">56</a></span><span class="t">        <span class="nam">subfolder</span><span class="op">=</span><span class="nam">subfolder</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t57" href="#t57">57</a></span><span class="t">        <span class="nam">cache_dir</span><span class="op">=</span><span class="nam">cache_dir</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t58" href="#t58">58</a></span><span class="t">        <span class="op">**</span><span class="nam">select_compatible_kwargs</span><span class="op">(</span><span class="nam">kwargs</span><span class="op">,</span> <span class="nam">hf_hub_download</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t59" href="#t59">59</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t60" href="#t60">60</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t61" href="#t61">61</a></span><span class="t">    <span class="key">if</span> <span class="nam">file_path</span><span class="op">.</span><span class="nam">endswith</span><span class="op">(</span><span class="str">".pth"</span><span class="op">)</span> <span class="key">or</span> <span class="nam">force_is_torch</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t62" href="#t62">62</a></span><span class="t">        <span class="key">return</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">load</span><span class="op">(</span><span class="nam">file_path</span><span class="op">,</span> <span class="nam">map_location</span><span class="op">=</span><span class="str">"cpu"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t63" href="#t63">63</a></span><span class="t">    <span class="key">elif</span> <span class="nam">file_path</span><span class="op">.</span><span class="nam">endswith</span><span class="op">(</span><span class="str">".json"</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">63&#x202F;&#x219B;&#x202F;66</span><span class="annotate long">line 63 didn't jump to line 66, because the condition on line 63 was never false</span></span></p>
    <p class="run"><span class="n"><a id="t64" href="#t64">64</a></span><span class="t">        <span class="key">return</span> <span class="nam">json</span><span class="op">.</span><span class="nam">load</span><span class="op">(</span><span class="nam">open</span><span class="op">(</span><span class="nam">file_path</span><span class="op">,</span> <span class="str">"r"</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t65" href="#t65">65</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t66" href="#t66">66</a></span><span class="t">        <span class="nam">print</span><span class="op">(</span><span class="str">"File type not supported:"</span><span class="op">,</span> <span class="nam">file_path</span><span class="op">.</span><span class="nam">split</span><span class="op">(</span><span class="str">"."</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t67" href="#t67">67</a></span><span class="t">        <span class="key">return</span> <span class="nam">file_path</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t68" href="#t68">68</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t69" href="#t69">69</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t70" href="#t70">70</a></span><span class="t"><span class="key">def</span> <span class="nam">clear_huggingface_cache</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t71" href="#t71">71</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t72" href="#t72">72</a></span><span class="t"><span class="str">    Deletes the Hugging Face cache directory and all its contents.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t73" href="#t73">73</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t74" href="#t74">74</a></span><span class="t"><span class="str">    This function deletes the Hugging Face cache directory, which is used to store downloaded models and their associated files. Deleting the cache directory will remove all the downloaded models and their files, so you will need to download them again if you want to use them in your code.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t75" href="#t75">75</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t76" href="#t76">76</a></span><span class="t"><span class="str">    Parameters:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t77" href="#t77">77</a></span><span class="t"><span class="str">    None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t78" href="#t78">78</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t79" href="#t79">79</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t80" href="#t80">80</a></span><span class="t"><span class="str">    None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t81" href="#t81">81</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t82" href="#t82">82</a></span><span class="t">    <span class="nam">print</span><span class="op">(</span><span class="str">"Deleting Hugging Face cache directory and all its contents."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t83" href="#t83">83</a></span><span class="t">    <span class="nam">shutil</span><span class="op">.</span><span class="nam">rmtree</span><span class="op">(</span><span class="nam">CACHE_DIR</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t84" href="#t84">84</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t85" href="#t85">85</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t86" href="#t86">86</a></span><span class="t"><span class="key">def</span> <span class="nam">print_gpu_mem</span><span class="op">(</span><span class="nam">step_name</span><span class="op">=</span><span class="str">""</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t87" href="#t87">87</a></span><span class="t">    <span class="nam">print</span><span class="op">(</span><span class="str">f"{step_name} ~ {np.round(torch.cuda.memory_allocated()/2e30, 2)} GiB allocated on GPU."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t88" href="#t88">88</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t89" href="#t89">89</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t90" href="#t90">90</a></span><span class="t"><span class="key">def</span> <span class="nam">get_corner</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">n</span><span class="op">=</span><span class="num">3</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t91" href="#t91">91</a></span><span class="t">    <span class="com"># Prints the top left corner of the tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t92" href="#t92">92</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">92&#x202F;&#x219B;&#x202F;94</span><span class="annotate long">line 92 didn't jump to line 94, because the condition on line 92 was never false</span></span></p>
    <p class="run"><span class="n"><a id="t93" href="#t93">93</a></span><span class="t">        <span class="key">return</span> <span class="nam">tensor</span><span class="op">[</span><span class="nam">tuple</span><span class="op">(</span><span class="nam">slice</span><span class="op">(</span><span class="nam">n</span><span class="op">)</span> <span class="key">for</span> <span class="nam">_</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">tensor</span><span class="op">.</span><span class="nam">ndim</span><span class="op">)</span><span class="op">)</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t94" href="#t94">94</a></span><span class="t">    <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">FactoredMatrix</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t95" href="#t95">95</a></span><span class="t">        <span class="key">return</span> <span class="nam">tensor</span><span class="op">[</span><span class="nam">tuple</span><span class="op">(</span><span class="nam">slice</span><span class="op">(</span><span class="nam">n</span><span class="op">)</span> <span class="key">for</span> <span class="nam">_</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">tensor</span><span class="op">.</span><span class="nam">ndim</span><span class="op">)</span><span class="op">)</span><span class="op">]</span><span class="op">.</span><span class="nam">AB</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t96" href="#t96">96</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t97" href="#t97">97</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t98" href="#t98">98</a></span><span class="t"><span class="key">def</span> <span class="nam">to_numpy</span><span class="op">(</span><span class="nam">tensor</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t99" href="#t99">99</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t100" href="#t100">100</a></span><span class="t"><span class="str">    Helper function to convert a tensor to a numpy array. Also works on lists, tuples, and numpy arrays.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t101" href="#t101">101</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t102" href="#t102">102</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">np</span><span class="op">.</span><span class="nam">ndarray</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t103" href="#t103">103</a></span><span class="t">        <span class="key">return</span> <span class="nam">tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t104" href="#t104">104</a></span><span class="t">    <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t105" href="#t105">105</a></span><span class="t">        <span class="nam">array</span> <span class="op">=</span> <span class="nam">np</span><span class="op">.</span><span class="nam">array</span><span class="op">(</span><span class="nam">tensor</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t106" href="#t106">106</a></span><span class="t">        <span class="key">return</span> <span class="nam">array</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t107" href="#t107">107</a></span><span class="t">    <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="op">(</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">nn</span><span class="op">.</span><span class="nam">parameter</span><span class="op">.</span><span class="nam">Parameter</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">107&#x202F;&#x219B;&#x202F;109</span><span class="annotate long">line 107 didn't jump to line 109, because the condition on line 107 was never false</span></span></p>
    <p class="run"><span class="n"><a id="t108" href="#t108">108</a></span><span class="t">        <span class="key">return</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">detach</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">cpu</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">numpy</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t109" href="#t109">109</a></span><span class="t">    <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="op">(</span><span class="nam">int</span><span class="op">,</span> <span class="nam">float</span><span class="op">,</span> <span class="nam">bool</span><span class="op">,</span> <span class="nam">str</span><span class="op">)</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t110" href="#t110">110</a></span><span class="t">        <span class="key">return</span> <span class="nam">np</span><span class="op">.</span><span class="nam">array</span><span class="op">(</span><span class="nam">tensor</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t111" href="#t111">111</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t112" href="#t112">112</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">f"Input to to_numpy has invalid type: {type(tensor)}"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t113" href="#t113">113</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t114" href="#t114">114</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t115" href="#t115">115</a></span><span class="t"><span class="key">def</span> <span class="nam">lm_cross_entropy_loss</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t116" href="#t116">116</a></span><span class="t">    <span class="nam">logits</span><span class="op">:</span> <span class="nam">Float</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">"batch pos d_vocab"</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t117" href="#t117">117</a></span><span class="t">    <span class="nam">tokens</span><span class="op">:</span> <span class="nam">Int</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">"batch pos"</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t118" href="#t118">118</a></span><span class="t">    <span class="nam">per_token</span><span class="op">:</span> <span class="nam">bool</span> <span class="op">=</span> <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t119" href="#t119">119</a></span><span class="t"><span class="op">)</span> <span class="op">-></span> <span class="nam">Union</span><span class="op">[</span><span class="nam">Float</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">""</span><span class="op">]</span><span class="op">,</span> <span class="nam">Float</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">"batch pos"</span><span class="op">]</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t120" href="#t120">120</a></span><span class="t">    <span class="str">"""Cross entropy loss for the language model, gives the loss for predicting the NEXT token.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t121" href="#t121">121</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t122" href="#t122">122</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t123" href="#t123">123</a></span><span class="t"><span class="str">        logits (torch.Tensor): Logits. Shape [batch, pos, d_vocab]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t124" href="#t124">124</a></span><span class="t"><span class="str">        tokens (torch.Tensor[int64]): Input tokens. Shape [batch, pos]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t125" href="#t125">125</a></span><span class="t"><span class="str">        per_token (bool, optional): Whether to return the log probs predicted for the correct token, or the loss (ie mean of the predicted log probs). Note that the returned array has shape [batch, seq-1] as we cannot predict the first token (alternately, we ignore the final logit). Defaults to False.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t126" href="#t126">126</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t127" href="#t127">127</a></span><span class="t">    <span class="nam">log_probs</span> <span class="op">=</span> <span class="nam">F</span><span class="op">.</span><span class="nam">log_softmax</span><span class="op">(</span><span class="nam">logits</span><span class="op">,</span> <span class="nam">dim</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t128" href="#t128">128</a></span><span class="t">    <span class="com"># Use torch.gather to find the log probs of the correct tokens</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t129" href="#t129">129</a></span><span class="t">    <span class="com"># Offsets needed because we're predicting the NEXT token (this means the final logit is meaningless)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t130" href="#t130">130</a></span><span class="t">    <span class="com"># None and [..., 0] needed because the tensor used in gather must have the same rank.</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t131" href="#t131">131</a></span><span class="t">    <span class="nam">predicted_log_probs</span> <span class="op">=</span> <span class="nam">log_probs</span><span class="op">[</span><span class="op">...</span><span class="op">,</span> <span class="op">:</span><span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="op">:</span><span class="op">]</span><span class="op">.</span><span class="nam">gather</span><span class="op">(</span><span class="nam">dim</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="nam">index</span><span class="op">=</span><span class="nam">tokens</span><span class="op">[</span><span class="op">...</span><span class="op">,</span> <span class="num">1</span><span class="op">:</span><span class="op">,</span> <span class="key">None</span><span class="op">]</span><span class="op">)</span><span class="op">[</span><span class="op">...</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t132" href="#t132">132</a></span><span class="t">    <span class="key">if</span> <span class="nam">per_token</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">132&#x202F;&#x219B;&#x202F;133</span><span class="annotate long">line 132 didn't jump to line 133, because the condition on line 132 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t133" href="#t133">133</a></span><span class="t">        <span class="key">return</span> <span class="op">-</span><span class="nam">predicted_log_probs</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t134" href="#t134">134</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t135" href="#t135">135</a></span><span class="t">        <span class="key">return</span> <span class="op">-</span><span class="nam">predicted_log_probs</span><span class="op">.</span><span class="nam">mean</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t136" href="#t136">136</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t137" href="#t137">137</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t138" href="#t138">138</a></span><span class="t"><span class="key">def</span> <span class="nam">lm_accuracy</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t139" href="#t139">139</a></span><span class="t">    <span class="nam">logits</span><span class="op">:</span> <span class="nam">Float</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">"batch pos d_vocab"</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t140" href="#t140">140</a></span><span class="t">    <span class="nam">tokens</span><span class="op">:</span> <span class="nam">Int</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">"batch pos"</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t141" href="#t141">141</a></span><span class="t">    <span class="nam">per_token</span><span class="op">:</span> <span class="nam">bool</span> <span class="op">=</span> <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t142" href="#t142">142</a></span><span class="t"><span class="op">)</span> <span class="op">-></span> <span class="nam">Union</span><span class="op">[</span><span class="nam">Float</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">""</span><span class="op">]</span><span class="op">,</span> <span class="nam">Float</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">"batch pos"</span><span class="op">]</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t143" href="#t143">143</a></span><span class="t">    <span class="str">"""Cross-Entropy Accuracy for Language Modelling. We measure the accuracy on the logits for predicting the NEXT token.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t144" href="#t144">144</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t145" href="#t145">145</a></span><span class="t"><span class="str">    If per_token is True, returns the boolean for top 1 accuracy for each token in the batch. Note that this has size [batch, seq_len-1], as we cannot predict the first token.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t146" href="#t146">146</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t147" href="#t147">147</a></span><span class="t">    <span class="nam">top_prediction</span> <span class="op">=</span> <span class="nam">logits</span><span class="op">.</span><span class="nam">argmax</span><span class="op">(</span><span class="nam">dim</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t148" href="#t148">148</a></span><span class="t">    <span class="nam">correct_matches</span> <span class="op">=</span> <span class="nam">top_prediction</span><span class="op">[</span><span class="op">:</span><span class="op">,</span> <span class="op">:</span><span class="op">-</span><span class="num">1</span><span class="op">]</span> <span class="op">==</span> <span class="nam">tokens</span><span class="op">[</span><span class="op">:</span><span class="op">,</span> <span class="num">1</span><span class="op">:</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t149" href="#t149">149</a></span><span class="t">    <span class="key">if</span> <span class="nam">per_token</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t150" href="#t150">150</a></span><span class="t">        <span class="key">return</span> <span class="nam">correct_matches</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t151" href="#t151">151</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t152" href="#t152">152</a></span><span class="t">        <span class="key">return</span> <span class="nam">correct_matches</span><span class="op">.</span><span class="nam">sum</span><span class="op">(</span><span class="op">)</span> <span class="op">/</span> <span class="nam">correct_matches</span><span class="op">.</span><span class="nam">numel</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t153" href="#t153">153</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t154" href="#t154">154</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t155" href="#t155">155</a></span><span class="t"><span class="key">def</span> <span class="nam">gelu_new</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t156" href="#t156">156</a></span><span class="t">    <span class="nam">input</span><span class="op">:</span> <span class="nam">Float</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">"batch pos d_mlp"</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t157" href="#t157">157</a></span><span class="t"><span class="op">)</span> <span class="op">-></span> <span class="nam">Float</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">"batch pos d_mlp"</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t158" href="#t158">158</a></span><span class="t">    <span class="com"># Implementation of GeLU used by GPT2 - subtly different from PyTorch's</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t159" href="#t159">159</a></span><span class="t">    <span class="key">return</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t160" href="#t160">160</a></span><span class="t">        <span class="num">0.5</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t161" href="#t161">161</a></span><span class="t">        <span class="op">*</span> <span class="nam">input</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t162" href="#t162">162</a></span><span class="t">        <span class="op">*</span> <span class="op">(</span><span class="num">1.0</span> <span class="op">+</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">tanh</span><span class="op">(</span><span class="nam">np</span><span class="op">.</span><span class="nam">sqrt</span><span class="op">(</span><span class="num">2.0</span> <span class="op">/</span> <span class="nam">np</span><span class="op">.</span><span class="nam">pi</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="nam">input</span> <span class="op">+</span> <span class="num">0.044715</span> <span class="op">*</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">pow</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="num">3.0</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t163" href="#t163">163</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t164" href="#t164">164</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t165" href="#t165">165</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t166" href="#t166">166</a></span><span class="t"><span class="key">def</span> <span class="nam">gelu_fast</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t167" href="#t167">167</a></span><span class="t">    <span class="nam">input</span><span class="op">:</span> <span class="nam">Float</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">"batch pos d_mlp"</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t168" href="#t168">168</a></span><span class="t"><span class="op">)</span> <span class="op">-></span> <span class="nam">Float</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">"batch pos d_mlp"</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t169" href="#t169">169</a></span><span class="t">    <span class="key">return</span> <span class="num">0.5</span> <span class="op">*</span> <span class="nam">input</span> <span class="op">*</span> <span class="op">(</span><span class="num">1.0</span> <span class="op">+</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">tanh</span><span class="op">(</span><span class="nam">input</span> <span class="op">*</span> <span class="num">0.7978845608</span> <span class="op">*</span> <span class="op">(</span><span class="num">1.0</span> <span class="op">+</span> <span class="num">0.044715</span> <span class="op">*</span> <span class="nam">input</span> <span class="op">*</span> <span class="nam">input</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t170" href="#t170">170</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t171" href="#t171">171</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t172" href="#t172">172</a></span><span class="t"><span class="key">def</span> <span class="nam">solu</span><span class="op">(</span><span class="nam">input</span><span class="op">:</span> <span class="nam">Float</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">"batch pos d_mlp"</span><span class="op">]</span><span class="op">)</span> <span class="op">-></span> <span class="nam">Float</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">"batch pos d_mlp"</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t173" href="#t173">173</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t174" href="#t174">174</a></span><span class="t"><span class="str">    SoLU activation function as described by</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t175" href="#t175">175</a></span><span class="t"><span class="str">    https://transformer-circuits.pub/2022/solu/index.html.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t176" href="#t176">176</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t177" href="#t177">177</a></span><span class="t"><span class="str">    LayerNorm implemented by the MLP class.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t178" href="#t178">178</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t179" href="#t179">179</a></span><span class="t">    <span class="key">return</span> <span class="nam">input</span> <span class="op">*</span> <span class="nam">F</span><span class="op">.</span><span class="nam">softmax</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">dim</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t180" href="#t180">180</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t181" href="#t181">181</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t182" href="#t182">182</a></span><span class="t"><span class="nam">ACTIVATION_FN_DICT</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"><span class="annotate short">182&#x202F;&#x219B;&#x202F;exit</span><span class="annotate long">line 182 didn't jump to the function exit</span></span></p>
    <p class="pln"><span class="n"><a id="t183" href="#t183">183</a></span><span class="t">    <span class="str">"solu"</span><span class="op">:</span> <span class="nam">solu</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t184" href="#t184">184</a></span><span class="t">    <span class="str">"solu_ln"</span><span class="op">:</span> <span class="nam">solu</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t185" href="#t185">185</a></span><span class="t">    <span class="str">"gelu_new"</span><span class="op">:</span> <span class="nam">gelu_new</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t186" href="#t186">186</a></span><span class="t">    <span class="str">"gelu_fast"</span><span class="op">:</span> <span class="nam">gelu_fast</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t187" href="#t187">187</a></span><span class="t">    <span class="str">"silu"</span><span class="op">:</span> <span class="nam">F</span><span class="op">.</span><span class="nam">silu</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t188" href="#t188">188</a></span><span class="t">    <span class="str">"relu"</span><span class="op">:</span> <span class="nam">F</span><span class="op">.</span><span class="nam">relu</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t189" href="#t189">189</a></span><span class="t">    <span class="str">"gelu"</span><span class="op">:</span> <span class="nam">F</span><span class="op">.</span><span class="nam">gelu</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t190" href="#t190">190</a></span><span class="t">    <span class="str">"gelu_pytorch_tanh"</span><span class="op">:</span> <span class="key">lambda</span> <span class="nam">tensor</span><span class="op">:</span> <span class="nam">F</span><span class="op">.</span><span class="nam">gelu</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">approximate</span><span class="op">=</span><span class="str">"tanh"</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t191" href="#t191">191</a></span><span class="t"><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t192" href="#t192">192</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t193" href="#t193">193</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t194" href="#t194">194</a></span><span class="t"><span class="key">def</span> <span class="nam">calc_fan_in_and_fan_out</span><span class="op">(</span><span class="nam">tensor</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t195" href="#t195">195</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t196" href="#t196">196</a></span><span class="t"><span class="str">    Calculate the fan in and fan out of a tensor. We define it ourselves because Torch uses a</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t197" href="#t197">197</a></span><span class="t"><span class="str">    different convention for weights (e.g. for an MLP they use d_out x d_in, and we use d_in x</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t198" href="#t198">198</a></span><span class="t"><span class="str">    d_out, for attention they do (n_head d_head) x d_model, we do n_head x d_model x d_head).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t199" href="#t199">199</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t200" href="#t200">200</a></span><span class="t">    <span class="nam">shape</span> <span class="op">=</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t201" href="#t201">201</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t202" href="#t202">202</a></span><span class="t">    <span class="key">if</span> <span class="nam">len</span><span class="op">(</span><span class="nam">shape</span><span class="op">)</span> <span class="op">==</span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t203" href="#t203">203</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"Fan in and fan out can not be computed for scalars."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t204" href="#t204">204</a></span><span class="t">    <span class="key">elif</span> <span class="nam">len</span><span class="op">(</span><span class="nam">shape</span><span class="op">)</span> <span class="op">==</span> <span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t205" href="#t205">205</a></span><span class="t">        <span class="nam">fan_in</span> <span class="op">=</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t206" href="#t206">206</a></span><span class="t">        <span class="nam">fan_out</span> <span class="op">=</span> <span class="nam">shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t207" href="#t207">207</a></span><span class="t">    <span class="key">elif</span> <span class="nam">len</span><span class="op">(</span><span class="nam">shape</span><span class="op">)</span> <span class="op">==</span> <span class="num">2</span><span class="op">:</span>  <span class="com"># Linear transform</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t208" href="#t208">208</a></span><span class="t">        <span class="nam">fan_in</span> <span class="op">=</span> <span class="nam">shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t209" href="#t209">209</a></span><span class="t">        <span class="nam">fan_out</span> <span class="op">=</span> <span class="nam">shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t210" href="#t210">210</a></span><span class="t">    <span class="key">elif</span> <span class="nam">len</span><span class="op">(</span><span class="nam">shape</span><span class="op">)</span> <span class="op">==</span> <span class="num">3</span><span class="op">:</span>  <span class="com"># Attention head weight, has shape n_head x d_model x d_head</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t211" href="#t211">211</a></span><span class="t">        <span class="nam">fan_in</span> <span class="op">=</span> <span class="nam">shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t212" href="#t212">212</a></span><span class="t">        <span class="nam">fan_out</span> <span class="op">=</span> <span class="nam">shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">*</span> <span class="nam">shape</span><span class="op">[</span><span class="num">2</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t213" href="#t213">213</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t214" href="#t214">214</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">f"Fan in and fan out can not be computed for shape {shape} tensors."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t215" href="#t215">215</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t216" href="#t216">216</a></span><span class="t">    <span class="key">return</span> <span class="nam">fan_in</span><span class="op">,</span> <span class="nam">fan_out</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t217" href="#t217">217</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t218" href="#t218">218</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t219" href="#t219">219</a></span><span class="t"><span class="key">def</span> <span class="nam">init_xavier_uniform_</span><span class="op">(</span><span class="nam">param</span><span class="op">,</span> <span class="nam">gain</span><span class="op">=</span><span class="num">1.0</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t220" href="#t220">220</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t221" href="#t221">221</a></span><span class="t"><span class="str">    Initializes the input tensor using the Xavier initialization method.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t222" href="#t222">222</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t223" href="#t223">223</a></span><span class="t">    <span class="nam">fan_in</span><span class="op">,</span> <span class="nam">fan_out</span> <span class="op">=</span> <span class="nam">calc_fan_in_and_fan_out</span><span class="op">(</span><span class="nam">param</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t224" href="#t224">224</a></span><span class="t">    <span class="nam">max</span> <span class="op">=</span> <span class="nam">gain</span> <span class="op">*</span> <span class="nam">np</span><span class="op">.</span><span class="nam">sqrt</span><span class="op">(</span><span class="num">6.0</span> <span class="op">/</span> <span class="op">(</span><span class="nam">fan_in</span> <span class="op">+</span> <span class="nam">fan_out</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t225" href="#t225">225</a></span><span class="t">    <span class="key">return</span> <span class="nam">nn</span><span class="op">.</span><span class="nam">init</span><span class="op">.</span><span class="nam">uniform_</span><span class="op">(</span><span class="nam">param</span><span class="op">,</span> <span class="op">-</span><span class="nam">max</span><span class="op">,</span> <span class="nam">max</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t226" href="#t226">226</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t227" href="#t227">227</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t228" href="#t228">228</a></span><span class="t"><span class="key">def</span> <span class="nam">init_xavier_normal_</span><span class="op">(</span><span class="nam">param</span><span class="op">,</span> <span class="nam">gain</span><span class="op">=</span><span class="num">1.0</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t229" href="#t229">229</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t230" href="#t230">230</a></span><span class="t"><span class="str">    Initializes the input tensor using the Xavier initialization method.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t231" href="#t231">231</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t232" href="#t232">232</a></span><span class="t">    <span class="nam">fan_in</span><span class="op">,</span> <span class="nam">fan_out</span> <span class="op">=</span> <span class="nam">calc_fan_in_and_fan_out</span><span class="op">(</span><span class="nam">param</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t233" href="#t233">233</a></span><span class="t">    <span class="nam">std</span> <span class="op">=</span> <span class="nam">gain</span> <span class="op">*</span> <span class="nam">np</span><span class="op">.</span><span class="nam">sqrt</span><span class="op">(</span><span class="num">2.0</span> <span class="op">/</span> <span class="op">(</span><span class="nam">fan_in</span> <span class="op">+</span> <span class="nam">fan_out</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t234" href="#t234">234</a></span><span class="t">    <span class="key">return</span> <span class="nam">nn</span><span class="op">.</span><span class="nam">init</span><span class="op">.</span><span class="nam">normal_</span><span class="op">(</span><span class="nam">param</span><span class="op">,</span> <span class="nam">mean</span><span class="op">=</span><span class="num">0.0</span><span class="op">,</span> <span class="nam">std</span><span class="op">=</span><span class="nam">std</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t235" href="#t235">235</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t236" href="#t236">236</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t237" href="#t237">237</a></span><span class="t"><span class="key">def</span> <span class="nam">init_kaiming_uniform_</span><span class="op">(</span><span class="nam">param</span><span class="op">,</span> <span class="nam">a</span><span class="op">=</span><span class="num">0</span><span class="op">,</span> <span class="nam">nonlinearity</span><span class="op">=</span><span class="str">"relu"</span><span class="op">,</span> <span class="nam">gain</span><span class="op">=</span><span class="num">1.0</span><span class="op">,</span> <span class="nam">mode</span><span class="op">=</span><span class="str">"fan_in"</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t238" href="#t238">238</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t239" href="#t239">239</a></span><span class="t"><span class="str">    Initializes the input tensor using the Kaiming initialization method.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t240" href="#t240">240</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t241" href="#t241">241</a></span><span class="t"><span class="str">    Starting from a std 1 uniform distribution, we scale the weights by c / sqrt(fan_in), where c =</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t242" href="#t242">242</a></span><span class="t"><span class="str">    sqrt(2) if the params were immediately preceded by a relu and 1 for everything else.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t243" href="#t243">243</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t244" href="#t244">244</a></span><span class="t"><span class="str">    As with torch, `a` is a hyperparameter for `nonlinearity`, if it takes one.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t245" href="#t245">245</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t246" href="#t246">246</a></span><span class="t">    <span class="nam">fan_in</span><span class="op">,</span> <span class="nam">fan_out</span> <span class="op">=</span> <span class="nam">calc_fan_in_and_fan_out</span><span class="op">(</span><span class="nam">param</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t247" href="#t247">247</a></span><span class="t">    <span class="nam">fan</span> <span class="op">=</span> <span class="nam">fan_in</span> <span class="key">if</span> <span class="nam">mode</span> <span class="op">==</span> <span class="str">"fan_in"</span> <span class="key">else</span> <span class="nam">fan_out</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t248" href="#t248">248</a></span><span class="t">    <span class="nam">gain</span> <span class="op">*=</span> <span class="nam">nn</span><span class="op">.</span><span class="nam">init</span><span class="op">.</span><span class="nam">calculate_gain</span><span class="op">(</span><span class="nam">nonlinearity</span><span class="op">,</span> <span class="nam">a</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t249" href="#t249">249</a></span><span class="t">    <span class="nam">max</span> <span class="op">=</span> <span class="nam">gain</span> <span class="op">*</span> <span class="nam">np</span><span class="op">.</span><span class="nam">sqrt</span><span class="op">(</span><span class="num">3.0</span> <span class="op">/</span> <span class="nam">fan</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t250" href="#t250">250</a></span><span class="t">    <span class="key">return</span> <span class="nam">nn</span><span class="op">.</span><span class="nam">init</span><span class="op">.</span><span class="nam">uniform_</span><span class="op">(</span><span class="nam">param</span><span class="op">,</span> <span class="op">-</span><span class="nam">max</span><span class="op">,</span> <span class="nam">max</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t251" href="#t251">251</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t252" href="#t252">252</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t253" href="#t253">253</a></span><span class="t"><span class="key">def</span> <span class="nam">init_kaiming_normal_</span><span class="op">(</span><span class="nam">param</span><span class="op">,</span> <span class="nam">a</span><span class="op">=</span><span class="num">0</span><span class="op">,</span> <span class="nam">nonlinearity</span><span class="op">=</span><span class="str">"relu"</span><span class="op">,</span> <span class="nam">gain</span><span class="op">=</span><span class="num">1.0</span><span class="op">,</span> <span class="nam">mode</span><span class="op">=</span><span class="str">"fan_in"</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t254" href="#t254">254</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t255" href="#t255">255</a></span><span class="t"><span class="str">    Initializes the input tensor using the Kaiming initialization method.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t256" href="#t256">256</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t257" href="#t257">257</a></span><span class="t"><span class="str">    Starting from a std 1 normal distribution, we scale the weights by c / sqrt(fan_in), where c =</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t258" href="#t258">258</a></span><span class="t"><span class="str">    sqrt(2) if the params were immediately preceded by a relu and 1 for everything else.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t259" href="#t259">259</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t260" href="#t260">260</a></span><span class="t"><span class="str">    As with torch, `a` is a hyperparameter for `nonlinearity`, if it takes one.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t261" href="#t261">261</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t262" href="#t262">262</a></span><span class="t">    <span class="nam">fan_in</span><span class="op">,</span> <span class="nam">fan_out</span> <span class="op">=</span> <span class="nam">calc_fan_in_and_fan_out</span><span class="op">(</span><span class="nam">param</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t263" href="#t263">263</a></span><span class="t">    <span class="nam">fan</span> <span class="op">=</span> <span class="nam">fan_in</span> <span class="key">if</span> <span class="nam">mode</span> <span class="op">==</span> <span class="str">"fan_in"</span> <span class="key">else</span> <span class="nam">fan_out</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t264" href="#t264">264</a></span><span class="t">    <span class="nam">gain</span> <span class="op">*=</span> <span class="nam">nn</span><span class="op">.</span><span class="nam">init</span><span class="op">.</span><span class="nam">calculate_gain</span><span class="op">(</span><span class="nam">nonlinearity</span><span class="op">,</span> <span class="nam">a</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t265" href="#t265">265</a></span><span class="t">    <span class="nam">std</span> <span class="op">=</span> <span class="nam">gain</span> <span class="op">*</span> <span class="nam">np</span><span class="op">.</span><span class="nam">sqrt</span><span class="op">(</span><span class="num">1.0</span> <span class="op">/</span> <span class="nam">fan</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t266" href="#t266">266</a></span><span class="t">    <span class="key">return</span> <span class="nam">nn</span><span class="op">.</span><span class="nam">init</span><span class="op">.</span><span class="nam">normal_</span><span class="op">(</span><span class="nam">param</span><span class="op">,</span> <span class="nam">mean</span><span class="op">=</span><span class="num">0.0</span><span class="op">,</span> <span class="nam">std</span><span class="op">=</span><span class="nam">std</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t267" href="#t267">267</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t268" href="#t268">268</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t269" href="#t269">269</a></span><span class="t"><span class="key">def</span> <span class="nam">keep_single_column</span><span class="op">(</span><span class="nam">dataset</span><span class="op">:</span> <span class="nam">Dataset</span><span class="op">,</span> <span class="nam">col_name</span><span class="op">:</span> <span class="nam">str</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t270" href="#t270">270</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t271" href="#t271">271</a></span><span class="t"><span class="str">    Acts on a HuggingFace dataset to delete all columns apart from a single column name - useful when we want to tokenize and mix together different strings</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t272" href="#t272">272</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t273" href="#t273">273</a></span><span class="t">    <span class="key">for</span> <span class="nam">key</span> <span class="key">in</span> <span class="nam">dataset</span><span class="op">.</span><span class="nam">features</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t274" href="#t274">274</a></span><span class="t">        <span class="key">if</span> <span class="nam">key</span> <span class="op">!=</span> <span class="nam">col_name</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t275" href="#t275">275</a></span><span class="t">            <span class="nam">dataset</span> <span class="op">=</span> <span class="nam">dataset</span><span class="op">.</span><span class="nam">remove_columns</span><span class="op">(</span><span class="nam">key</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t276" href="#t276">276</a></span><span class="t">    <span class="key">return</span> <span class="nam">dataset</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t277" href="#t277">277</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t278" href="#t278">278</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t279" href="#t279">279</a></span><span class="t"><span class="key">def</span> <span class="nam">tokenize_and_concatenate</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t280" href="#t280">280</a></span><span class="t">    <span class="nam">dataset</span><span class="op">:</span> <span class="nam">Dataset</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t281" href="#t281">281</a></span><span class="t">    <span class="nam">tokenizer</span><span class="op">:</span> <span class="nam">AutoTokenizer</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t282" href="#t282">282</a></span><span class="t">    <span class="nam">streaming</span><span class="op">:</span> <span class="nam">bool</span> <span class="op">=</span> <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t283" href="#t283">283</a></span><span class="t">    <span class="nam">max_length</span><span class="op">:</span> <span class="nam">int</span> <span class="op">=</span> <span class="num">1024</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t284" href="#t284">284</a></span><span class="t">    <span class="nam">column_name</span><span class="op">:</span> <span class="nam">str</span> <span class="op">=</span> <span class="str">"text"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t285" href="#t285">285</a></span><span class="t">    <span class="nam">add_bos_token</span><span class="op">:</span> <span class="nam">bool</span> <span class="op">=</span> <span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t286" href="#t286">286</a></span><span class="t">    <span class="nam">num_proc</span><span class="op">:</span> <span class="nam">int</span> <span class="op">=</span> <span class="num">10</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t287" href="#t287">287</a></span><span class="t"><span class="op">)</span> <span class="op">-></span> <span class="nam">Dataset</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t288" href="#t288">288</a></span><span class="t">    <span class="str">"""Helper function to tokenizer and concatenate a dataset of text. This converts the text to tokens, concatenates them (separated by EOS tokens) and then reshapes them into a 2D array of shape (____, sequence_length), dropping the last batch. Tokenizers are much faster if parallelised, so we chop the string into 20, feed it into the tokenizer, in parallel with padding, then remove padding at the end.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t289" href="#t289">289</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t290" href="#t290">290</a></span><span class="t"><span class="str">    This tokenization is useful for training language models, as it allows us to efficiently train on a large corpus of text of varying lengths (without, eg, a lot of truncation or padding). Further, for models with absolute positional encodings, this avoids privileging early tokens (eg, news articles often begin with CNN, and models may learn to use early positional encodings to predict these)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t291" href="#t291">291</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t292" href="#t292">292</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t293" href="#t293">293</a></span><span class="t"><span class="str">        dataset (Dataset): The dataset to tokenize, assumed to be a HuggingFace text dataset.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t294" href="#t294">294</a></span><span class="t"><span class="str">        tokenizer (AutoTokenizer): The tokenizer. Assumed to have a bos_token_id and an eos_token_id.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t295" href="#t295">295</a></span><span class="t"><span class="str">        streaming (bool, optional): Whether the dataset is being streamed. If True, avoids using parallelism. Defaults to False.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t296" href="#t296">296</a></span><span class="t"><span class="str">        max_length (int, optional): The length of the context window of the sequence. Defaults to 1024.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t297" href="#t297">297</a></span><span class="t"><span class="str">        column_name (str, optional): The name of the text column in the dataset. Defaults to 'text'.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t298" href="#t298">298</a></span><span class="t"><span class="str">        add_bos_token (bool, optional): . Defaults to True.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t299" href="#t299">299</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t300" href="#t300">300</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t301" href="#t301">301</a></span><span class="t"><span class="str">        Dataset: Returns the tokenized dataset, as a dataset of tensors, with a single column called "tokens"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t302" href="#t302">302</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t303" href="#t303">303</a></span><span class="t"><span class="str">    Note: There is a bug when inputting very small datasets (eg, &lt;1 batch per process) where it just outputs nothing. I'm not super sure why</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t304" href="#t304">304</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t305" href="#t305">305</a></span><span class="t">    <span class="nam">dataset</span> <span class="op">=</span> <span class="nam">keep_single_column</span><span class="op">(</span><span class="nam">dataset</span><span class="op">,</span> <span class="nam">column_name</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t306" href="#t306">306</a></span><span class="t">    <span class="key">if</span> <span class="nam">tokenizer</span><span class="op">.</span><span class="nam">pad_token</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t307" href="#t307">307</a></span><span class="t">        <span class="com"># We add a padding token, purely to implement the tokenizer. This will be removed before inputting tokens to the model, so we do not need to increment d_vocab in the model.</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t308" href="#t308">308</a></span><span class="t">        <span class="nam">tokenizer</span><span class="op">.</span><span class="nam">add_special_tokens</span><span class="op">(</span><span class="op">{</span><span class="str">"pad_token"</span><span class="op">:</span> <span class="str">"&lt;PAD>"</span><span class="op">}</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t309" href="#t309">309</a></span><span class="t">    <span class="com"># Define the length to chop things up into - leaving space for a bos_token if required</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t310" href="#t310">310</a></span><span class="t">    <span class="key">if</span> <span class="nam">add_bos_token</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t311" href="#t311">311</a></span><span class="t">        <span class="nam">seq_len</span> <span class="op">=</span> <span class="nam">max_length</span> <span class="op">-</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t312" href="#t312">312</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t313" href="#t313">313</a></span><span class="t">        <span class="nam">seq_len</span> <span class="op">=</span> <span class="nam">max_length</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t314" href="#t314">314</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t315" href="#t315">315</a></span><span class="t">    <span class="key">def</span> <span class="nam">tokenize_function</span><span class="op">(</span><span class="nam">examples</span><span class="op">:</span> <span class="nam">Dict</span><span class="op">[</span><span class="nam">str</span><span class="op">,</span> <span class="nam">List</span><span class="op">[</span><span class="nam">str</span><span class="op">]</span><span class="op">]</span><span class="op">)</span> <span class="op">-></span> <span class="nam">Dict</span><span class="op">[</span><span class="nam">str</span><span class="op">,</span> <span class="nam">np</span><span class="op">.</span><span class="nam">ndarray</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t316" href="#t316">316</a></span><span class="t">        <span class="nam">text</span> <span class="op">=</span> <span class="nam">examples</span><span class="op">[</span><span class="nam">column_name</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t317" href="#t317">317</a></span><span class="t">        <span class="com"># Concatenate it all into an enormous string, separated by eos_tokens</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t318" href="#t318">318</a></span><span class="t">        <span class="nam">full_text</span> <span class="op">=</span> <span class="nam">tokenizer</span><span class="op">.</span><span class="nam">eos_token</span><span class="op">.</span><span class="nam">join</span><span class="op">(</span><span class="nam">text</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t319" href="#t319">319</a></span><span class="t">        <span class="com"># Divide into 20 chunks of ~ equal length</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t320" href="#t320">320</a></span><span class="t">        <span class="nam">num_chunks</span> <span class="op">=</span> <span class="num">20</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t321" href="#t321">321</a></span><span class="t">        <span class="nam">chunk_length</span> <span class="op">=</span> <span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">full_text</span><span class="op">)</span> <span class="op">-</span> <span class="num">1</span><span class="op">)</span> <span class="op">//</span> <span class="nam">num_chunks</span> <span class="op">+</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t322" href="#t322">322</a></span><span class="t">        <span class="nam">chunks</span> <span class="op">=</span> <span class="op">[</span><span class="nam">full_text</span><span class="op">[</span><span class="nam">i</span> <span class="op">*</span> <span class="nam">chunk_length</span> <span class="op">:</span> <span class="op">(</span><span class="nam">i</span> <span class="op">+</span> <span class="num">1</span><span class="op">)</span> <span class="op">*</span> <span class="nam">chunk_length</span><span class="op">]</span> <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">num_chunks</span><span class="op">)</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t323" href="#t323">323</a></span><span class="t">        <span class="com"># Tokenize the chunks in parallel. Uses NumPy because HuggingFace map doesn't want tensors returned</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t324" href="#t324">324</a></span><span class="t">        <span class="nam">tokens</span> <span class="op">=</span> <span class="nam">tokenizer</span><span class="op">(</span><span class="nam">chunks</span><span class="op">,</span> <span class="nam">return_tensors</span><span class="op">=</span><span class="str">"np"</span><span class="op">,</span> <span class="nam">padding</span><span class="op">=</span><span class="key">True</span><span class="op">)</span><span class="op">[</span><span class="str">"input_ids"</span><span class="op">]</span><span class="op">.</span><span class="nam">flatten</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t325" href="#t325">325</a></span><span class="t">        <span class="com"># Drop padding tokens</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t326" href="#t326">326</a></span><span class="t">        <span class="nam">tokens</span> <span class="op">=</span> <span class="nam">tokens</span><span class="op">[</span><span class="nam">tokens</span> <span class="op">!=</span> <span class="nam">tokenizer</span><span class="op">.</span><span class="nam">pad_token_id</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t327" href="#t327">327</a></span><span class="t">        <span class="nam">num_tokens</span> <span class="op">=</span> <span class="nam">len</span><span class="op">(</span><span class="nam">tokens</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t328" href="#t328">328</a></span><span class="t">        <span class="nam">num_batches</span> <span class="op">=</span> <span class="nam">num_tokens</span> <span class="op">//</span> <span class="op">(</span><span class="nam">seq_len</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t329" href="#t329">329</a></span><span class="t">        <span class="com"># Drop the final tokens if not enough to make a full sequence</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t330" href="#t330">330</a></span><span class="t">        <span class="nam">tokens</span> <span class="op">=</span> <span class="nam">tokens</span><span class="op">[</span><span class="op">:</span> <span class="nam">seq_len</span> <span class="op">*</span> <span class="nam">num_batches</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t331" href="#t331">331</a></span><span class="t">        <span class="nam">tokens</span> <span class="op">=</span> <span class="nam">einops</span><span class="op">.</span><span class="nam">rearrange</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t332" href="#t332">332</a></span><span class="t">            <span class="nam">tokens</span><span class="op">,</span> <span class="str">"(batch seq) -> batch seq"</span><span class="op">,</span> <span class="nam">batch</span><span class="op">=</span><span class="nam">num_batches</span><span class="op">,</span> <span class="nam">seq</span><span class="op">=</span><span class="nam">seq_len</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t333" href="#t333">333</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t334" href="#t334">334</a></span><span class="t">        <span class="key">if</span> <span class="nam">add_bos_token</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t335" href="#t335">335</a></span><span class="t">            <span class="nam">prefix</span> <span class="op">=</span> <span class="nam">np</span><span class="op">.</span><span class="nam">full</span><span class="op">(</span><span class="op">(</span><span class="nam">num_batches</span><span class="op">,</span> <span class="num">1</span><span class="op">)</span><span class="op">,</span> <span class="nam">tokenizer</span><span class="op">.</span><span class="nam">bos_token_id</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t336" href="#t336">336</a></span><span class="t">            <span class="nam">tokens</span> <span class="op">=</span> <span class="nam">np</span><span class="op">.</span><span class="nam">concatenate</span><span class="op">(</span><span class="op">[</span><span class="nam">prefix</span><span class="op">,</span> <span class="nam">tokens</span><span class="op">]</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t337" href="#t337">337</a></span><span class="t">        <span class="key">return</span> <span class="op">{</span><span class="str">"tokens"</span><span class="op">:</span> <span class="nam">tokens</span><span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t338" href="#t338">338</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t339" href="#t339">339</a></span><span class="t">    <span class="nam">tokenized_dataset</span> <span class="op">=</span> <span class="nam">dataset</span><span class="op">.</span><span class="nam">map</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t340" href="#t340">340</a></span><span class="t">        <span class="nam">tokenize_function</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t341" href="#t341">341</a></span><span class="t">        <span class="nam">batched</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t342" href="#t342">342</a></span><span class="t">        <span class="nam">num_proc</span><span class="op">=</span><span class="op">(</span><span class="nam">num_proc</span> <span class="key">if</span> <span class="key">not</span> <span class="nam">streaming</span> <span class="key">else</span> <span class="key">None</span><span class="op">)</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t343" href="#t343">343</a></span><span class="t">        <span class="nam">remove_columns</span><span class="op">=</span><span class="op">[</span><span class="nam">column_name</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t344" href="#t344">344</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t345" href="#t345">345</a></span><span class="t">    <span class="nam">tokenized_dataset</span><span class="op">.</span><span class="nam">set_format</span><span class="op">(</span><span class="nam">type</span><span class="op">=</span><span class="str">"torch"</span><span class="op">,</span> <span class="nam">columns</span><span class="op">=</span><span class="op">[</span><span class="str">"tokens"</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t346" href="#t346">346</a></span><span class="t">    <span class="key">return</span> <span class="nam">tokenized_dataset</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t347" href="#t347">347</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t348" href="#t348">348</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t349" href="#t349">349</a></span><span class="t"><span class="key">def</span> <span class="nam">sample_logits</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t350" href="#t350">350</a></span><span class="t">    <span class="nam">final_logits</span><span class="op">:</span> <span class="nam">Float</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">"batch d_vocab"</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t351" href="#t351">351</a></span><span class="t">    <span class="nam">top_k</span><span class="op">:</span> <span class="nam">Optional</span><span class="op">[</span><span class="nam">int</span><span class="op">]</span> <span class="op">=</span> <span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t352" href="#t352">352</a></span><span class="t">    <span class="nam">top_p</span><span class="op">:</span> <span class="nam">Optional</span><span class="op">[</span><span class="nam">float</span><span class="op">]</span> <span class="op">=</span> <span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t353" href="#t353">353</a></span><span class="t">    <span class="nam">temperature</span><span class="op">:</span> <span class="nam">float</span> <span class="op">=</span> <span class="num">1.0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t354" href="#t354">354</a></span><span class="t">    <span class="nam">freq_penalty</span><span class="op">:</span> <span class="nam">float</span> <span class="op">=</span> <span class="num">0.0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t355" href="#t355">355</a></span><span class="t">    <span class="nam">tokens</span><span class="op">:</span> <span class="nam">Optional</span><span class="op">[</span><span class="nam">Int</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">"batch pos"</span><span class="op">]</span><span class="op">]</span> <span class="op">=</span> <span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t356" href="#t356">356</a></span><span class="t"><span class="op">)</span> <span class="op">-></span> <span class="nam">Int</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">"batch"</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t357" href="#t357">357</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t358" href="#t358">358</a></span><span class="t"><span class="str">    Sample from the logits, in order to generate text</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t359" href="#t359">359</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t360" href="#t360">360</a></span><span class="t"><span class="str">    final_logits has shape [batch, vocab_size]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t361" href="#t361">361</a></span><span class="t"><span class="str">    We divide the logits by temperature before softmaxing and sampling - high temperature = more uniform, low = more argmaxy. Temp = 0.0 is greedy sampling</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t362" href="#t362">362</a></span><span class="t"><span class="str">    We apply top_k and top_p filtering to the logits, to encourage diversity. top_k = 10 means we only sample from the 10 most likely tokens. top_p = 0.9 means we only sample from the top 90% of tokens, and then renormalise the distribution. top_k and top_p are mutually exclusive. By default we apply neither and just sample from the full distribution.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t363" href="#t363">363</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t364" href="#t364">364</a></span><span class="t"><span class="str">    Frequency penalty is a penalty on the probability of a token, proportional to the number of times it has been generated so far. This encourages the model to generate new tokens, rather than repeating itself. It is a hyperparameter, and should be tuned. It is applied to the logits before sampling. If this is non-zero it is required to input the input_tokens</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t365" href="#t365">365</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t366" href="#t366">366</a></span><span class="t"><span class="str">    #! TODO: Finish testing all the edge cases here. Useful testing code:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t367" href="#t367">367</a></span><span class="t"><span class="str">    logits = torch.randn(4)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t368" href="#t368">368</a></span><span class="t"><span class="str">    print(logits)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t369" href="#t369">369</a></span><span class="t"><span class="str">    np.unique(np.array([sample_logits(logits, top_k=2).item() for i in range(1000)]), return_counts=True)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t370" href="#t370">370</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t371" href="#t371">371</a></span><span class="t">    <span class="key">if</span> <span class="nam">temperature</span> <span class="op">==</span> <span class="num">0.0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t372" href="#t372">372</a></span><span class="t">        <span class="com"># Greedy sampling</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t373" href="#t373">373</a></span><span class="t">        <span class="key">return</span> <span class="nam">final_logits</span><span class="op">.</span><span class="nam">argmax</span><span class="op">(</span><span class="nam">dim</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t374" href="#t374">374</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t375" href="#t375">375</a></span><span class="t">        <span class="com"># Sample from the distribution</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t376" href="#t376">376</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t377" href="#t377">377</a></span><span class="t">        <span class="nam">final_logits</span> <span class="op">=</span> <span class="nam">final_logits</span> <span class="op">/</span> <span class="nam">temperature</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t378" href="#t378">378</a></span><span class="t">        <span class="key">if</span> <span class="nam">freq_penalty</span> <span class="op">></span> <span class="num">0</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t379" href="#t379">379</a></span><span class="t">            <span class="key">assert</span> <span class="nam">tokens</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">,</span> <span class="str">"Must provide input_tokens if applying a frequency penalty"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t380" href="#t380">380</a></span><span class="t">            <span class="key">for</span> <span class="nam">batch_index</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">final_logits</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t381" href="#t381">381</a></span><span class="t">                <span class="com"># torch.bincount returns a tensor of length d_vocab, with the number of occurences of each token in the tokens.</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t382" href="#t382">382</a></span><span class="t">                <span class="nam">final_logits</span><span class="op">[</span><span class="nam">batch_index</span><span class="op">]</span> <span class="op">=</span> <span class="nam">final_logits</span><span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t383" href="#t383">383</a></span><span class="t">                    <span class="nam">batch_index</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t384" href="#t384">384</a></span><span class="t">                <span class="op">]</span> <span class="op">-</span> <span class="nam">freq_penalty</span> <span class="op">*</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">bincount</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t385" href="#t385">385</a></span><span class="t">                    <span class="nam">tokens</span><span class="op">[</span><span class="nam">batch_index</span><span class="op">]</span><span class="op">,</span> <span class="nam">minlength</span><span class="op">=</span><span class="nam">final_logits</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t386" href="#t386">386</a></span><span class="t">                <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t387" href="#t387">387</a></span><span class="t">        <span class="key">if</span> <span class="nam">top_k</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t388" href="#t388">388</a></span><span class="t">            <span class="key">assert</span> <span class="nam">top_k</span> <span class="op">></span> <span class="num">0</span><span class="op">,</span> <span class="str">"top_k has to be greater than 0"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t389" href="#t389">389</a></span><span class="t">            <span class="nam">top_logits</span><span class="op">,</span> <span class="nam">top_idx</span> <span class="op">=</span> <span class="nam">final_logits</span><span class="op">.</span><span class="nam">topk</span><span class="op">(</span><span class="nam">top_k</span><span class="op">,</span> <span class="nam">dim</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t390" href="#t390">390</a></span><span class="t">            <span class="nam">indices_to_remove</span> <span class="op">=</span> <span class="nam">final_logits</span> <span class="op">&lt;</span> <span class="nam">top_logits</span><span class="op">[</span><span class="op">...</span><span class="op">,</span> <span class="op">-</span><span class="num">1</span><span class="op">]</span><span class="op">.</span><span class="nam">unsqueeze</span><span class="op">(</span><span class="op">-</span><span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t391" href="#t391">391</a></span><span class="t">            <span class="nam">final_logits</span> <span class="op">=</span> <span class="nam">final_logits</span><span class="op">.</span><span class="nam">masked_fill</span><span class="op">(</span><span class="nam">indices_to_remove</span><span class="op">,</span> <span class="op">-</span><span class="nam">float</span><span class="op">(</span><span class="str">"inf"</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t392" href="#t392">392</a></span><span class="t">        <span class="key">elif</span> <span class="nam">top_p</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t393" href="#t393">393</a></span><span class="t">            <span class="key">assert</span> <span class="num">1.0</span> <span class="op">>=</span> <span class="nam">top_p</span> <span class="op">></span> <span class="num">0.0</span><span class="op">,</span> <span class="str">"top_p has to be in (0, 1]"</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t394" href="#t394">394</a></span><span class="t">            <span class="nam">sorted_logits</span><span class="op">,</span> <span class="nam">sorted_indices</span> <span class="op">=</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">sort</span><span class="op">(</span><span class="nam">final_logits</span><span class="op">,</span> <span class="nam">descending</span><span class="op">=</span><span class="key">True</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t395" href="#t395">395</a></span><span class="t">            <span class="nam">cumulative_probs</span> <span class="op">=</span> <span class="nam">sorted_logits</span><span class="op">.</span><span class="nam">softmax</span><span class="op">(</span><span class="nam">dim</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">)</span><span class="op">.</span><span class="nam">cumsum</span><span class="op">(</span><span class="nam">dim</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t396" href="#t396">396</a></span><span class="t">            <span class="com"># We round up - we want prob >= top_p not &lt;top_p</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t397" href="#t397">397</a></span><span class="t">            <span class="nam">sorted_indices_to_remove</span> <span class="op">=</span> <span class="nam">cumulative_probs</span> <span class="op">></span> <span class="nam">top_p</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t398" href="#t398">398</a></span><span class="t">            <span class="nam">sorted_indices_to_remove</span><span class="op">[</span><span class="op">...</span><span class="op">,</span> <span class="num">1</span><span class="op">:</span><span class="op">]</span> <span class="op">=</span> <span class="nam">sorted_indices_to_remove</span><span class="op">[</span><span class="op">...</span><span class="op">,</span> <span class="op">:</span><span class="op">-</span><span class="num">1</span><span class="op">]</span><span class="op">.</span><span class="nam">clone</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t399" href="#t399">399</a></span><span class="t">            <span class="nam">sorted_indices_to_remove</span><span class="op">[</span><span class="op">...</span><span class="op">,</span> <span class="num">0</span><span class="op">]</span> <span class="op">=</span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t400" href="#t400">400</a></span><span class="t">            <span class="nam">indices_to_remove</span> <span class="op">=</span> <span class="nam">sorted_indices_to_remove</span><span class="op">.</span><span class="nam">scatter</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t401" href="#t401">401</a></span><span class="t">                <span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="nam">sorted_indices</span><span class="op">,</span> <span class="nam">sorted_indices_to_remove</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t402" href="#t402">402</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t403" href="#t403">403</a></span><span class="t">            <span class="nam">final_logits</span> <span class="op">=</span> <span class="nam">final_logits</span><span class="op">.</span><span class="nam">masked_fill</span><span class="op">(</span><span class="nam">indices_to_remove</span><span class="op">,</span> <span class="op">-</span><span class="nam">float</span><span class="op">(</span><span class="str">"inf"</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t404" href="#t404">404</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t405" href="#t405">405</a></span><span class="t">        <span class="nam">final_logits</span> <span class="op">=</span> <span class="nam">final_logits</span><span class="op">.</span><span class="nam">to</span><span class="op">(</span><span class="nam">torch</span><span class="op">.</span><span class="nam">float32</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t406" href="#t406">406</a></span><span class="t">        <span class="key">return</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">distributions</span><span class="op">.</span><span class="nam">categorical</span><span class="op">.</span><span class="nam">Categorical</span><span class="op">(</span><span class="nam">logits</span><span class="op">=</span><span class="nam">final_logits</span><span class="op">)</span><span class="op">.</span><span class="nam">sample</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t407" href="#t407">407</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t408" href="#t408">408</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t409" href="#t409">409</a></span><span class="t"><span class="com"># Type alias</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t410" href="#t410">410</a></span><span class="t"><span class="nam">SliceInput</span> <span class="op">=</span> <span class="nam">Optional</span><span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t411" href="#t411">411</a></span><span class="t">    <span class="nam">Union</span><span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t412" href="#t412">412</a></span><span class="t">        <span class="nam">int</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t413" href="#t413">413</a></span><span class="t">        <span class="nam">Tuple</span><span class="op">[</span><span class="nam">int</span><span class="op">,</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t414" href="#t414">414</a></span><span class="t">        <span class="nam">Tuple</span><span class="op">[</span><span class="nam">int</span><span class="op">,</span> <span class="nam">int</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t415" href="#t415">415</a></span><span class="t">        <span class="nam">Tuple</span><span class="op">[</span><span class="nam">int</span><span class="op">,</span> <span class="nam">int</span><span class="op">,</span> <span class="nam">int</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t416" href="#t416">416</a></span><span class="t">        <span class="nam">List</span><span class="op">[</span><span class="nam">int</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t417" href="#t417">417</a></span><span class="t">        <span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t418" href="#t418">418</a></span><span class="t">        <span class="nam">np</span><span class="op">.</span><span class="nam">ndarray</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t419" href="#t419">419</a></span><span class="t">    <span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t420" href="#t420">420</a></span><span class="t"><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t421" href="#t421">421</a></span><span class="t"><span class="str">"""An object that represents a slice input. It can be a tuple of integers or a slice object.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t422" href="#t422">422</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t423" href="#t423">423</a></span><span class="t"><span class="str">An optional type alias for a slice input used in the `ActivationCache` module.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t424" href="#t424">424</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t425" href="#t425">425</a></span><span class="t"><span class="str">A `SliceInput` can be one of the following types:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t426" href="#t426">426</a></span><span class="t"><span class="str">    - `int`: an integer representing a single position</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t427" href="#t427">427</a></span><span class="t"><span class="str">    - `Tuple[int, int]`: a tuple of two integers representing a range of positions</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t428" href="#t428">428</a></span><span class="t"><span class="str">    - `Tuple[int, int, int]`: a tuple of three integers representing a range of positions with a step size</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t429" href="#t429">429</a></span><span class="t"><span class="str">    - `List[int]`: a list of integers representing multiple positions</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t430" href="#t430">430</a></span><span class="t"><span class="str">    - `torch.Tensor`: a tensor containing a boolean mask or a list of indices to be selected from the input tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t431" href="#t431">431</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t432" href="#t432">432</a></span><span class="t"><span class="str">`SliceInput` is used in the `apply_ln_to_stack` method in the `ActivationCache` module.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t433" href="#t433">433</a></span><span class="t"><span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t434" href="#t434">434</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t435" href="#t435">435</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t436" href="#t436">436</a></span><span class="t"><span class="key">class</span> <span class="nam">Slice</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t437" href="#t437">437</a></span><span class="t">    <span class="str">"""An object that represents a slice input. It can be a tuple of integers or a slice object.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t438" href="#t438">438</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t439" href="#t439">439</a></span><span class="t"><span class="str">    We use a custom slice syntax because Python/Torch's don't let us reduce the number of dimensions:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t440" href="#t440">440</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t441" href="#t441">441</a></span><span class="t"><span class="str">    Note that slicing with input_slice=None means do nothing, NOT add an extra dimension (use unsqueeze for that)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t442" href="#t442">442</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t443" href="#t443">443</a></span><span class="t"><span class="str">    There are several modes:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t444" href="#t444">444</a></span><span class="t"><span class="str">    int - just index with that integer (decreases number of dimensions)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t445" href="#t445">445</a></span><span class="t"><span class="str">    slice - Input is a tuple converted to a slice ((k,) means :k, (k, m) means m:k, (k, m, n) means m:k:n)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t446" href="#t446">446</a></span><span class="t"><span class="str">    array - Input is a list or tensor or numpy array, converted to a numpy array, and we take the stack of values at those indices</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t447" href="#t447">447</a></span><span class="t"><span class="str">    identity - Input is None, leave it unchanged.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t448" href="#t448">448</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t449" href="#t449">449</a></span><span class="t"><span class="str">    Examples for dim=0:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t450" href="#t450">450</a></span><span class="t"><span class="str">    if input_slice=0, tensor -> tensor[0]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t451" href="#t451">451</a></span><span class="t"><span class="str">    elif input_slice = (1, 5), tensor -> tensor[1:5]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t452" href="#t452">452</a></span><span class="t"><span class="str">    elif input_slice = (1, 5, 2), tensor -> tensor[1:5:2] (ie indexing with [1, 3])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t453" href="#t453">453</a></span><span class="t"><span class="str">    elif input_slice = [1, 4, 5], tensor -> tensor[[1, 4, 5]] (ie changing the first axis to have length 3, and taking the indices 1, 4, 5 out).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t454" href="#t454">454</a></span><span class="t"><span class="str">    elif input_slice is a Tensor, same as list - Tensor is assumed to be a 1D list of indices.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t455" href="#t455">455</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t456" href="#t456">456</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t457" href="#t457">457</a></span><span class="t">    <span class="nam">slice</span><span class="op">:</span> <span class="nam">Union</span><span class="op">[</span><span class="nam">int</span><span class="op">,</span> <span class="nam">slice</span><span class="op">,</span> <span class="nam">np</span><span class="op">.</span><span class="nam">ndarray</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t458" href="#t458">458</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t459" href="#t459">459</a></span><span class="t">    <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t460" href="#t460">460</a></span><span class="t">        <span class="nam">self</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t461" href="#t461">461</a></span><span class="t">        <span class="nam">input_slice</span><span class="op">:</span> <span class="nam">SliceInput</span> <span class="op">=</span> <span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t462" href="#t462">462</a></span><span class="t">    <span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t463" href="#t463">463</a></span><span class="t">        <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t464" href="#t464">464</a></span><span class="t"><span class="str">        Modular component for slicing tensors. Can be used to slice a tensor along a given dimension, or to index into a tensor along a given dimension.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t465" href="#t465">465</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t466" href="#t466">466</a></span><span class="t"><span class="str">        Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t467" href="#t467">467</a></span><span class="t"><span class="str">            input_slice (SliceInput): The slice to apply. Can be an int, a tuple, a list, a torch.Tensor, or None. If None, do nothing.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t468" href="#t468">468</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t469" href="#t469">469</a></span><span class="t"><span class="str">        Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t470" href="#t470">470</a></span><span class="t"><span class="str">            ValueError: If the input_slice is not one of the above types.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t471" href="#t471">471</a></span><span class="t"><span class="str">        """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t472" href="#t472">472</a></span><span class="t">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">input_slice</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t473" href="#t473">473</a></span><span class="t">            <span class="nam">self</span><span class="op">.</span><span class="nam">slice</span> <span class="op">=</span> <span class="nam">slice</span><span class="op">(</span><span class="op">*</span><span class="nam">input_slice</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t474" href="#t474">474</a></span><span class="t">            <span class="nam">self</span><span class="op">.</span><span class="nam">mode</span> <span class="op">=</span> <span class="str">"slice"</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t475" href="#t475">475</a></span><span class="t">        <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">input_slice</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t476" href="#t476">476</a></span><span class="t">            <span class="nam">self</span><span class="op">.</span><span class="nam">slice</span> <span class="op">=</span> <span class="nam">input_slice</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t477" href="#t477">477</a></span><span class="t">            <span class="nam">self</span><span class="op">.</span><span class="nam">mode</span> <span class="op">=</span> <span class="str">"int"</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t478" href="#t478">478</a></span><span class="t">        <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">input_slice</span><span class="op">,</span> <span class="nam">slice</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">478&#x202F;&#x219B;&#x202F;479</span><span class="annotate long">line 478 didn't jump to line 479, because the condition on line 478 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t479" href="#t479">479</a></span><span class="t">            <span class="nam">self</span><span class="op">.</span><span class="nam">slice</span> <span class="op">=</span> <span class="nam">input_slice</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t480" href="#t480">480</a></span><span class="t">            <span class="nam">self</span><span class="op">.</span><span class="nam">mode</span> <span class="op">=</span> <span class="str">"slice"</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t481" href="#t481">481</a></span><span class="t">        <span class="key">elif</span> <span class="nam">type</span><span class="op">(</span><span class="nam">input_slice</span><span class="op">)</span> <span class="key">in</span> <span class="op">[</span><span class="nam">list</span><span class="op">,</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="nam">np</span><span class="op">.</span><span class="nam">ndarray</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t482" href="#t482">482</a></span><span class="t">            <span class="nam">self</span><span class="op">.</span><span class="nam">slice</span> <span class="op">=</span> <span class="nam">to_numpy</span><span class="op">(</span><span class="nam">input_slice</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t483" href="#t483">483</a></span><span class="t">            <span class="nam">self</span><span class="op">.</span><span class="nam">mode</span> <span class="op">=</span> <span class="str">"array"</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t484" href="#t484">484</a></span><span class="t">        <span class="key">elif</span> <span class="nam">input_slice</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">484&#x202F;&#x219B;&#x202F;488</span><span class="annotate long">line 484 didn't jump to line 488, because the condition on line 484 was never false</span></span></p>
    <p class="run"><span class="n"><a id="t485" href="#t485">485</a></span><span class="t">            <span class="nam">self</span><span class="op">.</span><span class="nam">slice</span> <span class="op">=</span> <span class="nam">slice</span><span class="op">(</span><span class="key">None</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t486" href="#t486">486</a></span><span class="t">            <span class="nam">self</span><span class="op">.</span><span class="nam">mode</span> <span class="op">=</span> <span class="str">"identity"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t487" href="#t487">487</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t488" href="#t488">488</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">f"Invalid input_slice {input_slice}"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t489" href="#t489">489</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t490" href="#t490">490</a></span><span class="t">    <span class="key">def</span> <span class="nam">apply</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t491" href="#t491">491</a></span><span class="t">        <span class="nam">self</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t492" href="#t492">492</a></span><span class="t">        <span class="nam">tensor</span><span class="op">:</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t493" href="#t493">493</a></span><span class="t">        <span class="nam">dim</span><span class="op">:</span> <span class="nam">int</span> <span class="op">=</span> <span class="num">0</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t494" href="#t494">494</a></span><span class="t">    <span class="op">)</span> <span class="op">-></span> <span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t495" href="#t495">495</a></span><span class="t">        <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t496" href="#t496">496</a></span><span class="t"><span class="str">        Takes in a tensor and a slice, and applies the slice to the given dimension (supports positive and negative dimension syntax). Returns the sliced tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t497" href="#t497">497</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t498" href="#t498">498</a></span><span class="t"><span class="str">        Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t499" href="#t499">499</a></span><span class="t"><span class="str">            tensor (torch.Tensor): The tensor to slice.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t500" href="#t500">500</a></span><span class="t"><span class="str">            dim (int, optional): The dimension to slice along. Supports positive and negative dimension syntax.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t501" href="#t501">501</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t502" href="#t502">502</a></span><span class="t"><span class="str">        Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t503" href="#t503">503</a></span><span class="t"><span class="str">            torch.Tensor: The sliced tensor.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t504" href="#t504">504</a></span><span class="t"><span class="str">        """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t505" href="#t505">505</a></span><span class="t">        <span class="nam">ndim</span> <span class="op">=</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">ndim</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t506" href="#t506">506</a></span><span class="t">        <span class="nam">slices</span> <span class="op">=</span> <span class="op">[</span><span class="nam">slice</span><span class="op">(</span><span class="key">None</span><span class="op">)</span><span class="op">]</span> <span class="op">*</span> <span class="nam">ndim</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t507" href="#t507">507</a></span><span class="t">        <span class="nam">slices</span><span class="op">[</span><span class="nam">dim</span><span class="op">]</span> <span class="op">=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">slice</span>  <span class="com"># type: ignore</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t508" href="#t508">508</a></span><span class="t">        <span class="key">return</span> <span class="nam">tensor</span><span class="op">[</span><span class="nam">tuple</span><span class="op">(</span><span class="nam">slices</span><span class="op">)</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t509" href="#t509">509</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t510" href="#t510">510</a></span><span class="t">    <span class="key">def</span> <span class="nam">indices</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t511" href="#t511">511</a></span><span class="t">        <span class="nam">self</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t512" href="#t512">512</a></span><span class="t">        <span class="nam">max_ctx</span><span class="op">:</span> <span class="nam">Optional</span><span class="op">[</span><span class="nam">int</span><span class="op">]</span> <span class="op">=</span> <span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t513" href="#t513">513</a></span><span class="t">    <span class="op">)</span> <span class="op">-></span> <span class="nam">Union</span><span class="op">[</span><span class="nam">np</span><span class="op">.</span><span class="nam">ndarray</span><span class="op">,</span> <span class="nam">np</span><span class="op">.</span><span class="nam">int32</span><span class="op">,</span> <span class="nam">np</span><span class="op">.</span><span class="nam">int64</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t514" href="#t514">514</a></span><span class="t">        <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t515" href="#t515">515</a></span><span class="t"><span class="str">        Returns the indices when this slice is applied to an axis of size max_ctx. Returns them as a numpy array, for integer slicing it is eg array([4])</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t516" href="#t516">516</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t517" href="#t517">517</a></span><span class="t"><span class="str">        Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t518" href="#t518">518</a></span><span class="t"><span class="str">            max_ctx (int, optional): The size of the axis to slice. Only used if the slice is not an integer.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t519" href="#t519">519</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t520" href="#t520">520</a></span><span class="t"><span class="str">        Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t521" href="#t521">521</a></span><span class="t"><span class="str">            np.ndarray: The indices that this slice will select.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t522" href="#t522">522</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t523" href="#t523">523</a></span><span class="t"><span class="str">        Raises:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t524" href="#t524">524</a></span><span class="t"><span class="str">            ValueError: If the slice is not an integer and max_ctx is not specified.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t525" href="#t525">525</a></span><span class="t"><span class="str">        """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t526" href="#t526">526</a></span><span class="t">        <span class="key">if</span> <span class="nam">self</span><span class="op">.</span><span class="nam">mode</span> <span class="op">==</span> <span class="str">"int"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t527" href="#t527">527</a></span><span class="t">            <span class="key">return</span> <span class="nam">np</span><span class="op">.</span><span class="nam">array</span><span class="op">(</span><span class="op">[</span><span class="nam">self</span><span class="op">.</span><span class="nam">slice</span><span class="op">]</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">np</span><span class="op">.</span><span class="nam">int64</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t528" href="#t528">528</a></span><span class="t">        <span class="key">if</span> <span class="nam">max_ctx</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t529" href="#t529">529</a></span><span class="t">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">"max_ctx must be specified if slice is not an integer"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t530" href="#t530">530</a></span><span class="t">        <span class="key">return</span> <span class="nam">np</span><span class="op">.</span><span class="nam">arange</span><span class="op">(</span><span class="nam">max_ctx</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">np</span><span class="op">.</span><span class="nam">int64</span><span class="op">)</span><span class="op">[</span><span class="nam">self</span><span class="op">.</span><span class="nam">slice</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t531" href="#t531">531</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t532" href="#t532">532</a></span><span class="t">    <span class="key">def</span> <span class="nam">__repr__</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t533" href="#t533">533</a></span><span class="t">        <span class="nam">self</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t534" href="#t534">534</a></span><span class="t">    <span class="op">)</span> <span class="op">-></span> <span class="nam">str</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t535" href="#t535">535</a></span><span class="t">        <span class="key">return</span> <span class="str">f"Slice: {self.slice} Mode: {self.mode} "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t536" href="#t536">536</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t537" href="#t537">537</a></span><span class="t">    <span class="op">@</span><span class="nam">classmethod</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t538" href="#t538">538</a></span><span class="t">    <span class="key">def</span> <span class="nam">unwrap</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t539" href="#t539">539</a></span><span class="t">        <span class="nam">cls</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t540" href="#t540">540</a></span><span class="t">        <span class="nam">slice_input</span><span class="op">:</span> <span class="nam">Union</span><span class="op">[</span><span class="str">"Slice"</span><span class="op">,</span> <span class="nam">SliceInput</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t541" href="#t541">541</a></span><span class="t">    <span class="op">)</span> <span class="op">-></span> <span class="str">"Slice"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t542" href="#t542">542</a></span><span class="t">        <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t543" href="#t543">543</a></span><span class="t"><span class="str">        Takes a Slice-like input and converts it into a Slice, if it is not already.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t544" href="#t544">544</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t545" href="#t545">545</a></span><span class="t"><span class="str">        Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t546" href="#t546">546</a></span><span class="t"><span class="str">            slice_input (Union[Slice, SliceInput]): The input to turn into a Slice.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t547" href="#t547">547</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t548" href="#t548">548</a></span><span class="t"><span class="str">        Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t549" href="#t549">549</a></span><span class="t"><span class="str">            Slice: A Slice object.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t550" href="#t550">550</a></span><span class="t"><span class="str">        """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t551" href="#t551">551</a></span><span class="t">        <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">slice_input</span><span class="op">,</span> <span class="nam">Slice</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t552" href="#t552">552</a></span><span class="t">            <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t553" href="#t553">553</a></span><span class="t">                <span class="nam">slice_input</span><span class="op">,</span> <span class="nam">int</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t554" href="#t554">554</a></span><span class="t">            <span class="op">)</span><span class="op">:</span>  <span class="com"># slicing with an int collapses the dimension so this stops the pos dimension from collapsing</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t555" href="#t555">555</a></span><span class="t">                <span class="nam">slice_input</span> <span class="op">=</span> <span class="op">[</span><span class="nam">slice_input</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t556" href="#t556">556</a></span><span class="t">            <span class="nam">slice_input</span> <span class="op">=</span> <span class="nam">Slice</span><span class="op">(</span><span class="nam">slice_input</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t557" href="#t557">557</a></span><span class="t">        <span class="key">return</span> <span class="nam">slice_input</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t558" href="#t558">558</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t559" href="#t559">559</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t560" href="#t560">560</a></span><span class="t"><span class="key">def</span> <span class="nam">get_act_name</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t561" href="#t561">561</a></span><span class="t">    <span class="nam">name</span><span class="op">:</span> <span class="nam">str</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t562" href="#t562">562</a></span><span class="t">    <span class="nam">layer</span><span class="op">:</span> <span class="nam">Optional</span><span class="op">[</span><span class="nam">Union</span><span class="op">[</span><span class="nam">int</span><span class="op">,</span> <span class="nam">str</span><span class="op">]</span><span class="op">]</span> <span class="op">=</span> <span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t563" href="#t563">563</a></span><span class="t">    <span class="nam">layer_type</span><span class="op">:</span> <span class="nam">Optional</span><span class="op">[</span><span class="nam">str</span><span class="op">]</span> <span class="op">=</span> <span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t564" href="#t564">564</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t565" href="#t565">565</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t566" href="#t566">566</a></span><span class="t"><span class="str">    Helper function to convert shorthand to an activation name. Pretty hacky, intended to be useful for short feedback</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t567" href="#t567">567</a></span><span class="t"><span class="str">    loop hacking stuff together, more so than writing good, readable code. But it is deterministic!</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t568" href="#t568">568</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t569" href="#t569">569</a></span><span class="t"><span class="str">    Returns a name corresponding to an activation point in a TransformerLens model.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t570" href="#t570">570</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t571" href="#t571">571</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t572" href="#t572">572</a></span><span class="t"><span class="str">         name (str): Takes in the name of the activation. This can be used to specify any activation name by itself.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t573" href="#t573">573</a></span><span class="t"><span class="str">         The code assumes the first sequence of digits passed to it (if any) is the layer number, and anything after</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t574" href="#t574">574</a></span><span class="t"><span class="str">         that is the layer type.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t575" href="#t575">575</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t576" href="#t576">576</a></span><span class="t"><span class="str">         Given only a word and number, it leaves layer_type as is.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t577" href="#t577">577</a></span><span class="t"><span class="str">         Given only a word, it leaves layer and layer_type as is.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t578" href="#t578">578</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t579" href="#t579">579</a></span><span class="t"><span class="str">         Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t580" href="#t580">580</a></span><span class="t"><span class="str">             get_act_name('embed') = get_act_name('embed', None, None)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t581" href="#t581">581</a></span><span class="t"><span class="str">             get_act_name('k6') = get_act_name('k', 6, None)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t582" href="#t582">582</a></span><span class="t"><span class="str">             get_act_name('scale4ln1') = get_act_name('scale', 4, 'ln1')</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t583" href="#t583">583</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t584" href="#t584">584</a></span><span class="t"><span class="str">         layer (int, optional): Takes in the layer number. Used for activations that appear in every block.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t585" href="#t585">585</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t586" href="#t586">586</a></span><span class="t"><span class="str">         layer_type (string, optional): Used to distinguish between activations that appear multiple times in one block.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t587" href="#t587">587</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t588" href="#t588">588</a></span><span class="t"><span class="str">    Full Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t589" href="#t589">589</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t590" href="#t590">590</a></span><span class="t"><span class="str">    get_act_name('k', 6, 'a')=='blocks.6.attn.hook_k'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t591" href="#t591">591</a></span><span class="t"><span class="str">    get_act_name('pre', 2)=='blocks.2.mlp.hook_pre'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t592" href="#t592">592</a></span><span class="t"><span class="str">    get_act_name('embed')=='hook_embed'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t593" href="#t593">593</a></span><span class="t"><span class="str">    get_act_name('normalized', 27, 'ln2')=='blocks.27.ln2.hook_normalized'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t594" href="#t594">594</a></span><span class="t"><span class="str">    get_act_name('k6')=='blocks.6.attn.hook_k'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t595" href="#t595">595</a></span><span class="t"><span class="str">    get_act_name('scale4ln1')=='blocks.4.ln1.hook_scale'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t596" href="#t596">596</a></span><span class="t"><span class="str">    get_act_name('pre5')=='blocks.5.mlp.hook_pre'</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t597" href="#t597">597</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t598" href="#t598">598</a></span><span class="t">    <span class="key">if</span> <span class="op">(</span><span class="str">"."</span> <span class="key">in</span> <span class="nam">name</span> <span class="key">or</span> <span class="nam">name</span><span class="op">.</span><span class="nam">startswith</span><span class="op">(</span><span class="str">"hook_"</span><span class="op">)</span><span class="op">)</span> <span class="key">and</span> <span class="nam">layer</span> <span class="key">is</span> <span class="key">None</span> <span class="key">and</span> <span class="nam">layer_type</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">598&#x202F;&#x219B;&#x202F;600</span><span class="annotate long">line 598 didn't jump to line 600, because the condition on line 598 was never true</span></span></p>
    <p class="pln"><span class="n"><a id="t599" href="#t599">599</a></span><span class="t">        <span class="com"># If this was called on a full name, just return it</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t600" href="#t600">600</a></span><span class="t">        <span class="key">return</span> <span class="nam">name</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t601" href="#t601">601</a></span><span class="t">    <span class="nam">match</span> <span class="op">=</span> <span class="nam">re</span><span class="op">.</span><span class="nam">match</span><span class="op">(</span><span class="str">r"([a-z]+)(\d+)([a-z]?.*)"</span><span class="op">,</span> <span class="nam">name</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t602" href="#t602">602</a></span><span class="t">    <span class="key">if</span> <span class="nam">match</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t603" href="#t603">603</a></span><span class="t">        <span class="nam">name</span><span class="op">,</span> <span class="nam">layer</span><span class="op">,</span> <span class="nam">layer_type</span> <span class="op">=</span> <span class="nam">match</span><span class="op">.</span><span class="nam">groups</span><span class="op">(</span><span class="num">0</span><span class="op">)</span>  <span class="com"># type: ignore</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t604" href="#t604">604</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t605" href="#t605">605</a></span><span class="t">    <span class="nam">layer_type_alias</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t606" href="#t606">606</a></span><span class="t">        <span class="str">"a"</span><span class="op">:</span> <span class="str">"attn"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t607" href="#t607">607</a></span><span class="t">        <span class="str">"m"</span><span class="op">:</span> <span class="str">"mlp"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t608" href="#t608">608</a></span><span class="t">        <span class="str">"b"</span><span class="op">:</span> <span class="str">""</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t609" href="#t609">609</a></span><span class="t">        <span class="str">"block"</span><span class="op">:</span> <span class="str">""</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t610" href="#t610">610</a></span><span class="t">        <span class="str">"blocks"</span><span class="op">:</span> <span class="str">""</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t611" href="#t611">611</a></span><span class="t">        <span class="str">"attention"</span><span class="op">:</span> <span class="str">"attn"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t612" href="#t612">612</a></span><span class="t">    <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t613" href="#t613">613</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t614" href="#t614">614</a></span><span class="t">    <span class="nam">act_name_alias</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t615" href="#t615">615</a></span><span class="t">        <span class="str">"attn"</span><span class="op">:</span> <span class="str">"pattern"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t616" href="#t616">616</a></span><span class="t">        <span class="str">"attn_logits"</span><span class="op">:</span> <span class="str">"attn_scores"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t617" href="#t617">617</a></span><span class="t">        <span class="str">"key"</span><span class="op">:</span> <span class="str">"k"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t618" href="#t618">618</a></span><span class="t">        <span class="str">"query"</span><span class="op">:</span> <span class="str">"q"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t619" href="#t619">619</a></span><span class="t">        <span class="str">"value"</span><span class="op">:</span> <span class="str">"v"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t620" href="#t620">620</a></span><span class="t">        <span class="str">"mlp_pre"</span><span class="op">:</span> <span class="str">"pre"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t621" href="#t621">621</a></span><span class="t">        <span class="str">"mlp_mid"</span><span class="op">:</span> <span class="str">"mid"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t622" href="#t622">622</a></span><span class="t">        <span class="str">"mlp_post"</span><span class="op">:</span> <span class="str">"post"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t623" href="#t623">623</a></span><span class="t">    <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t624" href="#t624">624</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t625" href="#t625">625</a></span><span class="t">    <span class="nam">layer_norm_names</span> <span class="op">=</span> <span class="op">[</span><span class="str">"scale"</span><span class="op">,</span> <span class="str">"normalized"</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t626" href="#t626">626</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t627" href="#t627">627</a></span><span class="t">    <span class="key">if</span> <span class="nam">name</span> <span class="key">in</span> <span class="nam">act_name_alias</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t628" href="#t628">628</a></span><span class="t">        <span class="nam">name</span> <span class="op">=</span> <span class="nam">act_name_alias</span><span class="op">[</span><span class="nam">name</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t629" href="#t629">629</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t630" href="#t630">630</a></span><span class="t">    <span class="nam">full_act_name</span> <span class="op">=</span> <span class="str">""</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t631" href="#t631">631</a></span><span class="t">    <span class="key">if</span> <span class="nam">layer</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t632" href="#t632">632</a></span><span class="t">        <span class="nam">full_act_name</span> <span class="op">+=</span> <span class="str">f"blocks.{layer}."</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t633" href="#t633">633</a></span><span class="t">    <span class="key">if</span> <span class="nam">name</span> <span class="key">in</span> <span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t634" href="#t634">634</a></span><span class="t">        <span class="str">"k"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t635" href="#t635">635</a></span><span class="t">        <span class="str">"v"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t636" href="#t636">636</a></span><span class="t">        <span class="str">"q"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t637" href="#t637">637</a></span><span class="t">        <span class="str">"z"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t638" href="#t638">638</a></span><span class="t">        <span class="str">"rot_k"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t639" href="#t639">639</a></span><span class="t">        <span class="str">"rot_q"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t640" href="#t640">640</a></span><span class="t">        <span class="str">"result"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t641" href="#t641">641</a></span><span class="t">        <span class="str">"pattern"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t642" href="#t642">642</a></span><span class="t">        <span class="str">"attn_scores"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t643" href="#t643">643</a></span><span class="t">    <span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t644" href="#t644">644</a></span><span class="t">        <span class="nam">layer_type</span> <span class="op">=</span> <span class="str">"attn"</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t645" href="#t645">645</a></span><span class="t">    <span class="key">elif</span> <span class="nam">name</span> <span class="key">in</span> <span class="op">[</span><span class="str">"pre"</span><span class="op">,</span> <span class="str">"post"</span><span class="op">,</span> <span class="str">"mid"</span><span class="op">,</span> <span class="str">"pre_linear"</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t646" href="#t646">646</a></span><span class="t">        <span class="nam">layer_type</span> <span class="op">=</span> <span class="str">"mlp"</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t647" href="#t647">647</a></span><span class="t">    <span class="key">elif</span> <span class="nam">layer_type</span> <span class="key">in</span> <span class="nam">layer_type_alias</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">647&#x202F;&#x219B;&#x202F;648</span><span class="annotate long">line 647 didn't jump to line 648, because the condition on line 647 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t648" href="#t648">648</a></span><span class="t">        <span class="nam">layer_type</span> <span class="op">=</span> <span class="nam">layer_type_alias</span><span class="op">[</span><span class="nam">layer_type</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t649" href="#t649">649</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t650" href="#t650">650</a></span><span class="t">    <span class="key">if</span> <span class="nam">layer_type</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t651" href="#t651">651</a></span><span class="t">        <span class="nam">full_act_name</span> <span class="op">+=</span> <span class="str">f"{layer_type}."</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t652" href="#t652">652</a></span><span class="t">    <span class="nam">full_act_name</span> <span class="op">+=</span> <span class="str">f"hook_{name}"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t653" href="#t653">653</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t654" href="#t654">654</a></span><span class="t">    <span class="key">if</span> <span class="nam">name</span> <span class="key">in</span> <span class="nam">layer_norm_names</span> <span class="key">and</span> <span class="nam">layer</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">654&#x202F;&#x219B;&#x202F;655</span><span class="annotate long">line 654 didn't jump to line 655, because the condition on line 654 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t655" href="#t655">655</a></span><span class="t">        <span class="nam">full_act_name</span> <span class="op">=</span> <span class="str">f"ln_final.{full_act_name}"</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t656" href="#t656">656</a></span><span class="t">    <span class="key">return</span> <span class="nam">full_act_name</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t657" href="#t657">657</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t658" href="#t658">658</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t659" href="#t659">659</a></span><span class="t"><span class="key">def</span> <span class="nam">remove_batch_dim</span><span class="op">(</span><span class="nam">tensor</span><span class="op">:</span> <span class="nam">Float</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">"1 ..."</span><span class="op">]</span><span class="op">)</span> <span class="op">-></span> <span class="nam">Float</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">"..."</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t660" href="#t660">660</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t661" href="#t661">661</a></span><span class="t"><span class="str">    Removes the first dimension of a tensor if it is size 1, otherwise returns the tensor unchanged</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t662" href="#t662">662</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t663" href="#t663">663</a></span><span class="t">    <span class="key">if</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">==</span> <span class="num">1</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">663&#x202F;&#x219B;&#x202F;666</span><span class="annotate long">line 663 didn't jump to line 666, because the condition on line 663 was never false</span></span></p>
    <p class="run"><span class="n"><a id="t664" href="#t664">664</a></span><span class="t">        <span class="key">return</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">squeeze</span><span class="op">(</span><span class="num">0</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t665" href="#t665">665</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t666" href="#t666">666</a></span><span class="t">        <span class="key">return</span> <span class="nam">tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t667" href="#t667">667</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t668" href="#t668">668</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t669" href="#t669">669</a></span><span class="t"><span class="key">def</span> <span class="nam">test_prompt</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t670" href="#t670">670</a></span><span class="t">    <span class="nam">prompt</span><span class="op">:</span> <span class="nam">str</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t671" href="#t671">671</a></span><span class="t">    <span class="nam">answer</span><span class="op">:</span> <span class="nam">str</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t672" href="#t672">672</a></span><span class="t">    <span class="nam">model</span><span class="op">,</span>  <span class="com"># Can't give type hint due to circular imports</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t673" href="#t673">673</a></span><span class="t">    <span class="nam">prepend_space_to_answer</span><span class="op">:</span> <span class="nam">bool</span> <span class="op">=</span> <span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t674" href="#t674">674</a></span><span class="t">    <span class="nam">print_details</span><span class="op">:</span> <span class="nam">bool</span> <span class="op">=</span> <span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t675" href="#t675">675</a></span><span class="t">    <span class="nam">prepend_bos</span><span class="op">:</span> <span class="nam">Optional</span><span class="op">[</span><span class="nam">bool</span><span class="op">]</span> <span class="op">=</span> <span class="nam">USE_DEFAULT_VALUE</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t676" href="#t676">676</a></span><span class="t">    <span class="nam">top_k</span><span class="op">:</span> <span class="nam">int</span> <span class="op">=</span> <span class="num">10</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t677" href="#t677">677</a></span><span class="t"><span class="op">)</span> <span class="op">-></span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t678" href="#t678">678</a></span><span class="t">    <span class="str">"""Test if the Model Can Give the Correct Answer to a Prompt.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t679" href="#t679">679</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t680" href="#t680">680</a></span><span class="t"><span class="str">    Intended for exploratory analysis. Prints out the performance on the answer (rank, logit, prob),</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t681" href="#t681">681</a></span><span class="t"><span class="str">    as well as the top k tokens. Works for multi-token prompts and multi-token answers.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t682" href="#t682">682</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t683" href="#t683">683</a></span><span class="t"><span class="str">    Warning:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t684" href="#t684">684</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t685" href="#t685">685</a></span><span class="t"><span class="str">    This will print the results (it does not return them).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t686" href="#t686">686</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t687" href="#t687">687</a></span><span class="t"><span class="str">    Examples:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t688" href="#t688">688</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t689" href="#t689">689</a></span><span class="t"><span class="str">    >>> from transformer_lens import HookedTransformer, utils</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t690" href="#t690">690</a></span><span class="t"><span class="str">    >>> model = HookedTransformer.from_pretrained("tiny-stories-1M")</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t691" href="#t691">691</a></span><span class="t"><span class="str">    Loaded pretrained model tiny-stories-1M into HookedTransformer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t692" href="#t692">692</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t693" href="#t693">693</a></span><span class="t"><span class="str">    >>> prompt = "Why did the elephant cross the"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t694" href="#t694">694</a></span><span class="t"><span class="str">    >>> answer = "road"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t695" href="#t695">695</a></span><span class="t"><span class="str">    >>> utils.test_prompt(prompt, answer, model)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t696" href="#t696">696</a></span><span class="t"><span class="str">    Tokenized prompt: ['&lt;|endoftext|>', 'Why', ' did', ' the', ' elephant', ' cross', ' the']</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t697" href="#t697">697</a></span><span class="t"><span class="str">    Tokenized answer: [' road']</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t698" href="#t698">698</a></span><span class="t"><span class="str">    Performance on answer token:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t699" href="#t699">699</a></span><span class="t"><span class="str">    Rank: 2        Logit: 14.24 Prob:  3.51% Token: | road|</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t700" href="#t700">700</a></span><span class="t"><span class="str">    Top 0th token. Logit: 14.51 Prob:  4.59% Token: | ground|</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t701" href="#t701">701</a></span><span class="t"><span class="str">    Top 1th token. Logit: 14.41 Prob:  4.18% Token: | tree|</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t702" href="#t702">702</a></span><span class="t"><span class="str">    Top 2th token. Logit: 14.24 Prob:  3.51% Token: | road|</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t703" href="#t703">703</a></span><span class="t"><span class="str">    Top 3th token. Logit: 14.22 Prob:  3.45% Token: | car|</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t704" href="#t704">704</a></span><span class="t"><span class="str">    Top 4th token. Logit: 13.92 Prob:  2.55% Token: | river|</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t705" href="#t705">705</a></span><span class="t"><span class="str">    Top 5th token. Logit: 13.79 Prob:  2.25% Token: | street|</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t706" href="#t706">706</a></span><span class="t"><span class="str">    Top 6th token. Logit: 13.77 Prob:  2.21% Token: | k|</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t707" href="#t707">707</a></span><span class="t"><span class="str">    Top 7th token. Logit: 13.75 Prob:  2.16% Token: | hill|</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t708" href="#t708">708</a></span><span class="t"><span class="str">    Top 8th token. Logit: 13.64 Prob:  1.92% Token: | swing|</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t709" href="#t709">709</a></span><span class="t"><span class="str">    Top 9th token. Logit: 13.46 Prob:  1.61% Token: | park|</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t710" href="#t710">710</a></span><span class="t"><span class="str">    Ranks of the answer tokens: [(' road', 2)]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t711" href="#t711">711</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t712" href="#t712">712</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t713" href="#t713">713</a></span><span class="t"><span class="str">        prompt:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t714" href="#t714">714</a></span><span class="t"><span class="str">            The prompt string, e.g. "Why did the elephant cross the".</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t715" href="#t715">715</a></span><span class="t"><span class="str">        answer:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t716" href="#t716">716</a></span><span class="t"><span class="str">            The answer, e.g. "road". Note that if you set prepend_space_to_answer to False, you need</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t717" href="#t717">717</a></span><span class="t"><span class="str">            to think about if you have a space before the answer here (as e.g. in this example the</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t718" href="#t718">718</a></span><span class="t"><span class="str">            answer may really be " road" if the prompt ends without a trailing space).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t719" href="#t719">719</a></span><span class="t"><span class="str">        model:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t720" href="#t720">720</a></span><span class="t"><span class="str">            The model.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t721" href="#t721">721</a></span><span class="t"><span class="str">        prepend_space_to_answer:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t722" href="#t722">722</a></span><span class="t"><span class="str">            Whether or not to prepend a space to the answer. Note this will only ever prepend a</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t723" href="#t723">723</a></span><span class="t"><span class="str">            space if the answer doesn't already start with one.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t724" href="#t724">724</a></span><span class="t"><span class="str">        print_details:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t725" href="#t725">725</a></span><span class="t"><span class="str">            Print the prompt (as a string but broken up by token), answer and top k tokens (all</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t726" href="#t726">726</a></span><span class="t"><span class="str">            with logit, rank and probability).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t727" href="#t727">727</a></span><span class="t"><span class="str">        prepend_bos:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t728" href="#t728">728</a></span><span class="t"><span class="str">            Overrides self.cfg.default_prepend_bos if set. Whether to prepend</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t729" href="#t729">729</a></span><span class="t"><span class="str">            the BOS token to the input (applicable when input is a string). Models generally learn</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t730" href="#t730">730</a></span><span class="t"><span class="str">            to use the BOS token as a resting place for attention heads (i.e. a way for them to be</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t731" href="#t731">731</a></span><span class="t"><span class="str">            "turned off"). This therefore often improves performance slightly.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t732" href="#t732">732</a></span><span class="t"><span class="str">        top_k:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t733" href="#t733">733</a></span><span class="t"><span class="str">            Top k tokens to print details of (when print_details is set to True).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t734" href="#t734">734</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t735" href="#t735">735</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t736" href="#t736">736</a></span><span class="t"><span class="str">        None (just prints the results directly).</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t737" href="#t737">737</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t738" href="#t738">738</a></span><span class="t">    <span class="key">if</span> <span class="nam">prepend_space_to_answer</span> <span class="key">and</span> <span class="key">not</span> <span class="nam">answer</span><span class="op">.</span><span class="nam">startswith</span><span class="op">(</span><span class="str">" "</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t739" href="#t739">739</a></span><span class="t">        <span class="nam">answer</span> <span class="op">=</span> <span class="str">" "</span> <span class="op">+</span> <span class="nam">answer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t740" href="#t740">740</a></span><span class="t">    <span class="com"># GPT-2 often treats the first token weirdly, so lets give it a resting position</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t741" href="#t741">741</a></span><span class="t">    <span class="nam">prompt_tokens</span> <span class="op">=</span> <span class="nam">model</span><span class="op">.</span><span class="nam">to_tokens</span><span class="op">(</span><span class="nam">prompt</span><span class="op">,</span> <span class="nam">prepend_bos</span><span class="op">=</span><span class="nam">prepend_bos</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t742" href="#t742">742</a></span><span class="t">    <span class="nam">answer_tokens</span> <span class="op">=</span> <span class="nam">model</span><span class="op">.</span><span class="nam">to_tokens</span><span class="op">(</span><span class="nam">answer</span><span class="op">,</span> <span class="nam">prepend_bos</span><span class="op">=</span><span class="key">False</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t743" href="#t743">743</a></span><span class="t">    <span class="nam">tokens</span> <span class="op">=</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">cat</span><span class="op">(</span><span class="op">(</span><span class="nam">prompt_tokens</span><span class="op">,</span> <span class="nam">answer_tokens</span><span class="op">)</span><span class="op">,</span> <span class="nam">dim</span><span class="op">=</span><span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t744" href="#t744">744</a></span><span class="t">    <span class="nam">prompt_str_tokens</span> <span class="op">=</span> <span class="nam">model</span><span class="op">.</span><span class="nam">to_str_tokens</span><span class="op">(</span><span class="nam">prompt</span><span class="op">,</span> <span class="nam">prepend_bos</span><span class="op">=</span><span class="nam">prepend_bos</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t745" href="#t745">745</a></span><span class="t">    <span class="nam">answer_str_tokens</span> <span class="op">=</span> <span class="nam">model</span><span class="op">.</span><span class="nam">to_str_tokens</span><span class="op">(</span><span class="nam">answer</span><span class="op">,</span> <span class="nam">prepend_bos</span><span class="op">=</span><span class="key">False</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t746" href="#t746">746</a></span><span class="t">    <span class="nam">prompt_length</span> <span class="op">=</span> <span class="nam">len</span><span class="op">(</span><span class="nam">prompt_str_tokens</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t747" href="#t747">747</a></span><span class="t">    <span class="nam">answer_length</span> <span class="op">=</span> <span class="nam">len</span><span class="op">(</span><span class="nam">answer_str_tokens</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t748" href="#t748">748</a></span><span class="t">    <span class="key">if</span> <span class="nam">print_details</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">748&#x202F;&#x219B;&#x202F;751</span><span class="annotate long">line 748 didn't jump to line 751, because the condition on line 748 was never false</span></span></p>
    <p class="run"><span class="n"><a id="t749" href="#t749">749</a></span><span class="t">        <span class="nam">print</span><span class="op">(</span><span class="str">"Tokenized prompt:"</span><span class="op">,</span> <span class="nam">prompt_str_tokens</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t750" href="#t750">750</a></span><span class="t">        <span class="nam">print</span><span class="op">(</span><span class="str">"Tokenized answer:"</span><span class="op">,</span> <span class="nam">answer_str_tokens</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t751" href="#t751">751</a></span><span class="t">    <span class="nam">logits</span> <span class="op">=</span> <span class="nam">remove_batch_dim</span><span class="op">(</span><span class="nam">model</span><span class="op">(</span><span class="nam">tokens</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t752" href="#t752">752</a></span><span class="t">    <span class="nam">probs</span> <span class="op">=</span> <span class="nam">logits</span><span class="op">.</span><span class="nam">softmax</span><span class="op">(</span><span class="nam">dim</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t753" href="#t753">753</a></span><span class="t">    <span class="nam">answer_ranks</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t754" href="#t754">754</a></span><span class="t">    <span class="key">for</span> <span class="nam">index</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">prompt_length</span><span class="op">,</span> <span class="nam">prompt_length</span> <span class="op">+</span> <span class="nam">answer_length</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t755" href="#t755">755</a></span><span class="t">        <span class="nam">answer_token</span> <span class="op">=</span> <span class="nam">tokens</span><span class="op">[</span><span class="num">0</span><span class="op">,</span> <span class="nam">index</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t756" href="#t756">756</a></span><span class="t">        <span class="nam">answer_str_token</span> <span class="op">=</span> <span class="nam">answer_str_tokens</span><span class="op">[</span><span class="nam">index</span> <span class="op">-</span> <span class="nam">prompt_length</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t757" href="#t757">757</a></span><span class="t">        <span class="com"># Offset by 1 because models predict the NEXT token</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t758" href="#t758">758</a></span><span class="t">        <span class="nam">token_probs</span> <span class="op">=</span> <span class="nam">probs</span><span class="op">[</span><span class="nam">index</span> <span class="op">-</span> <span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t759" href="#t759">759</a></span><span class="t">        <span class="nam">sorted_token_probs</span><span class="op">,</span> <span class="nam">sorted_token_values</span> <span class="op">=</span> <span class="nam">token_probs</span><span class="op">.</span><span class="nam">sort</span><span class="op">(</span><span class="nam">descending</span><span class="op">=</span><span class="key">True</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t760" href="#t760">760</a></span><span class="t">        <span class="com"># Janky way to get the index of the token in the sorted list - I couldn't find a better way?</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t761" href="#t761">761</a></span><span class="t">        <span class="nam">correct_rank</span> <span class="op">=</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">arange</span><span class="op">(</span><span class="nam">len</span><span class="op">(</span><span class="nam">sorted_token_values</span><span class="op">)</span><span class="op">)</span><span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t762" href="#t762">762</a></span><span class="t">            <span class="op">(</span><span class="nam">sorted_token_values</span> <span class="op">==</span> <span class="nam">answer_token</span><span class="op">)</span><span class="op">.</span><span class="nam">cpu</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t763" href="#t763">763</a></span><span class="t">        <span class="op">]</span><span class="op">.</span><span class="nam">item</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t764" href="#t764">764</a></span><span class="t">        <span class="nam">answer_ranks</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="op">(</span><span class="nam">answer_str_token</span><span class="op">,</span> <span class="nam">correct_rank</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t765" href="#t765">765</a></span><span class="t">        <span class="key">if</span> <span class="nam">print_details</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">765&#x202F;&#x219B;&#x202F;754</span><span class="annotate long">line 765 didn't jump to line 754, because the condition on line 765 was never false</span></span></p>
    <p class="pln"><span class="n"><a id="t766" href="#t766">766</a></span><span class="t">            <span class="com"># String formatting syntax - the first number gives the number of characters to pad to, the second number gives the number of decimal places.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t767" href="#t767">767</a></span><span class="t">            <span class="com"># rprint gives rich text printing</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t768" href="#t768">768</a></span><span class="t">            <span class="nam">rprint</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t769" href="#t769">769</a></span><span class="t">                <span class="str">f"Performance on answer token:\n[b]Rank: {correct_rank: &lt;8} Logit: {logits[index-1, answer_token].item():5.2f} Prob: {token_probs[answer_token].item():6.2%} Token: |{answer_str_token}|[/b]"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t770" href="#t770">770</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t771" href="#t771">771</a></span><span class="t">            <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">top_k</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t772" href="#t772">772</a></span><span class="t">                <span class="nam">print</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t773" href="#t773">773</a></span><span class="t">                    <span class="str">f"Top {i}th token. Logit: {logits[index-1, sorted_token_values[i]].item():5.2f} Prob: {sorted_token_probs[i].item():6.2%} Token: |{model.to_string(sorted_token_values[i])}|"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t774" href="#t774">774</a></span><span class="t">                <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t775" href="#t775">775</a></span><span class="t">    <span class="nam">rprint</span><span class="op">(</span><span class="str">f"[b]Ranks of the answer tokens:[/b] {answer_ranks}"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t776" href="#t776">776</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t777" href="#t777">777</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t778" href="#t778">778</a></span><span class="t"><span class="key">def</span> <span class="nam">transpose</span><span class="op">(</span><span class="nam">tensor</span><span class="op">:</span> <span class="nam">Float</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">"... a b"</span><span class="op">]</span><span class="op">)</span> <span class="op">-></span> <span class="nam">Float</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">"... b a"</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t779" href="#t779">779</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t780" href="#t780">780</a></span><span class="t"><span class="str">    Utility to swap the last two dimensions of a tensor, regardless of the number of leading dimensions</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t781" href="#t781">781</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t782" href="#t782">782</a></span><span class="t">    <span class="key">return</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">transpose</span><span class="op">(</span><span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="op">-</span><span class="num">2</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t783" href="#t783">783</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t784" href="#t784">784</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t785" href="#t785">785</a></span><span class="t"><span class="key">def</span> <span class="nam">composition_scores</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t786" href="#t786">786</a></span><span class="t">    <span class="nam">left</span><span class="op">:</span> <span class="str">"FactoredMatrix"</span><span class="op">,</span> <span class="nam">right</span><span class="op">:</span> <span class="str">"FactoredMatrix"</span><span class="op">,</span> <span class="nam">broadcast_dims</span><span class="op">=</span><span class="key">True</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t787" href="#t787">787</a></span><span class="t"><span class="op">)</span> <span class="op">-></span> <span class="nam">Union</span><span class="op">[</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t788" href="#t788">788</a></span><span class="t">    <span class="nam">Float</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">"*leading_dims"</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t789" href="#t789">789</a></span><span class="t">    <span class="nam">Float</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">"*leading_dims_left_and_right"</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t790" href="#t790">790</a></span><span class="t"><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t791" href="#t791">791</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t792" href="#t792">792</a></span><span class="t"><span class="str">    See `HookedTransformer.all_composition_scores` for documentation.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t793" href="#t793">793</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t794" href="#t794">794</a></span><span class="t">    <span class="key">if</span> <span class="nam">broadcast_dims</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t795" href="#t795">795</a></span><span class="t">        <span class="nam">r_leading</span> <span class="op">=</span> <span class="nam">right</span><span class="op">.</span><span class="nam">ndim</span> <span class="op">-</span> <span class="num">2</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t796" href="#t796">796</a></span><span class="t">        <span class="nam">l_leading</span> <span class="op">=</span> <span class="nam">left</span><span class="op">.</span><span class="nam">ndim</span> <span class="op">-</span> <span class="num">2</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t797" href="#t797">797</a></span><span class="t">        <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">l_leading</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t798" href="#t798">798</a></span><span class="t">            <span class="nam">right</span> <span class="op">=</span> <span class="nam">right</span><span class="op">.</span><span class="nam">unsqueeze</span><span class="op">(</span><span class="nam">i</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t799" href="#t799">799</a></span><span class="t">        <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">r_leading</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t800" href="#t800">800</a></span><span class="t">            <span class="nam">left</span> <span class="op">=</span> <span class="nam">left</span><span class="op">.</span><span class="nam">unsqueeze</span><span class="op">(</span><span class="nam">i</span> <span class="op">+</span> <span class="nam">l_leading</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t801" href="#t801">801</a></span><span class="t">    <span class="key">assert</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t802" href="#t802">802</a></span><span class="t">        <span class="nam">left</span><span class="op">.</span><span class="nam">rdim</span> <span class="op">==</span> <span class="nam">right</span><span class="op">.</span><span class="nam">ldim</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t803" href="#t803">803</a></span><span class="t">    <span class="op">)</span><span class="op">,</span> <span class="str">f"Composition scores require left.rdim==right.ldim, shapes were left: {left.shape}, right:{right.shape}"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t804" href="#t804">804</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t805" href="#t805">805</a></span><span class="t">    <span class="nam">new_right</span> <span class="op">=</span> <span class="nam">right</span><span class="op">.</span><span class="nam">collapse_r</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t806" href="#t806">806</a></span><span class="t">    <span class="nam">new_left</span> <span class="op">=</span> <span class="nam">left</span><span class="op">.</span><span class="nam">collapse_l</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t807" href="#t807">807</a></span><span class="t">    <span class="nam">r_norms</span> <span class="op">=</span> <span class="nam">new_right</span><span class="op">.</span><span class="nam">norm</span><span class="op">(</span><span class="nam">dim</span><span class="op">=</span><span class="op">[</span><span class="op">-</span><span class="num">2</span><span class="op">,</span> <span class="op">-</span><span class="num">1</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t808" href="#t808">808</a></span><span class="t">    <span class="nam">l_norms</span> <span class="op">=</span> <span class="nam">new_left</span><span class="op">.</span><span class="nam">norm</span><span class="op">(</span><span class="nam">dim</span><span class="op">=</span><span class="op">[</span><span class="op">-</span><span class="num">2</span><span class="op">,</span> <span class="op">-</span><span class="num">1</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t809" href="#t809">809</a></span><span class="t">    <span class="nam">comp_norms</span> <span class="op">=</span> <span class="op">(</span><span class="nam">new_left</span> <span class="op">@</span> <span class="nam">new_right</span><span class="op">)</span><span class="op">.</span><span class="nam">norm</span><span class="op">(</span><span class="nam">dim</span><span class="op">=</span><span class="op">[</span><span class="op">-</span><span class="num">2</span><span class="op">,</span> <span class="op">-</span><span class="num">1</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t810" href="#t810">810</a></span><span class="t">    <span class="key">return</span> <span class="nam">comp_norms</span> <span class="op">/</span> <span class="nam">r_norms</span> <span class="op">/</span> <span class="nam">l_norms</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t811" href="#t811">811</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t812" href="#t812">812</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t813" href="#t813">813</a></span><span class="t"><span class="key">def</span> <span class="nam">get_dataset</span><span class="op">(</span><span class="nam">dataset_name</span><span class="op">:</span> <span class="nam">str</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span> <span class="op">-></span> <span class="nam">Dataset</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t814" href="#t814">814</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t815" href="#t815">815</a></span><span class="t"><span class="str">    Returns a small HuggingFace dataset, for easy testing and exploration. Accesses several convenience datasets with 10,000 elements (dealing with the enormous 100GB - 2TB datasets is a lot of effort!). Note that it returns a dataset (ie a dictionary containing all the data), *not* a DataLoader (iterator over the data + some fancy features). But you can easily convert it to a DataLoader.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t816" href="#t816">816</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t817" href="#t817">817</a></span><span class="t"><span class="str">    Each dataset has a 'text' field, which contains the relevant info, some also have several meta data fields</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t818" href="#t818">818</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t819" href="#t819">819</a></span><span class="t"><span class="str">    Kwargs will be passed to the huggingface dataset loading function, e.g. "data_dir"</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t820" href="#t820">820</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t821" href="#t821">821</a></span><span class="t"><span class="str">    Possible inputs:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t822" href="#t822">822</a></span><span class="t"><span class="str">    * openwebtext (approx the GPT-2 training data https://huggingface.co/datasets/openwebtext)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t823" href="#t823">823</a></span><span class="t"><span class="str">    * pile (The Pile, a big mess of tons of diverse data https://pile.eleuther.ai/)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t824" href="#t824">824</a></span><span class="t"><span class="str">    * c4 (Colossal, Cleaned, Common Crawl - basically openwebtext but bigger https://huggingface.co/datasets/c4)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t825" href="#t825">825</a></span><span class="t"><span class="str">    * code (Codeparrot Clean, a Python code dataset https://huggingface.co/datasets/codeparrot/codeparrot-clean )</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t826" href="#t826">826</a></span><span class="t"><span class="str">    * c4_code (c4 + code - the 20K data points from c4-10k and code-10k. This is the mix of datasets used to train my interpretability-friendly models, though note that they are *not* in the correct ratio! There's 10K texts for each, but about 22M tokens of code and 5M tokens of C4)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t827" href="#t827">827</a></span><span class="t"><span class="str">    * wiki (Wikipedia, generated from the 20220301.en split of https://huggingface.co/datasets/wikipedia )</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t828" href="#t828">828</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t829" href="#t829">829</a></span><span class="t">    <span class="nam">dataset_aliases</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t830" href="#t830">830</a></span><span class="t">        <span class="str">"openwebtext"</span><span class="op">:</span> <span class="str">"stas/openwebtext-10k"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t831" href="#t831">831</a></span><span class="t">        <span class="str">"owt"</span><span class="op">:</span> <span class="str">"stas/openwebtext-10k"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t832" href="#t832">832</a></span><span class="t">        <span class="str">"pile"</span><span class="op">:</span> <span class="str">"NeelNanda/pile-10k"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t833" href="#t833">833</a></span><span class="t">        <span class="str">"c4"</span><span class="op">:</span> <span class="str">"NeelNanda/c4-10k"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t834" href="#t834">834</a></span><span class="t">        <span class="str">"code"</span><span class="op">:</span> <span class="str">"NeelNanda/code-10k"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t835" href="#t835">835</a></span><span class="t">        <span class="str">"python"</span><span class="op">:</span> <span class="str">"NeelNanda/code-10k"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t836" href="#t836">836</a></span><span class="t">        <span class="str">"c4_code"</span><span class="op">:</span> <span class="str">"NeelNanda/c4-code-20k"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t837" href="#t837">837</a></span><span class="t">        <span class="str">"c4-code"</span><span class="op">:</span> <span class="str">"NeelNanda/c4-code-20k"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t838" href="#t838">838</a></span><span class="t">        <span class="str">"wiki"</span><span class="op">:</span> <span class="str">"NeelNanda/wiki-10k"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t839" href="#t839">839</a></span><span class="t">    <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t840" href="#t840">840</a></span><span class="t">    <span class="key">if</span> <span class="nam">dataset_name</span> <span class="key">in</span> <span class="nam">dataset_aliases</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t841" href="#t841">841</a></span><span class="t">        <span class="nam">dataset</span> <span class="op">=</span> <span class="nam">load_dataset</span><span class="op">(</span><span class="nam">dataset_aliases</span><span class="op">[</span><span class="nam">dataset_name</span><span class="op">]</span><span class="op">,</span> <span class="nam">split</span><span class="op">=</span><span class="str">"train"</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t842" href="#t842">842</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t843" href="#t843">843</a></span><span class="t">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">f"Dataset {dataset_name} not supported"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t844" href="#t844">844</a></span><span class="t">    <span class="key">return</span> <span class="nam">dataset</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t845" href="#t845">845</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t846" href="#t846">846</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t847" href="#t847">847</a></span><span class="t"><span class="key">def</span> <span class="nam">is_square</span><span class="op">(</span><span class="nam">x</span><span class="op">:</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">)</span> <span class="op">-></span> <span class="nam">bool</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t848" href="#t848">848</a></span><span class="t">    <span class="str">"""Checks if `x` is a square matrix."""</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t849" href="#t849">849</a></span><span class="t">    <span class="key">return</span> <span class="nam">x</span><span class="op">.</span><span class="nam">ndim</span> <span class="op">==</span> <span class="num">2</span> <span class="key">and</span> <span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">==</span> <span class="nam">x</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t850" href="#t850">850</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t851" href="#t851">851</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t852" href="#t852">852</a></span><span class="t"><span class="key">def</span> <span class="nam">is_lower_triangular</span><span class="op">(</span><span class="nam">x</span><span class="op">:</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">)</span> <span class="op">-></span> <span class="nam">bool</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t853" href="#t853">853</a></span><span class="t">    <span class="str">"""Checks if `x` is a lower triangular matrix."""</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t854" href="#t854">854</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">is_square</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t855" href="#t855">855</a></span><span class="t">        <span class="key">return</span> <span class="key">False</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t856" href="#t856">856</a></span><span class="t">    <span class="key">return</span> <span class="nam">x</span><span class="op">.</span><span class="nam">equal</span><span class="op">(</span><span class="nam">x</span><span class="op">.</span><span class="nam">tril</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t857" href="#t857">857</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t858" href="#t858">858</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t859" href="#t859">859</a></span><span class="t"><span class="key">def</span> <span class="nam">check_structure</span><span class="op">(</span><span class="nam">t1</span><span class="op">:</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="nam">t2</span><span class="op">:</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="op">*</span><span class="op">,</span> <span class="nam">verbose</span><span class="op">:</span> <span class="nam">bool</span> <span class="op">=</span> <span class="key">False</span><span class="op">)</span> <span class="op">-></span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t860" href="#t860">860</a></span><span class="t">    <span class="str">"""Validate that the two square tensors have the same structure, i.e.,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t861" href="#t861">861</a></span><span class="t"><span class="str">    that the directionality of comparisons points in the same directions both</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t862" href="#t862">862</a></span><span class="t"><span class="str">    row-wise and column-wise.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t863" href="#t863">863</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t864" href="#t864">864</a></span><span class="t"><span class="str">    This function is not used anywhere in the code right now, just for debugging tests.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t865" href="#t865">865</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t866" href="#t866">866</a></span><span class="t">    <span class="key">assert</span> <span class="nam">t1</span><span class="op">.</span><span class="nam">ndim</span> <span class="op">==</span> <span class="num">2</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t867" href="#t867">867</a></span><span class="t">    <span class="key">assert</span> <span class="nam">t1</span><span class="op">.</span><span class="nam">shape</span> <span class="op">==</span> <span class="nam">t2</span><span class="op">.</span><span class="nam">shape</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t868" href="#t868">868</a></span><span class="t">    <span class="nam">n_rows</span><span class="op">,</span> <span class="nam">n_cols</span> <span class="op">=</span> <span class="nam">cast</span><span class="op">(</span><span class="nam">Tuple</span><span class="op">[</span><span class="nam">int</span><span class="op">,</span> <span class="nam">int</span><span class="op">]</span><span class="op">,</span> <span class="nam">t1</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t869" href="#t869">869</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t870" href="#t870">870</a></span><span class="t">    <span class="key">if</span> <span class="nam">verbose</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t871" href="#t871">871</a></span><span class="t">        <span class="nam">print</span><span class="op">(</span><span class="str">"Checking rows"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t872" href="#t872">872</a></span><span class="t">    <span class="nam">row_mismatch</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t873" href="#t873">873</a></span><span class="t">    <span class="key">for</span> <span class="nam">row_i</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">n_rows</span> <span class="op">-</span> <span class="num">1</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t874" href="#t874">874</a></span><span class="t">        <span class="nam">t1_result</span> <span class="op">=</span> <span class="nam">t1</span><span class="op">[</span><span class="nam">row_i</span><span class="op">]</span><span class="op">.</span><span class="nam">ge</span><span class="op">(</span><span class="nam">t1</span><span class="op">[</span><span class="nam">row_i</span> <span class="op">+</span> <span class="num">1</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t875" href="#t875">875</a></span><span class="t">        <span class="nam">t2_result</span> <span class="op">=</span> <span class="nam">t2</span><span class="op">[</span><span class="nam">row_i</span><span class="op">]</span><span class="op">.</span><span class="nam">ge</span><span class="op">(</span><span class="nam">t2</span><span class="op">[</span><span class="nam">row_i</span> <span class="op">+</span> <span class="num">1</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t876" href="#t876">876</a></span><span class="t">        <span class="key">if</span> <span class="nam">any</span><span class="op">(</span><span class="nam">t1_result</span> <span class="op">!=</span> <span class="nam">t2_result</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t877" href="#t877">877</a></span><span class="t">            <span class="nam">row_mismatch</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">row_i</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t878" href="#t878">878</a></span><span class="t">            <span class="key">if</span> <span class="nam">verbose</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t879" href="#t879">879</a></span><span class="t">                <span class="nam">print</span><span class="op">(</span><span class="str">f"\trows {row_i}:{row_i + 1}"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t880" href="#t880">880</a></span><span class="t">                <span class="nam">print</span><span class="op">(</span><span class="str">f"\tt1: {t1_result.tolist()}"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t881" href="#t881">881</a></span><span class="t">                <span class="nam">print</span><span class="op">(</span><span class="str">f"\tt2: {t2_result.tolist()}"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t882" href="#t882">882</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t883" href="#t883">883</a></span><span class="t">    <span class="key">if</span> <span class="nam">verbose</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t884" href="#t884">884</a></span><span class="t">        <span class="nam">print</span><span class="op">(</span><span class="str">"Checking columns"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t885" href="#t885">885</a></span><span class="t">    <span class="nam">col_mismatch</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t886" href="#t886">886</a></span><span class="t">    <span class="key">for</span> <span class="nam">col_i</span> <span class="key">in</span> <span class="nam">range</span><span class="op">(</span><span class="nam">n_cols</span> <span class="op">-</span> <span class="num">1</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t887" href="#t887">887</a></span><span class="t">        <span class="nam">t1_result</span> <span class="op">=</span> <span class="nam">t1</span><span class="op">[</span><span class="op">:</span><span class="op">,</span> <span class="nam">col_i</span><span class="op">]</span><span class="op">.</span><span class="nam">ge</span><span class="op">(</span><span class="nam">t1</span><span class="op">[</span><span class="op">:</span><span class="op">,</span> <span class="nam">col_i</span> <span class="op">+</span> <span class="num">1</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t888" href="#t888">888</a></span><span class="t">        <span class="nam">t2_result</span> <span class="op">=</span> <span class="nam">t2</span><span class="op">[</span><span class="op">:</span><span class="op">,</span> <span class="nam">col_i</span><span class="op">]</span><span class="op">.</span><span class="nam">ge</span><span class="op">(</span><span class="nam">t2</span><span class="op">[</span><span class="op">:</span><span class="op">,</span> <span class="nam">col_i</span> <span class="op">+</span> <span class="num">1</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t889" href="#t889">889</a></span><span class="t">        <span class="key">if</span> <span class="nam">any</span><span class="op">(</span><span class="nam">t1_result</span> <span class="op">!=</span> <span class="nam">t2_result</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t890" href="#t890">890</a></span><span class="t">            <span class="nam">col_mismatch</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">col_i</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t891" href="#t891">891</a></span><span class="t">            <span class="key">if</span> <span class="nam">verbose</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t892" href="#t892">892</a></span><span class="t">                <span class="nam">print</span><span class="op">(</span><span class="str">f"\trows {col_i}:{col_i + 1}"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t893" href="#t893">893</a></span><span class="t">                <span class="nam">print</span><span class="op">(</span><span class="str">f"\tt1: {t1_result.tolist()}"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t894" href="#t894">894</a></span><span class="t">                <span class="nam">print</span><span class="op">(</span><span class="str">f"\tt2: {t2_result.tolist()}"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t895" href="#t895">895</a></span><span class="t">    <span class="key">if</span> <span class="key">not</span> <span class="nam">row_mismatch</span> <span class="key">and</span> <span class="key">not</span> <span class="nam">col_mismatch</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t896" href="#t896">896</a></span><span class="t">        <span class="nam">print</span><span class="op">(</span><span class="str">"PASSED"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t897" href="#t897">897</a></span><span class="t">    <span class="key">elif</span> <span class="nam">row_mismatch</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t898" href="#t898">898</a></span><span class="t">        <span class="nam">print</span><span class="op">(</span><span class="str">f"row mismatch: {row_mismatch}"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t899" href="#t899">899</a></span><span class="t">    <span class="key">elif</span> <span class="nam">col_mismatch</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t900" href="#t900">900</a></span><span class="t">        <span class="nam">print</span><span class="op">(</span><span class="str">f"column mismatch: {col_mismatch}"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t901" href="#t901">901</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t902" href="#t902">902</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t903" href="#t903">903</a></span><span class="t"><span class="key">def</span> <span class="nam">get_device</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t904" href="#t904">904</a></span><span class="t">    <span class="key">if</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">cuda</span><span class="op">.</span><span class="nam">is_available</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">904&#x202F;&#x219B;&#x202F;905</span><span class="annotate long">line 904 didn't jump to line 905, because the condition on line 904 was never true</span></span></p>
    <p class="mis show_mis"><span class="n"><a id="t905" href="#t905">905</a></span><span class="t">        <span class="key">return</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">device</span><span class="op">(</span><span class="str">"cuda"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t906" href="#t906">906</a></span><span class="t">    <span class="key">if</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">backends</span><span class="op">.</span><span class="nam">mps</span><span class="op">.</span><span class="nam">is_available</span><span class="op">(</span><span class="op">)</span> <span class="key">and</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">backends</span><span class="op">.</span><span class="nam">mps</span><span class="op">.</span><span class="nam">is_built</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">906&#x202F;&#x219B;&#x202F;908</span><span class="annotate long">line 906 didn't jump to line 908, because the condition on line 906 was never true</span></span></p>
    <p class="pln"><span class="n"><a id="t907" href="#t907">907</a></span><span class="t">        <span class="com"># Parse the PyTorch version to check if it's below version 2.0</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t908" href="#t908">908</a></span><span class="t">        <span class="nam">major_version</span> <span class="op">=</span> <span class="nam">int</span><span class="op">(</span><span class="nam">torch</span><span class="op">.</span><span class="nam">__version__</span><span class="op">.</span><span class="nam">split</span><span class="op">(</span><span class="str">"."</span><span class="op">)</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t909" href="#t909">909</a></span><span class="t">        <span class="key">if</span> <span class="nam">major_version</span> <span class="op">>=</span> <span class="num">2</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t910" href="#t910">910</a></span><span class="t">            <span class="key">return</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">device</span><span class="op">(</span><span class="str">"mps"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t911" href="#t911">911</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t912" href="#t912">912</a></span><span class="t">    <span class="key">return</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">device</span><span class="op">(</span><span class="str">"cpu"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t913" href="#t913">913</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t914" href="#t914">914</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t915" href="#t915">915</a></span><span class="t"><span class="key">def</span> <span class="nam">override_or_use_default_value</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t916" href="#t916">916</a></span><span class="t">    <span class="nam">default_flag</span><span class="op">:</span> <span class="nam">Any</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t917" href="#t917">917</a></span><span class="t">    <span class="nam">override</span><span class="op">:</span> <span class="nam">Optional</span><span class="op">[</span><span class="nam">Any</span><span class="op">]</span> <span class="op">=</span> <span class="key">None</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t918" href="#t918">918</a></span><span class="t"><span class="op">)</span> <span class="op">-></span> <span class="nam">Any</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t919" href="#t919">919</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t920" href="#t920">920</a></span><span class="t"><span class="str">    Determines which flag to return based on whether an overriding flag is provided.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t921" href="#t921">921</a></span><span class="t"><span class="str">    If a not-None overriding flag is provided, it is returned.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t922" href="#t922">922</a></span><span class="t"><span class="str">    Otherwise, the global flag is returned.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t923" href="#t923">923</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t924" href="#t924">924</a></span><span class="t">    <span class="key">return</span> <span class="nam">override</span> <span class="key">if</span> <span class="nam">override</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span> <span class="key">else</span> <span class="nam">default_flag</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t925" href="#t925">925</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t926" href="#t926">926</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t927" href="#t927">927</a></span><span class="t"><span class="key">def</span> <span class="nam">get_offset_position_ids</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t928" href="#t928">928</a></span><span class="t">    <span class="nam">past_kv_pos_offset</span><span class="op">:</span> <span class="nam">int</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t929" href="#t929">929</a></span><span class="t">    <span class="nam">attention_mask</span><span class="op">:</span> <span class="nam">Int</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">"batch offset_pos"</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t930" href="#t930">930</a></span><span class="t"><span class="op">)</span> <span class="op">-></span> <span class="nam">Int</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">"batch pos"</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t931" href="#t931">931</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t932" href="#t932">932</a></span><span class="t"><span class="str">    Returns the indices of non-padded tokens, offset by the position of the first attended token.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t933" href="#t933">933</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t934" href="#t934">934</a></span><span class="t">    <span class="com"># shift the position ids so that the id at the the first attended token position becomes zero.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t935" href="#t935">935</a></span><span class="t">    <span class="com"># The position ids of the prepending pad tokens are shifted to -1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t936" href="#t936">936</a></span><span class="t">    <span class="nam">shifted_position_ids</span> <span class="op">=</span> <span class="nam">attention_mask</span><span class="op">.</span><span class="nam">cumsum</span><span class="op">(</span><span class="nam">dim</span><span class="op">=</span><span class="num">1</span><span class="op">)</span> <span class="op">-</span> <span class="num">1</span>  <span class="com"># [batch, tokens_length]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t937" href="#t937">937</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t938" href="#t938">938</a></span><span class="t">    <span class="com"># Set the position ids of all prepending pad tokens to an arbitrary number (zero here)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t939" href="#t939">939</a></span><span class="t">    <span class="com"># just to avoid indexing errors.</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t940" href="#t940">940</a></span><span class="t">    <span class="nam">position_ids</span> <span class="op">=</span> <span class="nam">shifted_position_ids</span><span class="op">.</span><span class="nam">masked_fill</span><span class="op">(</span><span class="nam">shifted_position_ids</span> <span class="op">&lt;</span> <span class="num">0</span><span class="op">,</span> <span class="num">0</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t941" href="#t941">941</a></span><span class="t">    <span class="key">return</span> <span class="nam">position_ids</span><span class="op">[</span><span class="op">:</span><span class="op">,</span> <span class="nam">past_kv_pos_offset</span><span class="op">:</span><span class="op">]</span>  <span class="com"># [pos, batch]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t942" href="#t942">942</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t943" href="#t943">943</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t944" href="#t944">944</a></span><span class="t"><span class="key">def</span> <span class="nam">get_cumsum_along_dim</span><span class="op">(</span><span class="nam">tensor</span><span class="op">,</span> <span class="nam">dim</span><span class="op">,</span> <span class="nam">reverse</span><span class="op">=</span><span class="key">False</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t945" href="#t945">945</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t946" href="#t946">946</a></span><span class="t"><span class="str">    Returns the cumulative sum of a tensor along a given dimension.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t947" href="#t947">947</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t948" href="#t948">948</a></span><span class="t">    <span class="key">if</span> <span class="nam">reverse</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t949" href="#t949">949</a></span><span class="t">        <span class="nam">tensor</span> <span class="op">=</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">flip</span><span class="op">(</span><span class="nam">dims</span><span class="op">=</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t950" href="#t950">950</a></span><span class="t">    <span class="nam">cumsum</span> <span class="op">=</span> <span class="nam">tensor</span><span class="op">.</span><span class="nam">cumsum</span><span class="op">(</span><span class="nam">dim</span><span class="op">=</span><span class="nam">dim</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t951" href="#t951">951</a></span><span class="t">    <span class="key">if</span> <span class="nam">reverse</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t952" href="#t952">952</a></span><span class="t">        <span class="nam">cumsum</span> <span class="op">=</span> <span class="nam">cumsum</span><span class="op">.</span><span class="nam">flip</span><span class="op">(</span><span class="nam">dims</span><span class="op">=</span><span class="op">(</span><span class="nam">dim</span><span class="op">,</span><span class="op">)</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t953" href="#t953">953</a></span><span class="t">    <span class="key">return</span> <span class="nam">cumsum</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t954" href="#t954">954</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t955" href="#t955">955</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t956" href="#t956">956</a></span><span class="t"><span class="key">def</span> <span class="nam">get_attention_mask</span><span class="op">(</span><span class="nam">tokenizer</span><span class="op">,</span> <span class="nam">tokens</span><span class="op">:</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="nam">prepend_bos</span><span class="op">:</span> <span class="nam">bool</span><span class="op">)</span> <span class="op">-></span> <span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t957" href="#t957">957</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t958" href="#t958">958</a></span><span class="t"><span class="str">    Computes the attention mask for the tokenized input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t959" href="#t959">959</a></span><span class="t"><span class="str">    NOTE: Only the leftmost leading pads (when `padding_side == left`)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t960" href="#t960">960</a></span><span class="t"><span class="str">    or rightmost trailing pads (when `padding_side == right`) are</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t961" href="#t961">961</a></span><span class="t"><span class="str">    considered as real pad tokens that should not be attended.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t962" href="#t962">962</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t963" href="#t963">963</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t964" href="#t964">964</a></span><span class="t"><span class="str">        tokenizer: The tokenizer used for tokenization.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t965" href="#t965">965</a></span><span class="t"><span class="str">        tokens (torch.Tensor): The tokenized input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t966" href="#t966">966</a></span><span class="t"><span class="str">        prepend_bos (bool): If True, a BOS token is prepended to the input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t967" href="#t967">967</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t968" href="#t968">968</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t969" href="#t969">969</a></span><span class="t"><span class="str">        torch.Tensor: The attention mask for the input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t970" href="#t970">970</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t971" href="#t971">971</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t972" href="#t972">972</a></span><span class="t">    <span class="com"># Initialize the attention mask with ones (indicating all tokens should be attended to)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t973" href="#t973">973</a></span><span class="t">    <span class="nam">attention_mask</span> <span class="op">=</span> <span class="nam">torch</span><span class="op">.</span><span class="nam">ones_like</span><span class="op">(</span><span class="nam">tokens</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t974" href="#t974">974</a></span><span class="t">    <span class="nam">is_not_pad_token</span> <span class="op">=</span> <span class="nam">tokens</span><span class="op">.</span><span class="nam">ne</span><span class="op">(</span><span class="nam">tokenizer</span><span class="op">.</span><span class="nam">pad_token_id</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t975" href="#t975">975</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t976" href="#t976">976</a></span><span class="t">    <span class="key">if</span> <span class="nam">tokenizer</span><span class="op">.</span><span class="nam">padding_side</span> <span class="op">==</span> <span class="str">"right"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t977" href="#t977">977</a></span><span class="t">        <span class="com"># Zero-out the rightmost trailing pad tokens</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t978" href="#t978">978</a></span><span class="t">        <span class="nam">is_trailing_pad</span> <span class="op">=</span> <span class="nam">get_cumsum_along_dim</span><span class="op">(</span><span class="nam">is_not_pad_token</span><span class="op">,</span> <span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="nam">reverse</span><span class="op">=</span><span class="key">True</span><span class="op">)</span> <span class="op">==</span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t979" href="#t979">979</a></span><span class="t">        <span class="nam">attention_mask</span><span class="op">[</span><span class="nam">is_trailing_pad</span><span class="op">]</span> <span class="op">=</span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t980" href="#t980">980</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t981" href="#t981">981</a></span><span class="t">        <span class="com"># Zero-out the leftmost leading pad tokens</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t982" href="#t982">982</a></span><span class="t">        <span class="nam">is_leading_pad</span> <span class="op">=</span> <span class="nam">get_cumsum_along_dim</span><span class="op">(</span><span class="nam">is_not_pad_token</span><span class="op">,</span> <span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="nam">reverse</span><span class="op">=</span><span class="key">False</span><span class="op">)</span> <span class="op">==</span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t983" href="#t983">983</a></span><span class="t">        <span class="nam">attention_mask</span><span class="op">[</span><span class="nam">is_leading_pad</span><span class="op">]</span> <span class="op">=</span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t984" href="#t984">984</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t985" href="#t985">985</a></span><span class="t">        <span class="com"># If the bos token is the same as the pad token,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t986" href="#t986">986</a></span><span class="t">        <span class="com"># the last token of the leftmost leading pad tokens is the bos token.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t987" href="#t987">987</a></span><span class="t">        <span class="com"># We need to set the attention mask for the bos token to 1.</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t988" href="#t988">988</a></span><span class="t">        <span class="key">if</span> <span class="nam">prepend_bos</span> <span class="key">and</span> <span class="nam">tokenizer</span><span class="op">.</span><span class="nam">bos_token_id</span> <span class="op">==</span> <span class="nam">tokenizer</span><span class="op">.</span><span class="nam">pad_token_id</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t989" href="#t989">989</a></span><span class="t">            <span class="nam">pad_bos_positions</span> <span class="op">=</span> <span class="nam">is_leading_pad</span><span class="op">.</span><span class="nam">sum</span><span class="op">(</span><span class="op">-</span><span class="num">1</span><span class="op">)</span> <span class="op">-</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t990" href="#t990">990</a></span><span class="t">            <span class="nam">attention_mask</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">arange</span><span class="op">(</span><span class="nam">attention_mask</span><span class="op">.</span><span class="nam">shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">)</span><span class="op">,</span> <span class="nam">pad_bos_positions</span><span class="op">]</span> <span class="op">=</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t991" href="#t991">991</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t992" href="#t992">992</a></span><span class="t">    <span class="key">return</span> <span class="nam">attention_mask</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t993" href="#t993">993</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t994" href="#t994">994</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t995" href="#t995">995</a></span><span class="t"><span class="key">def</span> <span class="nam">repeat_along_head_dimension</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t996" href="#t996">996</a></span><span class="t">    <span class="nam">tensor</span><span class="op">:</span> <span class="nam">Float</span><span class="op">[</span><span class="nam">torch</span><span class="op">.</span><span class="nam">Tensor</span><span class="op">,</span> <span class="str">"batch pos d_model"</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t997" href="#t997">997</a></span><span class="t">    <span class="nam">n_heads</span><span class="op">:</span> <span class="nam">int</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t998" href="#t998">998</a></span><span class="t">    <span class="nam">clone_tensor</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t999" href="#t999">999</a></span><span class="t">    <span class="com"># `einops.repeat` uses a view in torch, so we generally clone the tensor to avoid using shared storage for each head entry</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1000" href="#t1000">1000</a></span><span class="t"><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1001" href="#t1001">1001</a></span><span class="t">    <span class="nam">repeated_tensor</span> <span class="op">=</span> <span class="nam">einops</span><span class="op">.</span><span class="nam">repeat</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1002" href="#t1002">1002</a></span><span class="t">        <span class="nam">tensor</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1003" href="#t1003">1003</a></span><span class="t">        <span class="str">"batch pos d_model -> batch pos n_heads d_model"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1004" href="#t1004">1004</a></span><span class="t">        <span class="nam">n_heads</span><span class="op">=</span><span class="nam">n_heads</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1005" href="#t1005">1005</a></span><span class="t">    <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="par run show_par"><span class="n"><a id="t1006" href="#t1006">1006</a></span><span class="t">    <span class="key">if</span> <span class="nam">clone_tensor</span><span class="op">:</span>&nbsp;</span><span class="r"><span class="annotate short">1006&#x202F;&#x219B;&#x202F;1009</span><span class="annotate long">line 1006 didn't jump to line 1009, because the condition on line 1006 was never false</span></span></p>
    <p class="run"><span class="n"><a id="t1007" href="#t1007">1007</a></span><span class="t">        <span class="key">return</span> <span class="nam">repeated_tensor</span><span class="op">.</span><span class="nam">clone</span><span class="op">(</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1008" href="#t1008">1008</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1009" href="#t1009">1009</a></span><span class="t">        <span class="key">return</span> <span class="nam">repeated_tensor</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1010" href="#t1010">1010</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1011" href="#t1011">1011</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1012" href="#t1012">1012</a></span><span class="t"><span class="key">def</span> <span class="nam">get_nested_attr</span><span class="op">(</span><span class="nam">obj</span><span class="op">,</span> <span class="nam">attr_str</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1013" href="#t1013">1013</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1014" href="#t1014">1014</a></span><span class="t"><span class="str">    Retrieves a nested attribute from an object based on a dot-separated string.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1015" href="#t1015">1015</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1016" href="#t1016">1016</a></span><span class="t"><span class="str">    For example, if `attr_str` is "a.b.c", this function will return `obj.a.b.c`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1017" href="#t1017">1017</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1018" href="#t1018">1018</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1019" href="#t1019">1019</a></span><span class="t"><span class="str">        obj (Any): The object from which to retrieve the attribute.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1020" href="#t1020">1020</a></span><span class="t"><span class="str">        attr_str (str): A dot-separated string representing the attribute hierarchy.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1021" href="#t1021">1021</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1022" href="#t1022">1022</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1023" href="#t1023">1023</a></span><span class="t"><span class="str">        Any: The value of the nested attribute.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1024" href="#t1024">1024</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1025" href="#t1025">1025</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="nam">attr_str</span><span class="op">.</span><span class="nam">split</span><span class="op">(</span><span class="str">"."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1026" href="#t1026">1026</a></span><span class="t">    <span class="key">for</span> <span class="nam">attr</span> <span class="key">in</span> <span class="nam">attrs</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1027" href="#t1027">1027</a></span><span class="t">        <span class="nam">obj</span> <span class="op">=</span> <span class="nam">getattr</span><span class="op">(</span><span class="nam">obj</span><span class="op">,</span> <span class="nam">attr</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1028" href="#t1028">1028</a></span><span class="t">    <span class="key">return</span> <span class="nam">obj</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1029" href="#t1029">1029</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1030" href="#t1030">1030</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1031" href="#t1031">1031</a></span><span class="t"><span class="key">def</span> <span class="nam">set_nested_attr</span><span class="op">(</span><span class="nam">obj</span><span class="op">,</span> <span class="nam">attr_str</span><span class="op">,</span> <span class="nam">value</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1032" href="#t1032">1032</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1033" href="#t1033">1033</a></span><span class="t"><span class="str">    Sets a nested attribute of an object based on a dot-separated string.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1034" href="#t1034">1034</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1035" href="#t1035">1035</a></span><span class="t"><span class="str">    For example, if `attr_str` is "a.b.c", this function will set the value of `obj.a.b.c` to `value`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1036" href="#t1036">1036</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1037" href="#t1037">1037</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1038" href="#t1038">1038</a></span><span class="t"><span class="str">        obj (Any): The object on which to set the attribute.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1039" href="#t1039">1039</a></span><span class="t"><span class="str">        attr_str (str): A dot-separated string representing the attribute hierarchy.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1040" href="#t1040">1040</a></span><span class="t"><span class="str">        value (Any): The value to set for the nested attribute.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1041" href="#t1041">1041</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1042" href="#t1042">1042</a></span><span class="t">    <span class="nam">attrs</span> <span class="op">=</span> <span class="nam">attr_str</span><span class="op">.</span><span class="nam">split</span><span class="op">(</span><span class="str">"."</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1043" href="#t1043">1043</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1044" href="#t1044">1044</a></span><span class="t">    <span class="com"># Navigate to the deepest object containing the attribute to be set</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1045" href="#t1045">1045</a></span><span class="t">    <span class="key">for</span> <span class="nam">attr</span> <span class="key">in</span> <span class="nam">attrs</span><span class="op">[</span><span class="op">:</span><span class="op">-</span><span class="num">1</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1046" href="#t1046">1046</a></span><span class="t">        <span class="nam">obj</span> <span class="op">=</span> <span class="nam">getattr</span><span class="op">(</span><span class="nam">obj</span><span class="op">,</span> <span class="nam">attr</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1047" href="#t1047">1047</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1048" href="#t1048">1048</a></span><span class="t">    <span class="com"># Set the nested attribute's value</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1049" href="#t1049">1049</a></span><span class="t">    <span class="nam">setattr</span><span class="op">(</span><span class="nam">obj</span><span class="op">,</span> <span class="nam">attrs</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span><span class="op">,</span> <span class="nam">value</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1050" href="#t1050">1050</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1051" href="#t1051">1051</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1052" href="#t1052">1052</a></span><span class="t"><span class="key">class</span> <span class="nam">LocallyOverridenDefaults</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1053" href="#t1053">1053</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1054" href="#t1054">1054</a></span><span class="t"><span class="str">    Context manager that allows temporary overriding of default values within a model.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1055" href="#t1055">1055</a></span><span class="t"><span class="str">    Once the context is exited, the default values are restored.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1056" href="#t1056">1056</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1057" href="#t1057">1057</a></span><span class="t"><span class="str">    WARNING: This context manager must be used for any function/method that directly accesses</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1058" href="#t1058">1058</a></span><span class="t"><span class="str">    default values which may be overridden by the user using the function/method's arguments,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1059" href="#t1059">1059</a></span><span class="t"><span class="str">    e.g., `model.cfg.default_prepend_bos` and `model.tokenizer.padding_side` which can be</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1060" href="#t1060">1060</a></span><span class="t"><span class="str">    overriden by `prepend_bos` and `padding_side` arguments, respectively, in the `to_tokens`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1061" href="#t1061">1061</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1062" href="#t1062">1062</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1063" href="#t1063">1063</a></span><span class="t">    <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">model</span><span class="op">,</span> <span class="op">**</span><span class="nam">overrides</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1064" href="#t1064">1064</a></span><span class="t">        <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1065" href="#t1065">1065</a></span><span class="t"><span class="str">        Initializes the context manager.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1066" href="#t1066">1066</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1067" href="#t1067">1067</a></span><span class="t"><span class="str">        Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1068" href="#t1068">1068</a></span><span class="t"><span class="str">            model (HookedTransformer): The model whose default values will be overridden.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1069" href="#t1069">1069</a></span><span class="t"><span class="str">            overrides (dict): Key-value pairs of properties to override and their new values.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1070" href="#t1070">1070</a></span><span class="t"><span class="str">        """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1071" href="#t1071">1071</a></span><span class="t">        <span class="nam">self</span><span class="op">.</span><span class="nam">model</span> <span class="op">=</span> <span class="nam">model</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1072" href="#t1072">1072</a></span><span class="t">        <span class="nam">self</span><span class="op">.</span><span class="nam">overrides</span> <span class="op">=</span> <span class="nam">overrides</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1073" href="#t1073">1073</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1074" href="#t1074">1074</a></span><span class="t">        <span class="com"># Dictionary defining valid defaults, valid values, and locations to find and store them</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1075" href="#t1075">1075</a></span><span class="t">        <span class="nam">self</span><span class="op">.</span><span class="nam">values_with_defaults</span> <span class="op">=</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1076" href="#t1076">1076</a></span><span class="t">            <span class="str">"prepend_bos"</span><span class="op">:</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1077" href="#t1077">1077</a></span><span class="t">                <span class="str">"default_location"</span><span class="op">:</span> <span class="str">"model.cfg.default_prepend_bos"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1078" href="#t1078">1078</a></span><span class="t">                <span class="str">"valid_values"</span><span class="op">:</span> <span class="op">[</span><span class="nam">USE_DEFAULT_VALUE</span><span class="op">,</span> <span class="key">True</span><span class="op">,</span> <span class="key">False</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1079" href="#t1079">1079</a></span><span class="t">                <span class="str">"skip_overriding"</span><span class="op">:</span> <span class="key">False</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1080" href="#t1080">1080</a></span><span class="t">                <span class="str">"default_value_to_restore"</span><span class="op">:</span> <span class="key">None</span><span class="op">,</span>  <span class="com"># Will be set later</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1081" href="#t1081">1081</a></span><span class="t">            <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1082" href="#t1082">1082</a></span><span class="t">            <span class="str">"padding_side"</span><span class="op">:</span> <span class="op">{</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1083" href="#t1083">1083</a></span><span class="t">                <span class="str">"default_location"</span><span class="op">:</span> <span class="str">"model.tokenizer.padding_side"</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1084" href="#t1084">1084</a></span><span class="t">                <span class="str">"valid_values"</span><span class="op">:</span> <span class="op">[</span><span class="nam">USE_DEFAULT_VALUE</span><span class="op">,</span> <span class="str">"left"</span><span class="op">,</span> <span class="str">"right"</span><span class="op">]</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1085" href="#t1085">1085</a></span><span class="t">                <span class="str">"skip_overriding"</span><span class="op">:</span> <span class="nam">model</span><span class="op">.</span><span class="nam">tokenizer</span> <span class="key">is</span> <span class="key">None</span><span class="op">,</span>  <span class="com"># Do not override if tokenizer is None</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1086" href="#t1086">1086</a></span><span class="t">                <span class="str">"default_value_to_restore"</span><span class="op">:</span> <span class="key">None</span><span class="op">,</span>  <span class="com"># Will be set later</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1087" href="#t1087">1087</a></span><span class="t">            <span class="op">}</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1088" href="#t1088">1088</a></span><span class="t">        <span class="op">}</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1089" href="#t1089">1089</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1090" href="#t1090">1090</a></span><span class="t">        <span class="com"># Ensure provided overrides are defined in the dictionary above</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1091" href="#t1091">1091</a></span><span class="t">        <span class="key">for</span> <span class="nam">override</span> <span class="key">in</span> <span class="nam">overrides</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1092" href="#t1092">1092</a></span><span class="t">            <span class="key">assert</span> <span class="nam">override</span> <span class="key">in</span> <span class="nam">self</span><span class="op">.</span><span class="nam">values_with_defaults</span><span class="op">,</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1093" href="#t1093">1093</a></span><span class="t">                <span class="str">f"{override} is not a valid parameter to override. "</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1094" href="#t1094">1094</a></span><span class="t">                <span class="str">f"Valid parameters are {self.values_with_defaults.keys()}."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1095" href="#t1095">1095</a></span><span class="t">            <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1096" href="#t1096">1096</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1097" href="#t1097">1097</a></span><span class="t">    <span class="key">def</span> <span class="nam">__enter__</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1098" href="#t1098">1098</a></span><span class="t">        <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1099" href="#t1099">1099</a></span><span class="t"><span class="str">        Override default values upon entering the context.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1100" href="#t1100">1100</a></span><span class="t"><span class="str">        """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1101" href="#t1101">1101</a></span><span class="t">        <span class="key">for</span> <span class="nam">property</span><span class="op">,</span> <span class="nam">override</span> <span class="key">in</span> <span class="nam">self</span><span class="op">.</span><span class="nam">overrides</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1102" href="#t1102">1102</a></span><span class="t">            <span class="nam">info</span> <span class="op">=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">values_with_defaults</span><span class="op">[</span><span class="nam">property</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1103" href="#t1103">1103</a></span><span class="t">            <span class="key">if</span> <span class="nam">info</span><span class="op">[</span><span class="str">"skip_overriding"</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1104" href="#t1104">1104</a></span><span class="t">                <span class="key">continue</span>  <span class="com"># Skip if overriding for this property is disabled</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1105" href="#t1105">1105</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1106" href="#t1106">1106</a></span><span class="t">            <span class="com"># Ensure the override is a valid value</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1107" href="#t1107">1107</a></span><span class="t">            <span class="nam">valid_values</span> <span class="op">=</span> <span class="nam">info</span><span class="op">[</span><span class="str">"valid_values"</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1108" href="#t1108">1108</a></span><span class="t">            <span class="key">assert</span> <span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1109" href="#t1109">1109</a></span><span class="t">                <span class="nam">override</span> <span class="key">in</span> <span class="nam">valid_values</span>  <span class="com"># type: ignore</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1110" href="#t1110">1110</a></span><span class="t">            <span class="op">)</span><span class="op">,</span> <span class="str">f"{property} must be one of {valid_values}, but got {override}."</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1111" href="#t1111">1111</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1112" href="#t1112">1112</a></span><span class="t">            <span class="com"># Fetch current default and store it to restore later</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1113" href="#t1113">1113</a></span><span class="t">            <span class="nam">default_location</span> <span class="op">=</span> <span class="nam">info</span><span class="op">[</span><span class="str">"default_location"</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1114" href="#t1114">1114</a></span><span class="t">            <span class="nam">default_value</span> <span class="op">=</span> <span class="nam">get_nested_attr</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">default_location</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1115" href="#t1115">1115</a></span><span class="t">            <span class="nam">info</span><span class="op">[</span><span class="str">"default_value_to_restore"</span><span class="op">]</span> <span class="op">=</span> <span class="nam">deepcopy</span><span class="op">(</span><span class="nam">default_value</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1116" href="#t1116">1116</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1117" href="#t1117">1117</a></span><span class="t">            <span class="com"># Override the default value</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1118" href="#t1118">1118</a></span><span class="t">            <span class="nam">locally_overriden_value</span> <span class="op">=</span> <span class="nam">override_or_use_default_value</span><span class="op">(</span><span class="nam">default_value</span><span class="op">,</span> <span class="nam">override</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1119" href="#t1119">1119</a></span><span class="t">            <span class="nam">set_nested_attr</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">default_location</span><span class="op">,</span> <span class="nam">locally_overriden_value</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1120" href="#t1120">1120</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1121" href="#t1121">1121</a></span><span class="t">    <span class="key">def</span> <span class="nam">__exit__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">exc_type</span><span class="op">,</span> <span class="nam">exc_val</span><span class="op">,</span> <span class="nam">exc_tb</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1122" href="#t1122">1122</a></span><span class="t">        <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1123" href="#t1123">1123</a></span><span class="t"><span class="str">        Restore default values upon exiting the context.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1124" href="#t1124">1124</a></span><span class="t"><span class="str">        """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1125" href="#t1125">1125</a></span><span class="t">        <span class="key">for</span> <span class="nam">property</span> <span class="key">in</span> <span class="nam">self</span><span class="op">.</span><span class="nam">overrides</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1126" href="#t1126">1126</a></span><span class="t">            <span class="nam">info</span> <span class="op">=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">values_with_defaults</span><span class="op">[</span><span class="nam">property</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1127" href="#t1127">1127</a></span><span class="t">            <span class="key">if</span> <span class="nam">info</span><span class="op">[</span><span class="str">"skip_overriding"</span><span class="op">]</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1128" href="#t1128">1128</a></span><span class="t">                <span class="key">continue</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1129" href="#t1129">1129</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1130" href="#t1130">1130</a></span><span class="t">            <span class="com"># Restore the default value from before the context was entered</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1131" href="#t1131">1131</a></span><span class="t">            <span class="nam">default_location</span> <span class="op">=</span> <span class="nam">info</span><span class="op">[</span><span class="str">"default_location"</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1132" href="#t1132">1132</a></span><span class="t">            <span class="nam">default_value</span> <span class="op">=</span> <span class="nam">info</span><span class="op">[</span><span class="str">"default_value_to_restore"</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1133" href="#t1133">1133</a></span><span class="t">            <span class="nam">set_nested_attr</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">default_location</span><span class="op">,</span> <span class="nam">default_value</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1134" href="#t1134">1134</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1135" href="#t1135">1135</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1136" href="#t1136">1136</a></span><span class="t"><span class="key">def</span> <span class="nam">get_tokenizer_with_bos</span><span class="op">(</span><span class="nam">tokenizer</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1137" href="#t1137">1137</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1138" href="#t1138">1138</a></span><span class="t"><span class="str">    Returns the tokenizer initialized with add_bos_token=True.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1139" href="#t1139">1139</a></span><span class="t"><span class="str">    Such a tokenizer should be set as the default tokenizer because the tokenization of some</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1140" href="#t1140">1140</a></span><span class="t"><span class="str">    tokenizers like LlamaTokenizer are different when bos token is automatically/manually</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1141" href="#t1141">1141</a></span><span class="t"><span class="str">    prepended.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1142" href="#t1142">1142</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1143" href="#t1143">1143</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1144" href="#t1144">1144</a></span><span class="t"><span class="str">        tokenizer (AutoTokenizer): The tokenizer to initialize with add_bos_token=True.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1145" href="#t1145">1145</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1146" href="#t1146">1146</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1147" href="#t1147">1147</a></span><span class="t"><span class="str">        AutoTokenizer: The tokenizer initialized with add_bos_token=True.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1148" href="#t1148">1148</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1149" href="#t1149">1149</a></span><span class="t">    <span class="nam">init_kwargs</span> <span class="op">=</span> <span class="nam">deepcopy</span><span class="op">(</span><span class="nam">tokenizer</span><span class="op">.</span><span class="nam">init_kwargs</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1150" href="#t1150">1150</a></span><span class="t">    <span class="nam">pretrained_model_name_or_path</span> <span class="op">=</span> <span class="nam">init_kwargs</span><span class="op">.</span><span class="nam">pop</span><span class="op">(</span><span class="str">"name_or_path"</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1151" href="#t1151">1151</a></span><span class="t">    <span class="nam">add_bos_token</span> <span class="op">=</span> <span class="nam">init_kwargs</span><span class="op">.</span><span class="nam">pop</span><span class="op">(</span><span class="str">"add_bos_token"</span><span class="op">,</span> <span class="key">None</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1152" href="#t1152">1152</a></span><span class="t">    <span class="key">if</span> <span class="nam">add_bos_token</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1153" href="#t1153">1153</a></span><span class="t">        <span class="nam">add_bos_token</span> <span class="op">=</span> <span class="nam">getattr</span><span class="op">(</span><span class="nam">tokenizer</span><span class="op">,</span> <span class="str">"add_bos_token"</span><span class="op">,</span> <span class="key">False</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1154" href="#t1154">1154</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1155" href="#t1155">1155</a></span><span class="t">    <span class="key">if</span> <span class="nam">add_bos_token</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1156" href="#t1156">1156</a></span><span class="t">        <span class="nam">tokenizer_with_bos</span> <span class="op">=</span> <span class="nam">tokenizer</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1157" href="#t1157">1157</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1158" href="#t1158">1158</a></span><span class="t">        <span class="nam">huggingface_token</span> <span class="op">=</span> <span class="nam">os</span><span class="op">.</span><span class="nam">environ</span><span class="op">.</span><span class="nam">get</span><span class="op">(</span><span class="str">"HF_TOKEN"</span><span class="op">,</span> <span class="key">None</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1159" href="#t1159">1159</a></span><span class="t">        <span class="nam">tokenizer_with_bos</span> <span class="op">=</span> <span class="nam">AutoTokenizer</span><span class="op">.</span><span class="nam">from_pretrained</span><span class="op">(</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1160" href="#t1160">1160</a></span><span class="t">            <span class="nam">pretrained_model_name_or_path</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1161" href="#t1161">1161</a></span><span class="t">            <span class="nam">add_bos_token</span><span class="op">=</span><span class="key">True</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1162" href="#t1162">1162</a></span><span class="t">            <span class="nam">token</span><span class="op">=</span><span class="nam">huggingface_token</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1163" href="#t1163">1163</a></span><span class="t">            <span class="op">**</span><span class="nam">init_kwargs</span><span class="op">,</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1164" href="#t1164">1164</a></span><span class="t">        <span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1165" href="#t1165">1165</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1166" href="#t1166">1166</a></span><span class="t">    <span class="key">return</span> <span class="nam">tokenizer_with_bos</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1167" href="#t1167">1167</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1168" href="#t1168">1168</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1169" href="#t1169">1169</a></span><span class="t"><span class="key">def</span> <span class="nam">get_input_with_manually_prepended_bos</span><span class="op">(</span><span class="nam">tokenizer</span><span class="op">,</span> <span class="nam">input</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1170" href="#t1170">1170</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1171" href="#t1171">1171</a></span><span class="t"><span class="str">    Manually prepends the bos token to the input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1172" href="#t1172">1172</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1173" href="#t1173">1173</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1174" href="#t1174">1174</a></span><span class="t"><span class="str">        tokenizer (AutoTokenizer): The tokenizer to use for prepending the bos token.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1175" href="#t1175">1175</a></span><span class="t"><span class="str">        input (Union[str, List[str]]): The input to prepend the bos token to.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1176" href="#t1176">1176</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1177" href="#t1177">1177</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1178" href="#t1178">1178</a></span><span class="t"><span class="str">        Union[str, List[str]]: The input with the bos token manually prepended.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1179" href="#t1179">1179</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1180" href="#t1180">1180</a></span><span class="t">    <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">input</span><span class="op">,</span> <span class="nam">str</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1181" href="#t1181">1181</a></span><span class="t">        <span class="nam">input</span> <span class="op">=</span> <span class="nam">tokenizer</span><span class="op">.</span><span class="nam">bos_token</span> <span class="op">+</span> <span class="nam">input</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1182" href="#t1182">1182</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1183" href="#t1183">1183</a></span><span class="t">        <span class="nam">input</span> <span class="op">=</span> <span class="op">[</span><span class="nam">tokenizer</span><span class="op">.</span><span class="nam">bos_token</span> <span class="op">+</span> <span class="nam">string</span> <span class="key">for</span> <span class="nam">string</span> <span class="key">in</span> <span class="nam">input</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1184" href="#t1184">1184</a></span><span class="t">    <span class="key">return</span> <span class="nam">input</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1185" href="#t1185">1185</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1186" href="#t1186">1186</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1187" href="#t1187">1187</a></span><span class="t"><span class="key">def</span> <span class="nam">get_tokens_with_bos_removed</span><span class="op">(</span><span class="nam">tokenizer</span><span class="op">,</span> <span class="nam">tokens</span><span class="op">)</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1188" href="#t1188">1188</a></span><span class="t">    <span class="str">"""</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1189" href="#t1189">1189</a></span><span class="t"><span class="str">    Removes the bos token from the beginning of each sequence in `tokens`.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1190" href="#t1190">1190</a></span><span class="t"><span class="str">    The last dimension of `tokens` must be the sequence length.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1191" href="#t1191">1191</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1192" href="#t1192">1192</a></span><span class="t"><span class="str">    Args:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1193" href="#t1193">1193</a></span><span class="t"><span class="str">        tokenizer (AutoTokenizer): The tokenizer used to tokenize the input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1194" href="#t1194">1194</a></span><span class="t"><span class="str">        tokens (torch.Tensor): The tokenized input.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1195" href="#t1195">1195</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1196" href="#t1196">1196</a></span><span class="t"><span class="str">    Returns:</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1197" href="#t1197">1197</a></span><span class="t"><span class="str">        torch.Tensor: The tokenized input with the bos token removed.</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1198" href="#t1198">1198</a></span><span class="t"><span class="str">    """</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1199" href="#t1199">1199</a></span><span class="t">    <span class="key">if</span> <span class="nam">tokenizer</span><span class="op">.</span><span class="nam">padding_side</span> <span class="op">==</span> <span class="str">"right"</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1200" href="#t1200">1200</a></span><span class="t">        <span class="key">return</span> <span class="nam">tokens</span><span class="op">[</span><span class="op">...</span><span class="op">,</span> <span class="num">1</span><span class="op">:</span><span class="op">]</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1201" href="#t1201">1201</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1202" href="#t1202">1202</a></span><span class="t">    <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1203" href="#t1203">1203</a></span><span class="t">        <span class="nam">bos_removed_shape</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="nam">tokens</span><span class="op">.</span><span class="nam">shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1204" href="#t1204">1204</a></span><span class="t">        <span class="nam">bos_removed_shape</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span> <span class="op">-=</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1205" href="#t1205">1205</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1206" href="#t1206">1206</a></span><span class="t">        <span class="key">if</span> <span class="nam">tokenizer</span><span class="op">.</span><span class="nam">bos_token_id</span> <span class="op">==</span> <span class="nam">tokenizer</span><span class="op">.</span><span class="nam">pad_token_id</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1207" href="#t1207">1207</a></span><span class="t">            <span class="nam">is_not_pad_token</span> <span class="op">=</span> <span class="nam">tokens</span><span class="op">.</span><span class="nam">ne</span><span class="op">(</span><span class="nam">tokenizer</span><span class="op">.</span><span class="nam">pad_token_id</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1208" href="#t1208">1208</a></span><span class="t">            <span class="nam">is_leading_pad</span> <span class="op">=</span> <span class="nam">get_cumsum_along_dim</span><span class="op">(</span><span class="nam">is_not_pad_token</span><span class="op">,</span> <span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="nam">reverse</span><span class="op">=</span><span class="key">False</span><span class="op">)</span> <span class="op">==</span> <span class="num">0</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1209" href="#t1209">1209</a></span><span class="t">            <span class="nam">real_bos_positions</span> <span class="op">=</span> <span class="nam">is_leading_pad</span><span class="op">.</span><span class="nam">sum</span><span class="op">(</span><span class="op">-</span><span class="num">1</span><span class="op">)</span> <span class="op">-</span> <span class="num">1</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1210" href="#t1210">1210</a></span><span class="t">        <span class="key">else</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1211" href="#t1211">1211</a></span><span class="t">            <span class="nam">real_bos_positions</span> <span class="op">=</span> <span class="op">(</span><span class="nam">tokens</span> <span class="op">==</span> <span class="nam">tokenizer</span><span class="op">.</span><span class="nam">bos_token_id</span><span class="op">)</span><span class="op">.</span><span class="nam">int</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">argmax</span><span class="op">(</span><span class="op">-</span><span class="num">1</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1212" href="#t1212">1212</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1213" href="#t1213">1213</a></span><span class="t">        <span class="nam">tokens</span> <span class="op">=</span> <span class="nam">tokens</span><span class="op">.</span><span class="nam">scatter</span><span class="op">(</span><span class="nam">dim</span><span class="op">=</span><span class="num">1</span><span class="op">,</span> <span class="nam">index</span><span class="op">=</span><span class="nam">real_bos_positions</span><span class="op">.</span><span class="nam">unsqueeze</span><span class="op">(</span><span class="op">-</span><span class="num">1</span><span class="op">)</span><span class="op">,</span> <span class="nam">value</span><span class="op">=</span><span class="op">-</span><span class="num">100</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1214" href="#t1214">1214</a></span><span class="t">        <span class="key">return</span> <span class="nam">tokens</span><span class="op">[</span><span class="nam">tokens</span> <span class="op">!=</span> <span class="op">-</span><span class="num">100</span><span class="op">]</span><span class="op">.</span><span class="nam">view</span><span class="op">(</span><span class="op">*</span><span class="nam">bos_removed_shape</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1215" href="#t1215">1215</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1216" href="#t1216">1216</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1217" href="#t1217">1217</a></span><span class="t"><span class="key">try</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1218" href="#t1218">1218</a></span><span class="t">    <span class="key">import</span> <span class="nam">pytest</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1219" href="#t1219">1219</a></span><span class="t">&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1220" href="#t1220">1220</a></span><span class="t">    <span class="com"># Note: Docstring won't be tested with PyTest (it's ignored), as it thinks this is a regular unit</span>&nbsp;</span><span class="r"></span></p>
    <p class="pln"><span class="n"><a id="t1221" href="#t1221">1221</a></span><span class="t">    <span class="com"># test (because its name is prefixed `test_`).</span>&nbsp;</span><span class="r"></span></p>
    <p class="run"><span class="n"><a id="t1222" href="#t1222">1222</a></span><span class="t">    <span class="nam">pytest</span><span class="op">.</span><span class="nam">mark</span><span class="op">.</span><span class="nam">skip</span><span class="op">(</span><span class="nam">test_prompt</span><span class="op">)</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1223" href="#t1223">1223</a></span><span class="t"><span class="key">except</span> <span class="nam">ModuleNotFoundError</span><span class="op">:</span>&nbsp;</span><span class="r"></span></p>
    <p class="mis show_mis"><span class="n"><a id="t1224" href="#t1224">1224</a></span><span class="t">    <span class="key">pass</span>  <span class="com"># disregard if pytest not in env</span>&nbsp;</span><span class="r"></span></p>
</main>
<footer>
    <div class="content">
        <p>
            <a id="prevFileLink" class="nav" href="d_b2114f845e0399b7_devices_py.html">&#xab; prev</a> &nbsp; &nbsp;
            <a id="indexLink" class="nav" href="index.html">&Hat; index</a> &nbsp; &nbsp;
            <a id="nextFileLink" class="nav" href="index.html">&#xbb; next</a>
            &nbsp; &nbsp; &nbsp;
            <a class="nav" href="https://coverage.readthedocs.io/en/7.4.4">coverage.py v7.4.4</a>,
            created at 2024-07-06 00:32 +0000
        </p>
    </div>
</footer>
</body>
</html>
